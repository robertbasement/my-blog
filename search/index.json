[{"content":" 筆記 from IPython.display import HTML import pandas as pd def display_df_as_html(df): \u0026#34;\u0026#34;\u0026#34;Automatically display DataFrame as an HTML table.\u0026#34;\u0026#34;\u0026#34; display(HTML(df.to_html())) # Apply function to all DataFrame outputs pd.DataFrame._repr_html_ = display_df_as_html company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event.tail() 日期 股票代號 股票名稱 月營收公告 財報公告 除息日 除權日 法說會 減資前 減資後 ... \\ 9891130 20241225 9951 皇田 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891131 20241225 9955 佳龍 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891132 20241225 9958 世紀鋼 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891133 20241225 9960 邁達康 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891134 20241225 9962 有益 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 申報轉讓 庫藏股 注意股票 新股上市 人事異動 停資 停券 最後回補日 今日事件數 RTIME 9891130 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 510725547 9891131 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891132 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891133 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891134 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 [5 rows x 21 columns] 參考 ","date":"2025-02-07T23:59:14+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/test/","title":"測試df table"},{"content":" 筆記 import pandas as pd import numpy as np import matplotlib.pyplot as plt pd.options.display.float_format = \u0026#39;{:.4f}\u0026#39;.format SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] 月營收 mon_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/monthly/monthly_revenue.ftr\u0026#39;) mon_df = mon_df[mon_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] mon_df = mon_df[~mon_df[\u0026#39;公告日\u0026#39;].isna()] mon_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(mon_df[\u0026#39;公告日\u0026#39;]) mon_df.sort_values(\u0026#39;公告日_dt\u0026#39;, inplace=True, ascending=True) mon_df.reset_index(drop=True, inplace=True) 收盤價 price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price0050 = price_df[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;0050\u0026#39;] price0050[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price0050[\u0026#39;日期\u0026#39;]) price0050.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price0050.reset_index(drop=True, inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050['日期_dt'] = pd.to_datetime(price0050['日期']) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050.sort_values('日期_dt', inplace=True, ascending=True) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;last_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(n + 2) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price0050 = price0050.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2395123834.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price0050 = price0050.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price_df = price_df.merge(price0050, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_0050\u0026#39;)) 融資 margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) price_df = price_df.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((price_df[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 週集保 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) price_df = price_df.merge(agg, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res = res.merge(price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False), how=\u0026#39;left\u0026#39;, left_on=(\u0026#39;股票代號\u0026#39;), right_on=(\u0026#39;股票代號\u0026#39;), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_baseline\u0026#39;)) res[\u0026#39;diff_ret\u0026#39;] = res[\u0026#39;hold_20Days_ret\u0026#39;] - res[\u0026#39;hold_20Days_ret_baseline\u0026#39;] for ticker in SUB_TICKERS: print(res.loc[res[\u0026#39;股票代號\u0026#39;]==ticker, [\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;diff_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;signal_count\u0026#39;]]) cut 股票代號 diff_ret hold_20Days_winrate signal_count 0 (-7.381, -0.0403] 2059 0.0074 0.5253 297 9 (-0.0403, -0.0209] 2059 -0.0003 0.5539 612 18 (-0.0209, -0.0112] 2059 -0.0105 0.5278 612 27 (-0.0112, -0.00457] 2059 0.0055 0.6105 493 36 (-0.00457, 0.000588] 2059 -0.0055 0.5302 464 45 (0.000588, 0.0064] 2059 -0.0165 0.5211 474 54 (0.0064, 0.0132] 2059 -0.0066 0.5511 470 63 (0.0132, 0.0236] 2059 0.0048 0.5630 579 72 (0.0236, 0.0459] 2059 0.0154 0.4592 368 81 (0.0459, 6.477] 2059 -0.0042 0.4848 330 cut 股票代號 diff_ret hold_20Days_winrate signal_count 5 (-7.381, -0.0403] 3529 0.0076 0.5681 639 14 (-0.0403, -0.0209] 3529 0.0057 0.5977 430 23 (-0.0209, -0.0112] 3529 0.0197 0.6016 251 32 (-0.0112, -0.00457] 3529 -0.0115 0.4541 185 41 (-0.00457, 0.000588] 3529 -0.0182 0.4237 118 50 (0.000588, 0.0064] 3529 0.0286 0.5524 105 59 (0.0064, 0.0132] 3529 0.0080 0.5088 114 68 (0.0132, 0.0236] 3529 0.0233 0.6364 132 77 (0.0236, 0.0459] 3529 -0.0101 0.5516 368 86 (0.0459, 6.477] 3529 -0.0001 0.5152 924 cut 股票代號 diff_ret hold_20Days_winrate signal_count 2 (-7.381, -0.0403] 2383 -0.0163 0.5163 337 11 (-0.0403, -0.0209] 2383 -0.0155 0.6022 450 20 (-0.0209, -0.0112] 2383 0.0208 0.5992 509 29 (-0.0112, -0.00457] 2383 0.0109 0.6031 456 38 (-0.00457, 0.000588] 2383 -0.0056 0.5408 845 47 (0.000588, 0.0064] 2383 0.0085 0.5935 866 56 (0.0064, 0.0132] 2383 0.0112 0.5605 860 65 (0.0132, 0.0236] 2383 -0.0099 0.4559 601 74 (0.0236, 0.0459] 2383 0.0042 0.4363 314 83 (0.0459, 6.477] 2383 0.0311 0.5296 287 cut 股票代號 diff_ret hold_20Days_winrate signal_count 1 (-7.381, -0.0403] 2330 -0.0388 0.4315 788 10 (-0.0403, -0.0209] 2330 0.0045 0.5472 424 19 (-0.0209, -0.0112] 2330 -0.0026 0.5797 364 28 (-0.0112, -0.00457] 2330 0.0076 0.6842 741 37 (-0.00457, 0.000588] 2330 -0.0034 0.6103 839 46 (0.000588, 0.0064] 2330 -0.0058 0.5833 768 55 (0.0064, 0.0132] 2330 -0.0045 0.6129 824 64 (0.0132, 0.0236] 2330 0.0027 0.6062 617 73 (0.0236, 0.0459] 2330 0.0221 0.6621 441 82 (0.0459, 6.477] 2330 -0.0033 0.5289 484 cut 股票代號 diff_ret hold_20Days_winrate signal_count 8 (-7.381, -0.0403] 8069 -0.0083 0.4898 786 17 (-0.0403, -0.0209] 8069 0.0377 0.6390 313 26 (-0.0209, -0.0112] 8069 0.0130 0.5763 321 35 (-0.0112, -0.00457] 8069 -0.0059 0.5538 316 44 (-0.00457, 0.000588] 8069 0.0035 0.5430 256 53 (0.000588, 0.0064] 8069 -0.0044 0.5430 291 62 (0.0064, 0.0132] 8069 0.0173 0.6335 352 71 (0.0132, 0.0236] 8069 0.0035 0.5276 381 80 (0.0236, 0.0459] 8069 -0.0176 0.4596 594 89 (0.0459, 6.477] 8069 -0.0020 0.5591 744 cut 股票代號 diff_ret hold_20Days_winrate signal_count 7 (-7.381, -0.0403] 5274 0.0202 0.6256 438 16 (-0.0403, -0.0209] 5274 -0.0428 0.5028 179 25 (-0.0209, -0.0112] 5274 -0.0071 0.6331 169 34 (-0.0112, -0.00457] 5274 0.0072 0.6823 192 43 (-0.00457, 0.000588] 5274 0.0079 0.6508 126 52 (0.000588, 0.0064] 5274 0.0453 0.7287 129 61 (0.0064, 0.0132] 5274 0.0348 0.7063 160 70 (0.0132, 0.0236] 5274 0.0197 0.6702 188 79 (0.0236, 0.0459] 5274 0.0036 0.6394 416 88 (0.0459, 6.477] 5274 -0.0205 0.5478 712 cut 股票代號 diff_ret hold_20Days_winrate signal_count 4 (-7.381, -0.0403] 3008 0.0105 0.4967 449 13 (-0.0403, -0.0209] 3008 0.0191 0.6574 788 22 (-0.0209, -0.0112] 3008 0.0128 0.6181 720 31 (-0.0112, -0.00457] 3008 0.0030 0.5690 652 40 (-0.00457, 0.000588] 3008 -0.0275 0.4177 565 49 (0.000588, 0.0064] 3008 -0.0320 0.3731 453 58 (0.0064, 0.0132] 3008 -0.0063 0.4907 377 67 (0.0132, 0.0236] 3008 0.0032 0.5278 485 76 (0.0236, 0.0459] 3008 -0.0048 0.5455 627 85 (0.0459, 6.477] 3008 0.0236 0.5260 365 cut 股票代號 diff_ret hold_20Days_winrate signal_count 3 (-7.381, -0.0403] 2454 -0.0014 0.5589 433 12 (-0.0403, -0.0209] 2454 -0.0161 0.4977 663 21 (-0.0209, -0.0112] 2454 0.0020 0.6016 728 30 (-0.0112, -0.00457] 2454 -0.0285 0.4292 643 39 (-0.00457, 0.000588] 2454 0.0040 0.5687 466 48 (0.000588, 0.0064] 2454 0.0165 0.6183 503 57 (0.0064, 0.0132] 2454 -0.0053 0.5879 512 66 (0.0132, 0.0236] 2454 0.0106 0.6314 681 75 (0.0236, 0.0459] 2454 -0.0067 0.5551 726 84 (0.0459, 6.477] 2454 -0.0048 0.5616 276 cut 股票代號 diff_ret hold_20Days_winrate signal_count 6 (-7.381, -0.0403] 3533 -0.0589 0.2222 36 15 (-0.0403, -0.0209] 3533 0.0147 0.6366 344 24 (-0.0209, -0.0112] 3533 0.0306 0.6929 521 33 (-0.0112, -0.00457] 3533 -0.0040 0.5455 528 42 (-0.00457, 0.000588] 3533 -0.0483 0.3852 527 51 (0.000588, 0.0064] 3533 -0.0313 0.4356 606 60 (0.0064, 0.0132] 3533 0.0060 0.5898 529 69 (0.0132, 0.0236] 3533 0.0259 0.6311 534 78 (0.0236, 0.0459] 3533 0.0143 0.4725 345 87 (0.0459, 6.477] 3533 0.1118 0.8333 78 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window): date_numeric = window[:, 0] # Extract the first column (date_numeric) value = window[:, 1] # Extract the second column (value) x_diff = date_numeric[-1] - date_numeric[0] # Time difference y_diff = value[-1] - value[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size][[\u0026#39;date_numeric\u0026#39;, \u0026#39;value\u0026#39;]].to_numpy() slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] # Time difference y_diff = window_df[\u0026#39;value\u0026#39;].iloc[-1] - window_df[\u0026#39;value\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 price_df[\u0026#39;date_numeric\u0026#39;] = (price_df[\u0026#39;日期_dt\u0026#39;] - price_df[\u0026#39;日期_dt\u0026#39;].min()).dt.days price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'date_numeric'], dtype='object') # 120日本益比的切線斜率 # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] - 1 # Time difference y_diff = (window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[-1] - window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] )/ window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) df[f\u0026#39;slope_{window_size}\u0026#39;] = [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment df[f\u0026#39;slope_{window_size}\u0026#39;] = df[f\u0026#39;slope_{window_size}\u0026#39;].shift(1) # 本益比用今天的收盤價去計算 明天才知道result return df # Add slope to the DataFrame # price_df[\u0026#39;slope\u0026#39;] = rolling_slope(price_df, window_size=5) for w in [5, 10, 20, 60, 120]: price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) price_df.loc[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;本益比(近四季)\u0026#39;, \u0026#39;slope_5\u0026#39;, \u0026#39;date_numeric\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ((25.6-29.5)/29.5)/5 -0.026440677966101684 for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).mean().reset_index(drop=True) price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).sum().reset_index(drop=True) ret_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: print(price_df.loc[price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]\u0026gt;0, ret_cols].mean()) # price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=5)) w = 60 j = 60 for ticker in SUB_TICKERS: tmp = price_df[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;] = tmp[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean() ax1.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;], label=\u0026#39;PE\u0026#39;) ax2 = ax1.twinx() ax2.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;],color=\u0026#39;green\u0026#39;, label=\u0026#39;PE slope\u0026#39;) ax3 = ax1.twinx() ax3.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;收盤價\u0026#39;],color=\u0026#39;orange\u0026#39;, label=\u0026#39;price\u0026#39;) ax1.set_title(ticker) indices = tmp.loc[(tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt;= 0.02), \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) ax1.legend() ax2.legend() def vector_backtest(df): # input: df, 需要有signa columns, output : [[trade_data1], [trade_data2], ...] (list中包含多個list) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4] # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; com_code = group[\u0026#39;股票代號\u0026#39;].iloc[-1] start_date = group[\u0026#39;日期\u0026#39;].iloc[0] end_date = group[\u0026#39;日期\u0026#39;].iloc[-1] buy_price = group[\u0026#39;次日收盤價\u0026#39;].iloc[0] sell_price = group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1] ret = (sell_price/buy_price) - 1 holding_days = len(group) event_list = [com_code, start_date, end_date, buy_price, sell_price, ret, holding_days] event_list_all.append(event_list) return event_list_all print(f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;) slope_60_rolling_60_SUM price_df[\u0026#39;本益比_rolling5\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean().reset_index(drop=True) price_df[\u0026#39;本益比_rolling20\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(20).mean().reset_index(drop=True) 看起來本益比切線斜率 累積增加\u0026gt;0 對捕捉上升趨勢還不錯 price_df.reset_index(drop=True, inplace=True) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) # | (price_df[f\u0026#39;slope_{w}\u0026#39;] \u0026lt; price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) \u0026amp; (price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt;= 0) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/312944587.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), ret_cols].mean() hold_5Days_ret 0.0080 hold_10Days_ret 0.0148 hold_20Days_ret 0.0310 hold_60Days_ret 0.0807 hold_120Days_ret 0.1454 dtype: float64 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3156983121.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) | (price_df[\u0026#39;last_60Days_ret_0050\u0026#39;] \u0026lt;= -0.1) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/95528996.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.columns[-140:-120] Index(['收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME'], dtype='object') price_df[\u0026#39;20MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(20).mean().reset_index(drop=True) price_df[\u0026#39;60MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(60).mean().reset_index(drop=True) price_df[\u0026#39;200MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(200).mean().reset_index(drop=True) Local Minima, maxima from scipy.signal import argrelextrema def groupby_extrema(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df[\u0026#39;local_maxima\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima.loc[max_comparisons_larger_idx].values.tolist() df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_sup(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # print(local_minima) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) print(min_comparisons_smaller_idx) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df[\u0026#39;local_minima\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima.loc[min_comparisons_smaller_idx].values.tolist() df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) [np.int64(647), np.int64(727), np.int64(916), np.int64(1198), np.int64(1314), np.int64(1388), np.int64(1801), np.int64(2151), np.int64(2358), np.int64(2549), np.int64(2999), np.int64(3101), np.int64(3290), np.int64(4081), np.int64(4249), np.int64(4392), np.int64(4752)] [np.int64(388), np.int64(960), np.int64(1098), np.int64(1504), np.int64(1633), np.int64(1760), np.int64(2227), np.int64(2331), np.int64(2519), np.int64(2642), np.int64(2956), np.int64(3136), np.int64(3325), np.int64(3444), np.int64(3646), np.int64(3675), np.int64(3740), np.int64(4131), np.int64(4369), np.int64(4417), np.int64(4677), np.int64(4757), np.int64(4858), np.int64(4902), np.int64(5019), np.int64(5178), np.int64(5262), np.int64(5381), np.int64(5749), np.int64(6100), np.int64(6562), np.int64(6835), np.int64(6941), np.int64(7077), np.int64(7161)] [np.int64(799), np.int64(1099), np.int64(2475), np.int64(2879), np.int64(2999), np.int64(3090), np.int64(3347), np.int64(3469), np.int64(3750), np.int64(4090), np.int64(4196), np.int64(4293), np.int64(4472), np.int64(4599), np.int64(4716), np.int64(4844), np.int64(5076), np.int64(5188), np.int64(5317), np.int64(5535), np.int64(5556), np.int64(5818), np.int64(5899), np.int64(6264), np.int64(6430), np.int64(6451), np.int64(6795), np.int64(6893)] [np.int64(380), np.int64(624), np.int64(749), np.int64(1254), np.int64(1441), np.int64(1629), np.int64(1859), np.int64(2107), np.int64(2236), np.int64(2638), np.int64(2710), np.int64(2894), np.int64(2993), np.int64(3240), np.int64(3541), np.int64(3848), np.int64(4122), np.int64(4240), np.int64(4639), np.int64(4952), np.int64(5171), np.int64(5380), np.int64(5662), np.int64(5684), np.int64(5735)] [np.int64(345), np.int64(628), np.int64(1091), np.int64(1513), np.int64(1715), np.int64(1910), np.int64(1946), np.int64(2023), np.int64(2086), np.int64(2190), np.int64(2438), np.int64(2813), np.int64(3199), np.int64(3389), np.int64(3426), np.int64(3459), np.int64(3681), np.int64(3819), np.int64(3965), np.int64(4515), np.int64(4766), np.int64(4890), np.int64(5135), np.int64(5230), np.int64(5349), np.int64(5502)] [np.int64(374), np.int64(465), np.int64(598), np.int64(624), np.int64(1017), np.int64(1173), np.int64(1588), np.int64(1710), np.int64(1939), np.int64(2157), np.int64(2286), np.int64(2761), np.int64(2816), np.int64(3084), np.int64(3111), np.int64(3293)] [np.int64(653), np.int64(953), np.int64(1046), np.int64(1150), np.int64(1469), np.int64(1596), np.int64(1628), np.int64(1706), np.int64(1826), np.int64(1922), np.int64(2362), np.int64(2518), np.int64(2731), np.int64(3190), np.int64(3637), np.int64(3741), np.int64(3757), np.int64(3873), np.int64(4145)] [np.int64(318), np.int64(534), np.int64(796), np.int64(1031), np.int64(1068), np.int64(1110), np.int64(1153), np.int64(1328), np.int64(1394), np.int64(1716), np.int64(1835), np.int64(2269)] [np.int64(765), np.int64(952), np.int64(1659), np.int64(1962), np.int64(2577), np.int64(3066), np.int64(3310), np.int64(3626), np.int64(3773), np.int64(3796), np.int64(3961), np.int64(4354), np.int64(4559), np.int64(4661), np.int64(4841)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3911248321.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, \u0026#39;收盤價\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2624941152.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, '收盤價')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, \u0026#39;收盤價\u0026#39;)) [np.int64(204), np.int64(287), np.int64(387), np.int64(690), np.int64(886), np.int64(1026), np.int64(1259), np.int64(1299), np.int64(1369), np.int64(1471), np.int64(1508), np.int64(1530), np.int64(1583), np.int64(1742), np.int64(2029), np.int64(2081), np.int64(2308), np.int64(2343), np.int64(2501), np.int64(2543), np.int64(2626), np.int64(2713), np.int64(2737), np.int64(2794), np.int64(3012), np.int64(3029), np.int64(3053), np.int64(3107), np.int64(3157), np.int64(3169), np.int64(3267), np.int64(3314), np.int64(3345), np.int64(3420), np.int64(3452), np.int64(3475), np.int64(3494), np.int64(3681), np.int64(3819), np.int64(4028), np.int64(4159), np.int64(4193), np.int64(4316), np.int64(4338), np.int64(4367), np.int64(4410), np.int64(4563), np.int64(4706), np.int64(4746), np.int64(4790)] [np.int64(40), np.int64(133), np.int64(185), np.int64(258), np.int64(317), np.int64(343), np.int64(386), np.int64(431), np.int64(615), np.int64(904), np.int64(943), np.int64(1029), np.int64(1069), np.int64(1159), np.int64(1224), np.int64(1537), np.int64(1562), np.int64(1646), np.int64(1704), np.int64(1757), np.int64(1797), np.int64(1823), np.int64(1875), np.int64(1896), np.int64(1942), np.int64(2037), np.int64(2083), np.int64(2110), np.int64(2125), np.int64(2149), np.int64(2193), np.int64(2253), np.int64(2277), np.int64(2491), np.int64(2553), np.int64(2592), np.int64(2616), np.int64(2641), np.int64(2704), np.int64(2912), np.int64(2930), np.int64(2948), np.int64(3039), np.int64(3102), np.int64(3284), np.int64(3333), np.int64(3400), np.int64(3470), np.int64(3508), np.int64(3668), np.int64(3695), np.int64(3713), np.int64(3951), np.int64(4018), np.int64(4088), np.int64(4291), np.int64(4359), np.int64(4375), np.int64(4390), np.int64(4593), np.int64(4802), np.int64(4895), np.int64(4960), np.int64(5006), np.int64(5243), np.int64(5336), np.int64(5389), np.int64(5488), np.int64(5564), np.int64(5962), np.int64(6047), np.int64(6086), np.int64(6169), np.int64(6187), np.int64(6219), np.int64(6310), np.int64(6506), np.int64(6636), np.int64(6754), np.int64(6786), np.int64(6856), np.int64(6991), np.int64(7030), np.int64(7068), np.int64(7145), np.int64(7262), np.int64(7367), np.int64(7573)] [np.int64(96), np.int64(147), np.int64(203), np.int64(240), np.int64(401), np.int64(468), np.int64(587), np.int64(715), np.int64(789), np.int64(1042), np.int64(1190), np.int64(1235), np.int64(1283), np.int64(1432), np.int64(1463), np.int64(1489), np.int64(1530), np.int64(1632), np.int64(1646), np.int64(1669), np.int64(1894), np.int64(1986), np.int64(2041), np.int64(2101), np.int64(2167), np.int64(2263), np.int64(2449), np.int64(2622), np.int64(2822), np.int64(2847), np.int64(2976), np.int64(3006), np.int64(3078), np.int64(3287), np.int64(3307), np.int64(3349), np.int64(3437), np.int64(3543), np.int64(3629), np.int64(3673), np.int64(3693), np.int64(3710), np.int64(3737), np.int64(3820), np.int64(3890), np.int64(4051), np.int64(4140), np.int64(4164), np.int64(4193), np.int64(4274), np.int64(4496), np.int64(4577), np.int64(4681), np.int64(4806), np.int64(4827), np.int64(5003), np.int64(5026), np.int64(5273), np.int64(5294), np.int64(5333), np.int64(5387), np.int64(5430), np.int64(5477), np.int64(5508), np.int64(5742), np.int64(5760), np.int64(5812), np.int64(5844), np.int64(5999), np.int64(6123), np.int64(6411), np.int64(6484), np.int64(6574), np.int64(6600), np.int64(6702), np.int64(6727), np.int64(6777), np.int64(6840), np.int64(6911)] [np.int64(215), np.int64(229), np.int64(247), np.int64(390), np.int64(584), np.int64(692), np.int64(789), np.int64(833), np.int64(875), np.int64(1018), np.int64(1058), np.int64(1121), np.int64(1136), np.int64(1196), np.int64(1216), np.int64(1234), np.int64(1317), np.int64(1588), np.int64(1622), np.int64(1729), np.int64(1818), np.int64(1829), np.int64(2054), np.int64(2120), np.int64(2193), np.int64(2220), np.int64(2295), np.int64(2394), np.int64(2421), np.int64(2459), np.int64(2476), np.int64(2493), np.int64(2673), np.int64(2817), np.int64(2850), np.int64(2959), np.int64(3232), np.int64(3282), np.int64(3419), np.int64(3494), np.int64(3594), np.int64(3608), np.int64(3664), np.int64(3754), np.int64(3793), np.int64(3845), np.int64(4071), np.int64(4196), np.int64(4214), np.int64(4229), np.int64(4275), np.int64(4324), np.int64(4611), np.int64(4961), np.int64(4997), np.int64(5096), np.int64(5125), np.int64(5173), np.int64(5233), np.int64(5367), np.int64(5429), np.int64(5549), np.int64(5607)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) [np.int64(86), np.int64(106), np.int64(213), np.int64(429), np.int64(450), np.int64(573), np.int64(592), np.int64(639), np.int64(718), np.int64(1006), np.int64(1066), np.int64(1146), np.int64(1188), np.int64(1217), np.int64(1241), np.int64(1277), np.int64(1472), np.int64(1580), np.int64(1650), np.int64(1679), np.int64(1775), np.int64(1854), np.int64(1965), np.int64(2041), np.int64(2244), np.int64(2354), np.int64(2387), np.int64(2428), np.int64(2507), np.int64(2524), np.int64(2648), np.int64(2708), np.int64(2769), np.int64(2828), np.int64(2868), np.int64(3122), np.int64(3142), np.int64(3332), np.int64(3355), np.int64(3370), np.int64(3423), np.int64(3438), np.int64(3644), np.int64(3742), np.int64(3858), np.int64(3932), np.int64(3950), np.int64(3985), np.int64(4114), np.int64(4136), np.int64(4154), np.int64(4174), np.int64(4271), np.int64(4461), np.int64(4573), np.int64(4602), np.int64(4671), np.int64(4805), np.int64(4847), np.int64(4963), np.int64(4982), np.int64(5085), np.int64(5457), np.int64(5559), np.int64(5594)] [np.int64(63), np.int64(113), np.int64(163), np.int64(232), np.int64(292), np.int64(338), np.int64(349), np.int64(424), np.int64(436), np.int64(451), np.int64(520), np.int64(531), np.int64(640), np.int64(671), np.int64(1002), np.int64(1117), np.int64(1129), np.int64(1300), np.int64(1344), np.int64(1529), np.int64(1554), np.int64(1632), np.int64(1645), np.int64(1661), np.int64(1738), np.int64(1798), np.int64(1881), np.int64(1923), np.int64(2102), np.int64(2175), np.int64(2214), np.int64(2246), np.int64(2363), np.int64(2593), np.int64(2704), np.int64(2759), np.int64(2812), np.int64(3083), np.int64(3175), np.int64(3245), np.int64(3313)] [np.int64(123), np.int64(149), np.int64(219), np.int64(260), np.int64(280), np.int64(608), np.int64(637), np.int64(727), np.int64(813), np.int64(894), np.int64(921), np.int64(997), np.int64(1090), np.int64(1115), np.int64(1235), np.int64(1275), np.int64(1370), np.int64(1384), np.int64(1482), np.int64(1502), np.int64(1654), np.int64(1826), np.int64(1838), np.int64(1865), np.int64(1896), np.int64(2014), np.int64(2086), np.int64(2190), np.int64(2208), np.int64(2302), np.int64(2471), np.int64(2513), np.int64(2569), np.int64(2583), np.int64(2681), np.int64(2821), np.int64(2838), np.int64(3028), np.int64(3096), np.int64(3264), np.int64(3308), np.int64(3377), np.int64(3513), np.int64(3590), np.int64(3668), np.int64(3728), np.int64(3814), np.int64(3853), np.int64(3908), np.int64(4095)] [np.int64(38), np.int64(114), np.int64(255), np.int64(302), np.int64(314), np.int64(335), np.int64(674), np.int64(778), np.int64(922), np.int64(1079), np.int64(1276), np.int64(1310), np.int64(1342), np.int64(1486), np.int64(1781), np.int64(1968), np.int64(2036), np.int64(2161), np.int64(2174), np.int64(2223), np.int64(2255), np.int64(2276), np.int64(2310), np.int64(2328), np.int64(2444), np.int64(2476), np.int64(2498), np.int64(2520), np.int64(2659), np.int64(2826)] [np.int64(59), np.int64(146), np.int64(176), np.int64(272), np.int64(395), np.int64(475), np.int64(553), np.int64(571), np.int64(659), np.int64(901), np.int64(960), np.int64(1056), np.int64(1080), np.int64(1112), np.int64(1139), np.int64(1491), np.int64(1530), np.int64(1555), np.int64(1733), np.int64(1809), np.int64(1925), np.int64(1940), np.int64(2024), np.int64(2035), np.int64(2156), np.int64(2201), np.int64(2304), np.int64(2334), np.int64(2395), np.int64(2528), np.int64(2578), np.int64(2629), np.int64(2651), np.int64(2763), np.int64(2811), np.int64(2831), np.int64(2908), np.int64(2930), np.int64(3133), np.int64(3285), np.int64(3345), np.int64(3451), np.int64(3500), np.int64(3582), np.int64(3611), np.int64(3837), np.int64(3914), np.int64(3948), np.int64(4087), np.int64(4230), np.int64(4327), np.int64(4414), np.int64(4433), np.int64(4510), np.int64(4587), np.int64(4607), np.int64(4700), np.int64(4783), np.int64(4799), np.int64(4828), np.int64(4944), np.int64(5083)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/785596803.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, '收盤價')) price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;] ) strategy Logic price_df.reset_index(drop=True, inplace=True) # 近一個月 400張大戶 增加2%以上 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4079245513.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 mask = (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[mask, \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/857034293.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1700805250.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[((price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/168196673.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;20MA\u0026#39;] \u0026gt;= price_df[\u0026#39;200MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3380416550.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/939178834.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/357474516.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 組合上下行 price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/950731482.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3623880085.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1110539843.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt; 0.02), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3456730543.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026gt;= price_df[\u0026#39;60MA\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1528418423.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026lt; price_df[\u0026#39;60MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/538384737.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) # price_df[price_df[\u0026#39;signal\u0026#39;]==1] NOW price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) # (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5)| (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[((price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;0.02) \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3722245375.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 簡易PnL模擬 res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2059', '3008'], dtype='object') from collections import Counter def vector_backtest_ratio(df, buyholddays): \u0026#39;\u0026#39;\u0026#39; for backtest PnL ratio index_count 算目前在該ticker 上累積bet的數量 \u0026#39;\u0026#39;\u0026#39; df.reset_index(drop=True, inplace=True) df[\u0026#39;ratio\u0026#39;] = 0 signal_idx = df[df[\u0026#39;signal\u0026#39;]==1].index all_holding_idx = [] for idx in signal_idx: adding_idx = [i for i in range(idx, idx+buyholddays) if i \u0026lt; len(df)] all_holding_idx += adding_idx df.loc[all_holding_idx, \u0026#39;signal\u0026#39;] = 1 return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 10)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/517245478.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 10)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 20)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2754594864.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 20)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 60)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3282921495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 60)) price_df.reset_index(drop=True, inplace=True) res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/317971430.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2330', '8069', '3008'], dtype='object') 如果是想要抄底的策略 holding 天數可能要拉長到可以等他漲回去 # price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;signal\u0026#39;]==1)].iloc[-20::] res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1410/2410 0.5850622406639004 2454, 2383, 2059, 3008 done res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;slope\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;]\u0026lt;=-0.05), \u0026#39;signal\u0026#39;] = 1 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;slope\u0026#39;]\u0026gt;=0.1), \u0026#39;signal\u0026#39;] = 1 ret_cols = [f\u0026#39;hold_{n}Days_ret\u0026#39; for n in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{n}Days_winrate\u0026#39; for n in [5, 10, 20, 60, 120]] price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() - price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PE price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;本益比(近四季)\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'cut', 'signal'], dtype='object') price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) income_stat_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/quarterly/quarterlyIncomeStatementSingal.ftr\u0026#39;) income_stat_df = income_stat_df[income_stat_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] income_stat_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(income_stat_df[\u0026#39;公告日期\u0026#39;]) income_stat_df.sort_values(\u0026#39;年季\u0026#39;, inplace=True, ascending=True) income_stat_df.reset_index(drop=True, inplace=True) income_stat_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import re income_stat_df.columns = [re.sub(r\u0026#39;\\s+\u0026#39;, \u0026#39;\u0026#39;, i) for i in income_stat_df.columns] income_stat_df.columns[0:30] Index(['年季', '股票代號', '股票名稱', '市場別', '財報類別', '銷貨收入淨額(千)', '銷貨收入(千)', '銷貨退回(千)', '銷貨折讓(千)', '營業收入淨額(千)', '營業成本(千)', '營業毛利(千)', '聯屬公司間未實現利益(千)', '聯屬公司間已實現利益(千)', '營業毛利淨額(千)', '營業費用(千)', '推銷費用(千)', '管理費用(千)', '研發費用(千)', '預期信用減損損益(千)', '其他營業費用(千)', '其他收益及費損(千)', '其他收益(千)', '其他費損(千)', '營業利益(千)', '營業外收入及支出(千)', '利息收入(千)', '銀行存款利息(千)', '按攤銷後成本衡量之金融資產利息收入(千)', '透過其他綜合損益按公允價值衡量之金融資產利息收入(千)'], dtype='object') income_stat_df.columns[-30::] Index(['國外營運機構淨投資避險中屬有效避險部分之避險工具損益(千)', '與待出售非流動資產直接相關之權益–可能重分類至損益(千)', '透過其他綜合損益按公允價值衡量之債務工具投資未實現評價損益(千)', '避險工具之損益–可能重分類至損益(千)', '採權益法認列關聯企業及合資其他綜合損益之份額–可能重分類至損益(千)', '可能重分類至損益之其他項目(千)', '與可能重分類至損益之項目相關之所得稅(千)', '綜合損益(千)', '稅後純益歸屬(千)', '母公司業主–稅後純益(千)', '非控制權益–稅後純益(千)', '共同控制下前手權益–稅後純益(千)', '綜合損益歸屬(千)', '母公司業主–綜合損益(千)', '非控制權益–綜合損益(千)', '共同控制下前手權益–綜合損益(千)', 'EBITDA(千)', '公告基本每股盈餘(元)', '公告稀釋每股盈餘(元)', '原始每股稅前盈餘(元)', '原始每股稅後盈餘(元)', '原始每股綜合盈餘(元)', '每股稅前盈餘(元)', '每股稅後盈餘(元)', '每股綜合盈餘(元)', '更新日期', '公告日期', '建立日期', 'RTIME', '公告日_dt'], dtype='object') income_stat_df[\u0026#39;母公司業主–稅後純益(千)\u0026#39;] 0 \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; 2 \u0026lt;NA\u0026gt; 3 \u0026lt;NA\u0026gt; 4 1602873 ... 818 4498178 819 25715520 820 2435866 821 247845528 822 1456409 Name: 母公司業主–稅後純益(千), Length: 823, dtype: Int64 不同時間段 適合看得指標也不盡相同 我能不能這個概念 -\u0026gt; 用基本面的變化來作為時間段的區分 像是基本面改善期間 -\u0026gt; 適合的策略\n基本面維持不變時的策略\n股價過度反應/過高過低PE對應的策略\n像是 基本面漲, 股價沒漲 -\u0026gt; 可能已經反應過了, 也可能是還沒反應\n順勢 基本面漲 \u0026amp; 股價也漲\n大盤逆風 基本面漲 但股價大跌 -\u0026gt; 先不要進場 等大盤回穩 or PE到一定程度才進場\n貝氏定理 先把營收, EPS, 對比股價的圖Plot出來 判斷大盤行情 上行, 糾結, 下行 在對比各個features在這些期間之下的表現 ex: 大盤下行的時候 全部訊號都沒用 除了PE跌倒歷史quantile多少時可以買入\u0026hellip;, 上行的時候跟著持有也不用管基本面etc reample + merge EPS forward knowing , cal + resample + merge 1. 先把每一季的EPS做加總(4季 agg) 再藉由shift去假設 能夠完美預測未來N季 再resample 至daily def resample_q_forward(df): # print(df[\u0026#39;股票代號\u0026#39;].iloc[-1]) df = df[~df[\u0026#39;公告日期\u0026#39;].isna()] df = df[~df.duplicated(subset=[\u0026#39;公告日期\u0026#39;])] df[\u0026#39;knowNext0Q\u0026#39;] = df[\u0026#39;每股稅後盈餘(元)\u0026#39;].rolling(4).sum() df.set_index(\u0026#39;公告日_dt\u0026#39;, inplace=True) df = df.resample(\u0026#39;D\u0026#39;).ffill() return df 2. 與股價合併 resample_q_df = combine_df = price_df.merge(resample_q_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) combine_df[\u0026#39;Y_M\u0026#39;] = combine_df[\u0026#39;日期_dt\u0026#39;].dt.year.astype(str) + \u0026#39;_\u0026#39; + combine_df[\u0026#39;日期_dt\u0026#39;].dt.month.astype(str).str.zfill(2) sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub[\u0026#39;PEG_0Q\u0026#39;].describe() count 5167.0000 mean 1.5405 std 2.4577 min -1.0632 25% 0.3917 50% 0.7254 75% 1.6816 max 20.2743 Name: PEG_0Q, dtype: float64 3. 有股價 有完美預測一段時間的EPS -\u0026gt; 就有完美預估的PE 找出該期間的MAX, MIN值 主要是用來繪制河流圖 並shift def find_PE_range(df): \u0026#39;\u0026#39;\u0026#39; groupby 年季, ticker 假設知道未來N季的EPS 對應期間股價的P/E 區間的max, min 應該要用於未來畫本益比河流圖所用 \u0026#39;\u0026#39;\u0026#39; tmp = pd.DataFrame() YM = df[\u0026#39;Y_M\u0026#39;].iloc[-1] Q = df[\u0026#39;年季\u0026#39;].iloc[-1] for i in range(1, 5): tmp.loc[Q, f\u0026#39;{i}_max_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].max() tmp.loc[Q, f\u0026#39;{i}_mean_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].mean() tmp.loc[Q, f\u0026#39;{i}_min_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].min() # tmp.loc[Q, f\u0026#39;{i}_max_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].max() # tmp.loc[Q, f\u0026#39;{i}_mean_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].mean() # tmp.loc[Q, f\u0026#39;{i}_min_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].min() tmp[\u0026#39;Q\u0026#39;] = Q return tmp pe_res = combine_df.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]).apply(find_PE_range).reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/3018702681.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. pe_res = combine_df.groupby(['股票代號', '年季']).apply(find_PE_range).reset_index(drop=False) 用前一季之前的All data 來計算 分位數 # Convert the \u0026#39;quarter\u0026#39; column to a Period with quarterly frequency combine_df[\u0026#39;year\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[:4] # Extract the year (first 4 digits) combine_df[\u0026#39;qtr\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[-2:] # Extract the quarter (last 2 digits) # Create a new column with period as \u0026#39;YYYYQ#\u0026#39; format (like 2000Q4, 2001Q1, etc.) combine_df[\u0026#39;period\u0026#39;] = combine_df[\u0026#39;year\u0026#39;] + \u0026#39;Q\u0026#39; + combine_df[\u0026#39;qtr\u0026#39;].replace({\u0026#39;01\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;02\u0026#39;: \u0026#39;2\u0026#39;, \u0026#39;03\u0026#39;: \u0026#39;3\u0026#39;, \u0026#39;04\u0026#39;: \u0026#39;4\u0026#39;}) # Convert to Pandas Period with quarterly frequency combine_df[\u0026#39;period\u0026#39;] = pd.PeriodIndex(combine_df[\u0026#39;period\u0026#39;], freq=\u0026#39;Q\u0026#39;) def quantile_q(df): i = 0 q_list = df[\u0026#39;period\u0026#39;].unique().tolist() sub_df_list = [] for q in q_list: thisQ = df[df[\u0026#39;period\u0026#39;]==q] lastQ = df[(df[\u0026#39;period\u0026#39;]\u0026gt;(q - 40)) \u0026amp; (df[\u0026#39;period\u0026#39;]\u0026lt;q)] # 20 -\u0026gt; 5y, 12 -\u0026gt; 3y for i in range(0, 5): thisQ[f\u0026#39;q20_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.2) thisQ[f\u0026#39;q40_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.4) thisQ[f\u0026#39;q60_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.6) thisQ[f\u0026#39;q80_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.8) # thisQ[f\u0026#39;q20_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.2) # thisQ[f\u0026#39;q40_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.4) # thisQ[f\u0026#39;q60_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.6) # thisQ[f\u0026#39;q80_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.8) sub_df_list.append(thisQ) new_df = pd.concat(sub_df_list) return new_df res = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_q).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/348048885.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res = combine_df.groupby('股票代號').apply(quantile_q).reset_index(drop=True) res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2008Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x1283cb400\u0026gt; png\r\u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2018Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 4 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q_G\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q_G\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q_G\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q_G\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PEG_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x124c216d0\u0026gt; png\rfor i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;0~20_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;20~40_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;40~60_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;60~80_{i}Q_G\u0026#39; if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;80~100_{i}Q_G\u0026#39; for i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;0~20_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;20~40_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;40~60_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;60~80_{i}Q\u0026#39; if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;80~100_{i}Q\u0026#39; res[res[\u0026#39;cata_0Q\u0026#39;]==\u0026#39;0~20_0Q\u0026#39;] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[[\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_0Q\u0026#39;])[[\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() preview_res[\u0026#39;day_ratio\u0026#39;] = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[\u0026#39;收盤價\u0026#39;].count()/6275 preview_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;20~40_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) # for i in range(0, 5): for i in [0, 4]: # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) hist_obj = ax1.hist(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, bins=100, alpha=0.5 ) color = hist_obj[2][0].get_facecolor() ax1.axvline(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].mean(), ymin=0, ymax=500, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, color=color) ax1.legend() png\rpng\rpng\rpng\rpng\rfrom scipy import stats import numpy as np # Generate some sample data with different lengths data1 = np.random.normal(50, 10, 100) # Dataset 1 data2 = np.random.normal(52, 15, 150) # Dataset 2 # Perform a two-sample t-test assuming equal variances (Student\u0026#39;s t-test) t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\u0026#34;) # Perform Welch\u0026#39;s t-test (does not assume equal variances) t_stat_welch, p_value_welch = stats.ttest_ind(data1, data2, equal_var=False) print(f\u0026#34;Welch\u0026#39;s t-test: t-statistic = {t_stat_welch:.4f}, p-value = {p_value_welch:.4f}\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res tmp = pd.DataFrame() for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: i = 0 t = 1 for days in [5, 10, 20, 60, 120]: data1 = sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values data2 = sub.loc[sub[f\u0026#39;cata_{t}Q\u0026#39;] == f\u0026#39;{quantile}_{t}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}, {quantile}_{t}Q, \u0026#39;hold_{days}Days_ret\u0026#39;\u0026#34;) tmp.loc[f\u0026#39;{quantile}_{i}Q vs {t}Q\u0026#39;, f\u0026#39;hold {days} mean return p-value\u0026#39;] = p_value tmp 有多少 forward 0 在低本益比 但其實用forward 4Q是高本益比\n反之亦然\n這類股價其實是由未來營收所帶動的 也許就是我們想要抓的?\nforward 的優勢就在於 用歷史推估 跟由研調預測得出來的結論有明顯差異 材值得做\nsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;60~80_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;80~100_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res # mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) # mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import numpy as np sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) show_df = pd.DataFrame() for i in np.arange(0.1, 1, 0.1): mask2 = (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026gt;= i) \u0026amp; (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026lt; (i + 0.1)) show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, \u0026#39;count\u0026#39;] = len(sub.loc[mask2]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df = pd.DataFrame() sub = res for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: mask1 = (sub[\u0026#39;cata_4Q\u0026#39;] == f\u0026#39;{quantile}_4Q\u0026#39;) show_df.loc[f\u0026#39;mean_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;precision_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res.columns import pandas as pd import matplotlib.pyplot as plt # Example data with 8 categories data = {\u0026#39;Date\u0026#39;: pd.date_range(start=\u0026#39;2024-01-01\u0026#39;, periods=10, freq=\u0026#39;D\u0026#39;), \u0026#39;Signal\u0026#39;: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0], \u0026#39;Category\u0026#39;: [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]} df = pd.DataFrame(data) # Get unique categories (suppose you have exactly 8 categories) categories = df[\u0026#39;Category\u0026#39;].unique() # Define the number of rows and columns for the subplots n_rows, n_cols = 2, 4 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() # Loop through each category and plot for i, category in enumerate(categories): # Filter DataFrame by category category_df = df[df[\u0026#39;Category\u0026#39;] == category] # Get dates where Signal == 1 for that category signal_dates = category_df.loc[category_df[\u0026#39;Signal\u0026#39;] == 1, \u0026#39;Date\u0026#39;] # Plot vertical lines on the respective subplot axes[i].vlines(x=signal_dates, ymin=0, ymax=1, color=\u0026#39;b\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;Signal {category}\u0026#39;) axes[i].set_title(f\u0026#39;Category {category}\u0026#39;) axes[i].set_ylabel(\u0026#39;Signal\u0026#39;) # Format the x-axis for dates (shared x-axis) axes[i].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter(\u0026#39;%Y-%m-%d\u0026#39;)) axes[i].tick_params(axis=\u0026#39;x\u0026#39;, rotation=45) # Hide empty subplots if any (for cases when the grid is larger than needed) for j in range(i + 1, n_rows * n_cols): fig.delaxes(axes[j]) # Set the xlabel for the subplots in the last row for ax in axes[-n_cols:]: ax.set_xlabel(\u0026#39;Date\u0026#39;) # Adjust layout plt.tight_layout() plt.show() len(res[\u0026#39;股票代號\u0026#39;].unique()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q 0~20\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\r\u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal PEG ver. \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt;= 0.7) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt;= 0.9) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q, PEG 0.7~0.9\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax1.legend() signal_dates = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values ax1.vlines(x=signal_dates, label=\u0026#39;signal\u0026#39;) sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values preview_res.loc[\u0026#39;2330\u0026#39;] res_indexPE = res.merge(IndexPE_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;])) IndexPE_res.columns res_indexPE[\u0026#39;股票代號\u0026#39;].unique() sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20030701\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20101231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20101231\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20191231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] i = 1 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20121231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20240509\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] i = 4 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20161231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20231109\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ticker = sub[\u0026#39;股票代號\u0026#39;].iloc[-1] ax1.set_title(f\u0026#39;Index PE vs {ticker}_forward{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;], label=f\u0026#39;{ticker}_PE_{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;agg_PE_{i}Q\u0026#39;], label=f\u0026#39;index_PE_{i}Q\u0026#39;) ax1.legend() ticker = (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) q = 4 tmp = pd.DataFrame() for i in [2, 4, 6, 8]: signal = (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026gt;res_indexPE[f\u0026#39;agg_PE_{q}Q\u0026#39;]) \u0026amp; (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026lt;res_indexPE[f\u0026#39;q{i}0\u0026#39;]) # tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() # res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].describe() tmp cumsum or rolling min/max + shift 就可以了\ndef rolling_max(df): \u0026#39;\u0026#39;\u0026#39; groupby ticker \u0026#39;\u0026#39;\u0026#39; for i in range(1, 5): df[f\u0026#39;{i}_cummax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].cummax().shift(1) df[f\u0026#39;{i}_cummin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].cummin().shift(1) df[f\u0026#39;{i}_cummean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].expanding().mean().shift(1) df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(20).max().shift(1) df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).min().shift(1) df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).mean().shift(1) df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(12).max().shift(1) df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).min().shift(1) df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).mean().shift(1) df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(40).max().shift(1) df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).min().shift(1) df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).mean().shift(1) return df pe_res = pe_res.groupby(\u0026#39;股票代號\u0026#39;).apply(rolling_max).reset_index(drop=True) # cumsum 至上一季 PE最高值, cumsum 至上一季 PE最低值, rolling 5y 至上一季 PE最高值, rolling 5y 至上一季 PE最低值 pe_res.loc[(pe_res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) , [\u0026#39;年季\u0026#39;, \u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] 把 截至上一季 PE的高低點 算出來後 與股價merge combine_df = combine_df.merge(pe_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), right_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_MINMAX\u0026#39;)) combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;) , [\u0026#39;日期\u0026#39;,\u0026#39;PE_1Q\u0026#39; ,\u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2454\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;knowNext1Q\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;, \u0026#39;1_rolling5ymean_PE\u0026#39;]].dropna() for i in range(1, 5): combine_df[f\u0026#39;knowNext{i}Q_5y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummean_PE\u0026#39;] # 在知曉下一季EPS後 利用過往3季 + 未來1季 去算年度EPS # 在用該EPS 與當下股價計算 預知PE # 期間預知PE的min, max 將獨立出來 combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;1_max_PE\u0026#39;, \u0026#39;1_min_PE\u0026#39;, \u0026#39;1_mean_PE\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] 繪製本益比河流圖時 河流應為過去一段時間的min, max ex : under 知曉下一Q EPS的情況下\n過去10年 所有在知曉下一Q對應的EPS\nmin, max 作為河流 對照如今的 預知PE\n可以try 的財務指標\n存貨(千) 研發費用(千) PPE (不動產相關的變化) 先做圖 在想要怎麼辦\ncombine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] combine_df.columns[180:210] combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub.reset_index(drop=True, inplace=True) def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2)) * (data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9): data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 0 return data signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal).reset_index(drop=True) signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal_reverse).reset_index(drop=True) def vector_backtest_delay_entering(df, delay_days): # prodction ver. # input: df, 需要有signal columns, output : [{trade_data1}, {trade_data2}, ...] (list中包含多個dict) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4](cumsum) # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index ## 想要include 最新持有的狀態 -\u0026gt; 若是最後一個row 的連續持有日期 \u0026gt;=4 (3個訊號 隔日才會買進 目前沒有持有) ## return的計算 要改 if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 用來確認退場reaso # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; if len(group) \u0026lt;= delay_days: # 訊號數不足 不會進場 continue else: group.reset_index(drop=True, inplace=True) group = group.iloc[delay_days::] # extract info from group trading_dict = { \u0026#39;股票代號\u0026#39;: group[\u0026#39;股票代號\u0026#39;].iloc[-1], \u0026#39;買入日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[0], \u0026#39;賣出日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[-1], \u0026#39;買入價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].iloc[0], \u0026#39;賣出價\u0026#39; : group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1], \u0026#39;期間最高價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].max(), \u0026#39;持有天數\u0026#39; : len(group), \u0026#39;持有狀態\u0026#39; : \u0026#39;history\u0026#39;, \u0026#39;return\u0026#39; : (group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1]/group[\u0026#39;次日收盤價\u0026#39;].iloc[0]) - 1, } event_list_all.append(trading_dict) # production情況下 每日最新一個group的狀況不一定 \u0026#39;\u0026#39;\u0026#39; 原本是收盤後跑 下午3點跑 改為開盤前 早上8點跑 這樣昨天的data一定更新好了 故 持有狀態的用詞修改 從buy_tomorrow -\u0026gt; buy_today \u0026#39;\u0026#39;\u0026#39; return event_list_all vector_backtest_delay_entering(sub, 0) res = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) res import pandas as pd import numpy as np # Simulated data with multiple cycles dates = pd.to_datetime([ \u0026#39;2024-01-01\u0026#39;, \u0026#39;2024-01-02\u0026#39;, \u0026#39;2024-01-03\u0026#39;, \u0026#39;2024-01-04\u0026#39;, \u0026#39;2024-01-05\u0026#39;, \u0026#39;2024-01-06\u0026#39;, \u0026#39;2024-01-07\u0026#39;, \u0026#39;2024-01-08\u0026#39;, \u0026#39;2024-01-09\u0026#39;, \u0026#39;2024-01-10\u0026#39;, \u0026#39;2024-01-11\u0026#39;, \u0026#39;2024-01-12\u0026#39;, \u0026#39;2024-01-13\u0026#39;, \u0026#39;2024-01-14\u0026#39;, \u0026#39;2024-01-15\u0026#39;, \u0026#39;2024-01-16\u0026#39;, \u0026#39;2024-01-17\u0026#39;, \u0026#39;2024-01-18\u0026#39;, \u0026#39;2024-01-19\u0026#39;, \u0026#39;2024-01-20\u0026#39; ]) # Simulated P/E ratios data = pd.DataFrame({ \u0026#39;PE_ratio\u0026#39;: [20, 21, 19, 22, 23, 10, 9, 11, 14, 16, 18, 20, 35, 36, 10, 9, 12, 15, 18, 20], \u0026#39;Adj Close\u0026#39;: np.random.randn(len(dates)) * 10 + 100 }, index=dates) # Parameters lower_bound = 10 upper_bound = 35 # Initialize the signal and state data[\u0026#39;Signal\u0026#39;] = 0 data.loc[(data[\u0026#39;PE_ratio\u0026#39;] \u0026lt;= lower_bound), \u0026#39;Signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for i in range(len(data)): pe_ratio = data.iloc[i][\u0026#39;PE_ratio\u0026#39;] if state == 0: # Normal period if pe_ratio \u0026lt;= lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if pe_ratio \u0026gt; lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if pe_ratio \u0026gt;= upper_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 0 state = 0 else: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 print(\u0026#34;Filtered Data with Signals:\u0026#34;) print(data) trading_dict = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) # 整理backtest result code = signal_df[\u0026#39;股票代號\u0026#39;].unique().tolist() res_df = pd.DataFrame() for c in code: tmp = trading_dict[c] tmp_df = pd.DataFrame(tmp) if not tmp_df.empty: res_df = pd.concat([res_df, tmp_df], ignore_index=True) code res_df[\u0026#39;precision\u0026#39;] = res_df[\u0026#39;return\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) res_df[[\u0026#39;return\u0026#39;, \u0026#39;precision\u0026#39;,\u0026#39;持有天數\u0026#39;]].describe() res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe() for i in code: print(i) print(res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==i, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe()) trading_dict[\u0026#39;2059\u0026#39;] sub[\u0026#39;forwardPE\u0026#39;].expanding().std() # combine_df = price_df.merge(resample_mon_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) columns 展示 combine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] # Create subplots without shared axes fig, axes = plt.subplots(3, 3, figsize=(12, 8)) # Flatten the axes array for easy iteration axes = axes.flatten() # Group by \u0026#39;Stock\u0026#39; and plot each group in a separate subplot for ax, (name, group) in zip(axes, combine_df.groupby(\u0026#39;股票代號\u0026#39;)): ax.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;收盤價\u0026#39;], label=\u0026#39;Price\u0026#39;) ax.set_title(name) ax.set_xlabel(\u0026#39;Date\u0026#39;) # ax.set_ylabel(\u0026#39;Price\u0026#39;, color=\u0026#39;blue\u0026#39;) ax.legend(loc=2) # Create a secondary y-axis and plot \u0026#39;Volume\u0026#39; ax2 = ax.twinx() ax2.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;稅後純益率(%)\u0026#39;], label=\u0026#39;net profit ratio\u0026#39;, color=\u0026#39;orange\u0026#39;, alpha=0.6) # ax2.set_ylabel(\u0026#39;monthly rev\u0026#39;, color=\u0026#39;green\u0026#39;) ax2.legend(loc=3) # Set axis colors to match the data they represent ax.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;blue\u0026#39;) ax2.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;green\u0026#39;) # Adjust layout to prevent overlap plt.tight_layout() # Show the plot plt.show() combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;, \u0026#39;近三月合併營收(千)\u0026#39;].plot() combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;] image_2024-08-15_11-38-01.png\rfig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;2317\u0026#39;) ax1.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;近12月累計合併營收(千)\u0026#39;], label=\u0026#39;12m_rev_agg\u0026#39;, color=\u0026#39;orange\u0026#39;) ax1.legend(loc=1) 指標相關聯 我覺得應該不只是財務數據 也有其他的東西但我們無法access\n籌碼相關, 分析師估值等\n但以我目前的情況 應該是做估值 並建立買賣點\n-\u0026gt; 存貨\n大概看了一下 營收的趨勢整體多為向上，股價也是 但若將週期縮小至2-3個月 營收與股價背離的情況很常發生\n判斷營收成長 or 衰退的趨勢 其time frame也要抓好\n畢竟營收整個趨勢變化較慢 但方向較穩定 但股價有更多雜訊因素\nsub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = sub[(~sub[\u0026#39;3m_diff\u0026#39;].isna()) \u0026amp; (~sub[\u0026#39;12m_diff\u0026#39;].isna())] sub.isna().sum() combine_df.columns[-60:-30] sub[\u0026#39;optimize\u0026#39;] = (sub[\u0026#39;3m_diff\u0026#39;] \u0026gt; sub[\u0026#39;12m_diff\u0026#39;]).apply(lambda x : 1 if x else 0) sub[\u0026#39;近三月合併營收(千)\u0026#39;] sub[\u0026#39;3m_diff\u0026#39;] 694442123 - 673510177 參考 ","date":"2025-02-07T23:02:53+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/final_test2/","title":"Final_test2"},{"content":" 筆記 部落格要一直寫下去是不間單，工作一忙回到家倒頭就睡，沒時間跟精神來記錄一下\n我本人基本上沒有在使用IG，但內心也有一個要發廢文的衝動\n把這邊當IG在用來的心態寫東西\n記錄一下Hugo操作的指令\n免得下次又要再去查怎麼用\nHugo指令 新增文章 hugo new post/\u0026lt;md file path\u0026gt; 這樣就可以在content/post/下看到新創的markdown檔\n文章調整 基本上我所有的文章都是從jupyter轉換過來\n在用hugo new post create好md檔之後 得把jupyter轉換過的md檔複製到 hugo格式中 筆記的位置 需要run 這個指令under root (content folder的上一層)\njupyter nbconvert --to markdown --output-dir=\u0026lt;output dir\u0026gt; \u0026lt;ipynb file\u0026gt; 有一個問題是 轉換後圖會被存在另一個folder中\n假設你的jupyter file叫 test.ipynb 在轉換的output dir中還會有一個folder 叫 test_files.ipynb 此時可以把你的圖片都丟到 static/images中 並用以下command line\n將圖片的url做修改\nsed -i \u0026#39;\u0026#39; \u0026#39;s/your_notebook_files\\//\\/images\\//g\u0026#39; your_notebook.md 開幾本地server hugo server 先在本地測試預覽用的\n打包成靜態網頁檔(每次更新過blog內容後) hugo -D 執行完後，打包的靜態網頁會輸出在public/資料夾下\nGitHub Page相關 在root的.gitignore 要加上 public/ git init public folder cd public git init git remote add origin https://github.com/username/my-hugo-site.git push to github git add . git commit -m \u0026#34;Deploy Hugo site\u0026#34; git branch -M main git push -f origin main Note 若是網站有更新過後 要回到root 並重跑\nhugo -D 之後重複step 3.\n(不用在git init, 即使hugo -D 會更新public folder的內容 但不是全部刪除 所以第一次的git init 還是能track)\nMarkDown相關 \u0026gt;## MarkDown相關\n段落標題，如上\n### 段落內的小區塊\n段落內的小區塊 #### 段落的段落\n段落的段落 **就是粗體** *就是斜體*\n就是粗體 就是斜體\n+ 列表的Fu\n列表的Fu 其他有需要再去查吧 https://markdown.tw/\n後記 大致修改完成 也順過流程了\n","date":"2022-09-28T14:24:26+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220928_blog%E6%93%8D%E4%BD%9C%E6%89%8B%E5%86%8A.md/","title":"Blog操作手冊"},{"content":"from cmoney.client import CMoneyDownloader host_addr = \u0026#39;192.168.1.56\u0026#39; dl = CMoneyDownloader(host_addr) event_df = await dl.query(\u0026#39;日個股事件\u0026#39;, start=\u0026#39;20150101\u0026#39;) import pandas as pd import numpy as np import matplotlib.pyplot as plt company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] company_event.columns Index(['日期', '股票代號', '股票名稱', '月營收公告', '財報公告', '除息日', '除權日', '法說會', '減資前', '減資後', '股東會', '申報轉讓', '庫藏股', '注意股票', '新股上市', '人事異動', '停資', '停券', '最後回補日', '今日事件數', 'RTIME'], dtype='object') company_event.loc[~company_event[\u0026#39;減資前\u0026#39;].isna(), [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]] company_event.columns 400張以上大戶持股比例數據異常\ncompany_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) , [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 import pandas as pd # Example DataFrame with datetime data = {\u0026#39;date\u0026#39;: [\u0026#39;2024-12-12\u0026#39;, \u0026#39;2024-12-18\u0026#39;, \u0026#39;2024-12-25\u0026#39;, \u0026#39;2024-12-26\u0026#39;]} df = pd.DataFrame(data) df[\u0026#39;date\u0026#39;] = pd.to_datetime(df[\u0026#39;date\u0026#39;]) # Transform to the Friday of that week df[\u0026#39;friday_of_week\u0026#39;] = df[\u0026#39;date\u0026#39;] + pd.offsets.Week(weekday=4) print(df) date friday_of_week 0 2024-12-12 2024-12-13 1 2024-12-18 2024-12-20 2 2024-12-25 2024-12-27 3 2024-12-26 2024-12-27 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) TJP = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/threeJuridicalPerson.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;,\u0026#39;外資持股比率(%)\u0026#39;,\u0026#39;投信持股比率(%)\u0026#39;, \u0026#39;自營商持股比率(%)\u0026#39;]) TJP = TJP[TJP[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] TJP.sort_values(\u0026#39;日期\u0026#39;, inplace=True) TJP.reset_index(drop=True, inplace=True) TJP.columns Index(['日期', '股票代號', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)'], dtype='object') margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) margin_df = margin_df[margin_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] margin_df.sort_values(\u0026#39;日期\u0026#39;, inplace=True) margin_df.reset_index(drop=True, inplace=True) margin_df.columns Index(['日期', '股票代號', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)'], dtype='object') SUB_TICKERS ['2059', '3529', '2383', '2330', '8069', '5274', '3008', '2454', '3533'] sub = weekly_depostie[(weekly_depostie[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;]))] agg = sub.groupby(\u0026#39;日期\u0026#39;)[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() 400張以上比率sum agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() # 100張以上 agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0100001-0200000\u0026#39;, \u0026#39;0200001-0400000\u0026#39;,\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 5張以下 sum agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0000001-0000999\u0026#39;, \u0026#39;0001000-0005000\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) agg weekly_depostie[\u0026#39;持股分級\u0026#39;].unique() price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].str.contains(r\u0026#39;^\\d{4}$\u0026#39;)] # price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].str.contains(r\u0026#39;^\\d{4}$\u0026#39;)] price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) 支撐突破 from scipy.signal import argrelextrema def groupby_extrema(df): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, \u0026#39;收盤價\u0026#39;].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, \u0026#39;收盤價\u0026#39;].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(groupby_extrema) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3881079495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(groupby_extrema) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 price_df.reset_index(drop=True, inplace=True) ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_min(df): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, \u0026#39;收盤價\u0026#39;].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, \u0026#39;收盤價\u0026#39;].values, index=local_min_indices) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(groupby_extrema_min) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3402733562.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(groupby_extrema_min) price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]!=\u0026#39;3008\u0026#39;)\u0026amp; (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 price_df.reset_index(drop=True, inplace=True) price_df[price_df[\u0026#39;signal\u0026#39;]==1] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg = agg.merge(price_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg = agg.merge(TJP, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg = agg.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) company_event.columns Index(['日期', '股票代號', '股票名稱', '月營收公告', '財報公告', '除息日', '除權日', '法說會', '減資前', '減資後', '股東會', '申報轉讓', '庫藏股', '注意股票', '新股上市', '人事異動', '停資', '停券', '最後回補日', '今日事件數', 'RTIME', '日期_dt', 'friday_of_week', 'adjust_week'], dtype='object') agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg.columns Index(['日期', '股票代號', '佔集保庫存數比例(%)', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'hold_120Days_winrate', 'max_comparisons_larger', 'local_maxima', 'signal', 'min_comparisons_smaller', 'local_minima', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)', 'friday_of_week', '減資前', '新股上市', 'adjust_week'], dtype='object') agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg.columns Index(['日期', '股票代號', '佔集保庫存數比例(%)', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'hold_120Days_winrate', 'max_comparisons_larger', 'local_maxima', 'signal', 'min_comparisons_smaller', 'local_minima', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)', 'friday_of_week', '減資前', '新股上市', 'adjust_week'], dtype='object') 過去一段時間週集保變化 vs 後續一段時間return 絕對變化的% 期間的震盪程度 時間分成5份 每一個時間點的平均return / precision import pandas as pd from sklearn.model_selection import TimeSeriesSplit def split_by_timeframe(data, date_col, n_splits): \u0026#34;\u0026#34;\u0026#34; Splits time series data into equal time-based chunks. Args: data (pd.DataFrame): Time series data. date_col (str): Column name containing datetime values. n_splits (int): Number of splits. Returns: list: A list of dataframes, each corresponding to a split. \u0026#34;\u0026#34;\u0026#34; # Ensure datetime format data[date_col] = pd.to_datetime(data[date_col]) # Sort by date data = data.sort_values(by=date_col) # Compute timeframe boundaries start_date = data[date_col].min() end_date = data[date_col].max() timeframe = (end_date - start_date) / n_splits timeframes = [start_date + i * timeframe for i in range(n_splits + 1)] # Split data by timeframes splits = [ data[(data[date_col] \u0026gt;= timeframes[i]) \u0026amp; (data[date_col] \u0026lt; timeframes[i + 1])] for i in range(n_splits) ] return splits # Example usage data = pd.DataFrame({ \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2023-01-01\u0026#39;, periods=100, freq=\u0026#39;D\u0026#39;), # Random irregular time series \u0026#39;value\u0026#39;: range(100) }) splits = split_by_timeframe(data, date_col=\u0026#39;date\u0026#39;, n_splits=5) # Print the results for i, split in enumerate(splits): print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;date\u0026#39;].min()} to {split[\u0026#39;date\u0026#39;].max()}\u0026#34;) Split 1: 20 rows, from 2023-01-01 00:00:00 to 2023-01-20 00:00:00 Split 2: 20 rows, from 2023-01-21 00:00:00 to 2023-02-09 00:00:00 Split 3: 20 rows, from 2023-02-10 00:00:00 to 2023-03-01 00:00:00 Split 4: 20 rows, from 2023-03-02 00:00:00 to 2023-03-21 00:00:00 Split 5: 19 rows, from 2023-03-22 00:00:00 to 2023-04-09 00:00:00 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=5) # Print the results for i, split in enumerate(splits): print(split[\u0026#39;hold_20Days_ret\u0026#39;].mean()) print(split[\u0026#39;hold_20Days_winrate\u0026#39;].mean()) print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) 0.020042361220259826 0.5847362514029181 Split 1: 891 rows, from 2015-05-08 00:00:00 to 2017-03-31 00:00:00 0.011071535202021886 0.5230078563411896 Split 2: 891 rows, from 2017-04-07 00:00:00 to 2019-02-27 00:00:00 0.03613439907321296 0.6285072951739619 Split 3: 891 rows, from 2019-03-08 00:00:00 to 2021-01-22 00:00:00 0.017309024770151112 0.5108820160366552 Split 4: 882 rows, from 2021-01-29 00:00:00 to 2022-12-16 00:00:00 0.044214360887047124 0.5861678004535147 Split 5: 882 rows, from 2022-12-23 00:00:00 to 2024-11-08 00:00:00 週集保 高or 低於 月線, 半年線 後續return (不用要求每一黨都可以work 找出能用的ticker就好) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) 因為新股發行/減資等 把有調整的week 其週集保的變化 set 0 agg[agg[\u0026#39;adjust_week\u0026#39;]==1].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[agg[\u0026#39;adjust_week\u0026#39;]==1].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) agg.loc[agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;佔集保庫存數比例(%)\u0026#39;, \u0026#39;週集保月線\u0026#39;, \u0026#39;週集保半年線\u0026#39;]] agg[\u0026#39;週集保diff\u0026#39;].describe() agg.columns return_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] qcut 依據數量做group 但有幾個點要注意, 每個分類的出現時間點不明 我要怎麼讓特定group set signal = 1來判斷個時間點的signal 數 \u0026amp; return? def groupcut(df, col): comcode = df[\u0026#39;股票代號\u0026#39;].iloc[-1] df[f\u0026#39;qcut_{comcode}\u0026#39;] = pd.qcut(df[col], 10) benchmark_df = df[return_cols].mean() # res = df.groupby(f\u0026#39;qcut_{comcode}\u0026#39;)[return_cols].mean() - benchmark_df res = df.groupby(f\u0026#39;qcut_{comcode}\u0026#39;)[return_cols].mean() return res import pandas as pd import numpy as np # Create a sample DataFrame with random data np.random.seed(42) data = pd.DataFrame({\u0026#39;value\u0026#39;: np.random.uniform(-0.2, 0.2, 100)}) # Define the range and bins bins = np.arange(-0.1, 0.1 + 0.05, 0.05) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {i}\u0026#39; for i in range(1, len(bins))] # Group labels # Categorize the data into groups data[\u0026#39;group\u0026#39;] = pd.cut(data[\u0026#39;value\u0026#39;], bins=bins, labels=labels, include_lowest=True) print(data.head()) import pandas as pd import numpy as np # Create a sample DataFrame with random data np.random.seed(42) data = pd.DataFrame({\u0026#39;value\u0026#39;: np.random.uniform(-0.2, 0.3, 100)}) # Extended range for example # Define the range and bins bins = np.arange(-0.1, 0.1 + 0.05, 0.05) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {i}\u0026#39; for i in range(1, len(bins))] # Group labels # Categorize the data into groups, including out-of-range values data[\u0026#39;group\u0026#39;] = pd.cut( data[\u0026#39;value\u0026#39;], bins=bins, labels=labels, include_lowest=True, right=False # Left-inclusive bins ) # Handle values outside the bins data[\u0026#39;group\u0026#39;] = data[\u0026#39;group\u0026#39;].cat.add_categories([\u0026#39;Outliers\u0026#39;]) # Add \u0026#39;Outliers\u0026#39; as a category data[\u0026#39;group\u0026#39;].fillna(\u0026#39;Outliers\u0026#39;, inplace=True) # Assign out-of-range values to \u0026#39;Outliers\u0026#39; print(data.head()) # Define the range and bins bins = np.arange(-10, 10, 1) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {bins[i - 1]:.2f}\u0026#39; for i in range(1, len(bins))] # Group labels labels ['Group -10.00', 'Group -9.00', 'Group -8.00', 'Group -7.00', 'Group -6.00', 'Group -5.00', 'Group -4.00', 'Group -3.00', 'Group -2.00', 'Group -1.00', 'Group 0.00', 'Group 1.00', 'Group 2.00', 'Group 3.00', 'Group 4.00', 'Group 5.00', 'Group 6.00', 'Group 7.00', 'Group 8.00'] agg[\u0026#39;週集保diff4week\u0026#39;].describe() count 4.410000e+03 mean 9.682553e-04 std 1.172644e+00 min -7.130000e+00 25% -5.199995e-01 50% -9.834766e-07 75% 5.599985e-01 max 5.129999e+00 Name: 週集保diff4week, dtype: float64 agg[\u0026#39;group\u0026#39;] = pd.cut( agg[\u0026#39;週集保diff4week\u0026#39;], bins=bins, labels=labels, include_lowest=True, right=False # Left-inclusive bins ) agg[\u0026#39;group\u0026#39;] = agg[\u0026#39;group\u0026#39;].cat.add_categories([\u0026#39;Outliers\u0026#39;]) # Add \u0026#39;Outliers\u0026#39; as a category agg[\u0026#39;group\u0026#39;].fillna(\u0026#39;Outliers\u0026#39;, inplace=True) # Assign out-of-range values to \u0026#39;Outliers\u0026#39; /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3887867593.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. agg['group'].fillna('Outliers', inplace=True) # Assign out-of-range values to 'Outliers' agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;3, return_cols].mean() hold_5Days_ret 0.009619 hold_10Days_ret 0.023788 hold_20Days_ret 0.022823 hold_60Days_ret 0.132806 hold_120Days_ret 0.216323 dtype: float64 winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg[return_cols].mean() hold_5Days_ret 0.006679 hold_10Days_ret 0.013289 hold_20Days_ret 0.025638 hold_60Days_ret 0.077952 hold_120Days_ret 0.160038 dtype: float64 for i in range(0, 6): print(f\u0026#39;週集保diff4week\u0026gt;={i}\u0026#39;, \u0026#39;-\u0026#39;*50) print(agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=i, return_cols].mean()) print(agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=i, winrate_cols].mean()) 週集保diff4week\u0026gt;=0 -------------------------------------------------- hold_5Days_ret 0.006911 hold_10Days_ret 0.014504 hold_20Days_ret 0.027247 hold_60Days_ret 0.077227 hold_120Days_ret 0.162232 dtype: float64 hold_5Days_winrate 0.525740 hold_10Days_winrate 0.555353 hold_20Days_winrate 0.569476 hold_60Days_winrate 0.610023 hold_120Days_winrate 0.658770 dtype: float64 週集保diff4week\u0026gt;=1 -------------------------------------------------- hold_5Days_ret 0.006452 hold_10Days_ret 0.014195 hold_20Days_ret 0.028679 hold_60Days_ret 0.084416 hold_120Days_ret 0.181973 dtype: float64 hold_5Days_winrate 0.520000 hold_10Days_winrate 0.533333 hold_20Days_winrate 0.576296 hold_60Days_winrate 0.616296 hold_120Days_winrate 0.699259 dtype: float64 週集保diff4week\u0026gt;=2 -------------------------------------------------- hold_5Days_ret 0.007483 hold_10Days_ret 0.019430 hold_20Days_ret 0.029827 hold_60Days_ret 0.089183 hold_120Days_ret 0.189969 dtype: float64 hold_5Days_winrate 0.513228 hold_10Days_winrate 0.529101 hold_20Days_winrate 0.603175 hold_60Days_winrate 0.603175 hold_120Days_winrate 0.777778 dtype: float64 週集保diff4week\u0026gt;=3 -------------------------------------------------- hold_5Days_ret 0.009619 hold_10Days_ret 0.023788 hold_20Days_ret 0.022823 hold_60Days_ret 0.132806 hold_120Days_ret 0.216323 dtype: float64 hold_5Days_winrate 0.531915 hold_10Days_winrate 0.553191 hold_20Days_winrate 0.659574 hold_60Days_winrate 0.702128 hold_120Days_winrate 0.808511 dtype: float64 週集保diff4week\u0026gt;=4 -------------------------------------------------- hold_5Days_ret -0.012338 hold_10Days_ret -0.000531 hold_20Days_ret -0.027299 hold_60Days_ret 0.185005 hold_120Days_ret 0.252875 dtype: float64 hold_5Days_winrate 0.294118 hold_10Days_winrate 0.294118 hold_20Days_winrate 0.470588 hold_60Days_winrate 0.764706 hold_120Days_winrate 0.882353 dtype: float64 週集保diff4week\u0026gt;=5 -------------------------------------------------- hold_5Days_ret -0.050694 hold_10Days_ret -0.098042 hold_20Days_ret -0.118287 hold_60Days_ret 0.251046 hold_120Days_ret 0.330517 dtype: float64 hold_5Days_winrate 0.0 hold_10Days_winrate 0.0 hold_20Days_winrate 0.0 hold_60Days_winrate 1.0 hold_120Days_winrate 1.0 dtype: float64 for i in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): mask = (agg[\u0026#39;股票代號\u0026#39;]==i) print(i, \u0026#39;-\u0026#39;*50) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), return_cols].mean()) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), winrate_cols].mean()) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), winrate_cols].count()) 2059 -------------------------------------------------- hold_5Days_ret 0.027832 hold_10Days_ret 0.052327 hold_20Days_ret 0.060835 hold_60Days_ret 0.086638 hold_120Days_ret 0.114998 dtype: float64 hold_5Days_winrate 0.444444 hold_10Days_winrate 0.555556 hold_20Days_winrate 0.444444 hold_60Days_winrate 0.555556 hold_120Days_winrate 0.444444 dtype: float64 hold_5Days_winrate 9 hold_10Days_winrate 9 hold_20Days_winrate 9 hold_60Days_winrate 9 hold_120Days_winrate 9 dtype: int64 2330 -------------------------------------------------- hold_5Days_ret NaN hold_10Days_ret NaN hold_20Days_ret NaN hold_60Days_ret NaN hold_120Days_ret NaN dtype: float64 hold_5Days_winrate NaN hold_10Days_winrate NaN hold_20Days_winrate NaN hold_60Days_winrate NaN hold_120Days_winrate NaN dtype: float64 hold_5Days_winrate 0 hold_10Days_winrate 0 hold_20Days_winrate 0 hold_60Days_winrate 0 hold_120Days_winrate 0 dtype: int64 2383 -------------------------------------------------- hold_5Days_ret 0.005892 hold_10Days_ret 0.031547 hold_20Days_ret 0.059150 hold_60Days_ret 0.060357 hold_120Days_ret 0.161821 dtype: float64 hold_5Days_winrate 0.514286 hold_10Days_winrate 0.600000 hold_20Days_winrate 0.742857 hold_60Days_winrate 0.571429 hold_120Days_winrate 0.685714 dtype: float64 hold_5Days_winrate 35 hold_10Days_winrate 35 hold_20Days_winrate 35 hold_60Days_winrate 35 hold_120Days_winrate 35 dtype: int64 2454 -------------------------------------------------- hold_5Days_ret -0.002074 hold_10Days_ret 0.012793 hold_20Days_ret 0.113898 hold_60Days_ret 0.236901 hold_120Days_ret 0.328099 dtype: float64 hold_5Days_winrate 0.5 hold_10Days_winrate 0.5 hold_20Days_winrate 0.5 hold_60Days_winrate 1.0 hold_120Days_winrate 1.0 dtype: float64 hold_5Days_winrate 2 hold_10Days_winrate 2 hold_20Days_winrate 2 hold_60Days_winrate 2 hold_120Days_winrate 2 dtype: int64 3008 -------------------------------------------------- hold_5Days_ret 0.047004 hold_10Days_ret 0.079946 hold_20Days_ret 0.001695 hold_60Days_ret -0.054823 hold_120Days_ret -0.057345 dtype: float64 hold_5Days_winrate 0.666667 hold_10Days_winrate 1.000000 hold_20Days_winrate 0.333333 hold_60Days_winrate 0.333333 hold_120Days_winrate 0.666667 dtype: float64 hold_5Days_winrate 3 hold_10Days_winrate 3 hold_20Days_winrate 3 hold_60Days_winrate 3 hold_120Days_winrate 3 dtype: int64 3529 -------------------------------------------------- hold_5Days_ret 0.020865 hold_10Days_ret 0.033990 hold_20Days_ret 0.028309 hold_60Days_ret 0.061575 hold_120Days_ret 0.118578 dtype: float64 hold_5Days_winrate 0.631579 hold_10Days_winrate 0.631579 hold_20Days_winrate 0.578947 hold_60Days_winrate 0.736842 hold_120Days_winrate 0.736842 dtype: float64 hold_5Days_winrate 19 hold_10Days_winrate 19 hold_20Days_winrate 19 hold_60Days_winrate 19 hold_120Days_winrate 19 dtype: int64 3533 -------------------------------------------------- hold_5Days_ret 0.001765 hold_10Days_ret 0.003480 hold_20Days_ret -0.001786 hold_60Days_ret 0.061982 hold_120Days_ret 0.120031 dtype: float64 hold_5Days_winrate 0.489796 hold_10Days_winrate 0.469388 hold_20Days_winrate 0.571429 hold_60Days_winrate 0.530612 hold_120Days_winrate 0.795918 dtype: float64 hold_5Days_winrate 49 hold_10Days_winrate 49 hold_20Days_winrate 49 hold_60Days_winrate 49 hold_120Days_winrate 49 dtype: int64 5274 -------------------------------------------------- hold_5Days_ret -0.003093 hold_10Days_ret -0.001091 hold_20Days_ret -0.005808 hold_60Days_ret 0.174683 hold_120Days_ret 0.356038 dtype: float64 hold_5Days_winrate 0.500000 hold_10Days_winrate 0.441176 hold_20Days_winrate 0.558824 hold_60Days_winrate 0.823529 hold_120Days_winrate 0.941176 dtype: float64 hold_5Days_winrate 34 hold_10Days_winrate 34 hold_20Days_winrate 34 hold_60Days_winrate 34 hold_120Days_winrate 34 dtype: int64 8069 -------------------------------------------------- hold_5Days_ret 0.011655 hold_10Days_ret 0.028562 hold_20Days_ret 0.068309 hold_60Days_ret 0.091415 hold_120Days_ret 0.217771 dtype: float64 hold_5Days_winrate 0.500000 hold_10Days_winrate 0.526316 hold_20Days_winrate 0.631579 hold_60Days_winrate 0.473684 hold_120Days_winrate 0.789474 dtype: float64 hold_5Days_winrate 38 hold_10Days_winrate 38 hold_20Days_winrate 38 hold_60Days_winrate 38 hold_120Days_winrate 38 dtype: int64 8069, 2383 agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=0, winrate_cols].mean() hold_5Days_winrate 0.525740 hold_10Days_winrate 0.555353 hold_20Days_winrate 0.569476 hold_60Days_winrate 0.610023 hold_120Days_winrate 0.658770 dtype: float64 agg.groupby(\u0026#39;group\u0026#39;)[return_cols].mean() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3754709820.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[return_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Model 上線標準 - 同期大盤年化報酬的2倍(扣除手續費) \u0026amp; mdd \u0026lt; -40% \u0026amp; PnL 沒有創新高的期間\u0026lt;3y 今年 : 2個可以上線的model\n一個project 2個月\n產業surey 前10大產業market cap, 做基本面/籌碼面指標加總 -\u0026gt; 找出領先指標 建立投組\n美股產業也可以做\nagg.groupby(\u0026#39;group\u0026#39;)[return_cols].count() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/635314126.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[return_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg.groupby(\u0026#39;group\u0026#39;)[winrate_cols].mean() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/432786995.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } qcut_res = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupcut(df, \u0026#39;週集保diff4week\u0026#39;)) qcut_res.loc[\u0026#39;2383\u0026#39;] mask1 = (agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;1.958) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;2.986) agg.loc[mask1 \u0026amp; mask2, return_cols].mean() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): splits = split_by_timeframe(agg[agg[\u0026#39;股票代號\u0026#39;]==ticker], date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() print(ticker, \u0026#39;-\u0026#39;*50) print(split_res) # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) 5274, 2383 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;5274\u0026#39;, \u0026#39;2383\u0026#39;]), return_cols].mean() hold_5Days_ret 0.008201 hold_10Days_ret 0.016249 hold_20Days_ret 0.031963 hold_60Days_ret 0.101030 hold_120Days_ret 0.199245 dtype: float64 agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=3), return_cols].mean() hold_5Days_ret 0.010208 hold_10Days_ret 0.021064 hold_20Days_ret 0.039608 hold_60Days_ret 0.115359 hold_120Days_ret 0.198587 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), return_cols].mean() hold_5Days_ret 0.008892 hold_10Days_ret 0.029993 hold_20Days_ret 0.063918 hold_60Days_ret 0.076749 hold_120Days_ret 0.191766 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), winrate_cols].mean() hold_5Days_winrate 0.506849 hold_10Days_winrate 0.561644 hold_20Days_winrate 0.684932 hold_60Days_winrate 0.520548 hold_120Days_winrate 0.739726 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), \u0026#39;signal\u0026#39;] = 1 qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.left \u0026gt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.right \u0026lt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] top10_index = qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10].index top10_index = qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.left \u0026gt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10].index top10_index for i in top10_index: print(i[1].left) # agg[\u0026#39;signal\u0026#39;] = 0 for i in top10_index: mask1 = (agg[\u0026#39;股票代號\u0026#39;]==i[0]) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;i[1].left) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;i[1].right) agg.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) splits[0][\u0026#39;日期\u0026#39;].dt.strftime(\u0026#39;%Y%m%d\u0026#39;) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res 若是更簡單的 大戶持股比例在 月/半年線上 下 agg.columns agg[\u0026#39;signal\u0026#39;] = 0 mask = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保月線\u0026#39;]) agg.loc[mask, \u0026#39;signal\u0026#39;] = 1 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res 融資維持率 agg.columns qcut_res = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupcut(df, \u0026#39;融資維持率(%)\u0026#39;)) 融資成本(推估) = [昨日融資成本 * (昨日資餘 - 今日資限償 - 資賣)] + [今日資買 * 今日收盤 / 今日資餘] 假設今天沒有任何買入 則今日融資成本一樣\n若是今日有買入 且今日股價較高 -\u0026gt; 會拉高融資成本\n反過來 今日有買入 但今日股價較低 -\u0026gt; 會拉低融資成本\n又或是我們該這樣想 有四種狀況\n今日資餘 \u0026gt; 昨日資餘 (=今日資買 \u0026gt; (今日資線嘗 + 資賣)), 今日收盤 \u0026gt; 昨日融資成本 = 融資成本上升,\n但這還要對比收盤價上升的幅度 以我的感覺來說 收盤價變動的幅度較大 融資成本跟不太上 然而當股價上漲的時候 融資維持率會增加 反過來股價下跌的時候融資維持率會降\n既然如此 那融資維持率低 是否可以解讀成\n股價大幅下殺 但是對應的資餘 減少沒那麼快 所以才有低的融資維持率\n要是股價大幅下殺 假設昨日以前的資餘全部出清 只剩今天資買的 那融資維持率就會是標準的166%對吧\nfor ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot() ax1.set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;close price\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成本(推估)\u0026#39;], label=\u0026#39;margin cost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資維持率(%)\u0026#39;], label=\u0026#39;margin maintence\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.legend() ax2.legend() 融資維持率 = 持有股票市值 / 融資金額 × 100%\n先處理不同時期融資成數 -\u0026gt; 其實我搞錯了 -\u0026gt; 我懂問題了 其實法規早在2015年前融資成數就是6成了 只是Cmoney 在計算融資維持率的時候用的是 \u0026lsquo;收盤價(未還原)\u0026rsquo; 但我們是用還原收盤\n才會出現成數是階梯狀 那其實是發放股利後 股價做調整的樣貌(這也是為什麼台積電近期成數階梯這麼密的原因 他們改成每季發放股利)\n所以拿維持率與還原股價去對 會對不上的原因\n融資維持率 = 收盤價 / (融資成本 * 融資成數) * 100%\n融資成數 = (收盤價 / 融資維持率/100) / 融資成本\nagg[\u0026#39;融資成數\u0026#39;] = agg[\u0026#39;收盤價\u0026#39;] / agg[\u0026#39;融資維持率(%)\u0026#39;] / agg[\u0026#39;融資成本(推估)\u0026#39;] / 100 for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot() ax1.set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;close price\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成本(推估)\u0026#39;], label=\u0026#39;margin cost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成數\u0026#39;], label=\u0026#39;margin maintence\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.legend() ax2.legend() 現在確定 融資成數是相同的 那問題就回到原本的 如果融資成本與收盤價差越大 越可能出現極端的融資維持率 但這樣 融資成本不能和還原後的股價做直接比較\nagg[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((agg[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 winrate = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg[[\u0026#39;維持率反推融資平均損益\u0026#39;]+return_cols].corr() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[[\u0026#39;維持率反推融資平均損益\u0026#39;]+winrate].corr() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;維持率反推融資平均損益\u0026#39;] + return_cols].sort_values(\u0026#39;維持率反推融資平均損益\u0026#39;, ascending=False).iloc[0:10] # agg[\u0026#39;signal\u0026#39;] = 0 mask = (agg[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) agg.loc[mask, \u0026#39;signal\u0026#39;] = 1 agg.to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/intermid/combine_signal.ftr\u0026#39;) agg[agg[\u0026#39;signal\u0026#39;]==1].sort_values(\u0026#39;融資維持率(%)\u0026#39;) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 日個股事件表 週集保要處理增減資 SUB_TICKERS 籌碼 Done mask1 = (agg[\u0026#39;融資成本(推估)\u0026#39;]\u0026gt;agg[\u0026#39;收盤價\u0026#39;]) mask2 = (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026gt; 167) agg[mask2].sort_values(\u0026#39;維持率反推融資平均損益\u0026#39;, ascending=False) qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;, ascending=False).iloc[0:10] agg.loc[agg[\u0026#39;signal\u0026#39;]==1, return_cols].mean() mask1 = (agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;4.644) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;2.986) agg.loc[mask1 \u0026amp; mask2, return_cols].mean() agg.reset_index(drop=True, inplace=True) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): print(ticker, \u0026#39;-\u0026#39;*50) print(agg.groupby(f\u0026#39;qcut_{ticker}\u0026#39;)[return_cols].mean()) benchmark_df = import pandas as pd # Example DataFrame (df1) df1 = pd.DataFrame({ \u0026#39;A\u0026#39;: [1, 2, 3], \u0026#39;B\u0026#39;: [4, 5, 6], \u0026#39;C\u0026#39;: [7, 8, 9] }) # Single-row DataFrame (df2) df2 = pd.DataFrame({\u0026#39;A\u0026#39;: [1], \u0026#39;B\u0026#39;: [2], \u0026#39;C\u0026#39;: [3]}) # Subtracting df2 from df1 result = df1 - df2.iloc[0] print(result) agg.groupby(\u0026#39;qcut\u0026#39;)[return_cols].mean() agg[\u0026#39;週集保signal\u0026#39;] = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保月線\u0026#39;]).apply(lambda x : 1 if x else 0) agg[\u0026#39;週集保signal\u0026#39;] = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保半年線\u0026#39;]).apply(lambda x : 1 if x else 0) return_cols = [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;] return_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg.groupby([\u0026#39;股票代號\u0026#39;])[return_cols].mean() agg.groupby([\u0026#39;股票代號\u0026#39;])[winrate_cols].mean() agg[agg[\u0026#39;週集保signal\u0026#39;]==1].groupby([\u0026#39;year\u0026#39;, \u0026#39;股票代號\u0026#39;])[return_cols].count().plot() margin_cols = [\u0026#39;資買\u0026#39;, \u0026#39;資賣\u0026#39;, \u0026#39;資現償\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;資增減\u0026#39;, \u0026#39;資限\u0026#39;, \u0026#39;券買\u0026#39;, \u0026#39;券賣\u0026#39;, \u0026#39;券賣金額(千)\u0026#39;, \u0026#39;券現償\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券增減\u0026#39;, \u0026#39;資券相抵\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;資使用率\u0026#39;, \u0026#39;券使用率\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;借券賣出\u0026#39;, \u0026#39;借券賣出金額(千)\u0026#39;, \u0026#39;借券賣出還券\u0026#39;, \u0026#39;借券賣出調整\u0026#39;, \u0026#39;借券賣出庫存異動\u0026#39;, \u0026#39;借券賣出餘額\u0026#39;, \u0026#39;借券可使用額度\u0026#39;, \u0026#39;借券系統當日借券\u0026#39;, \u0026#39;借券系統當日還券\u0026#39;, \u0026#39;借券系統借券餘額異動\u0026#39;, \u0026#39;借券系統借券餘額\u0026#39;, \u0026#39;借券系統借券餘額市值\u0026#39;, \u0026#39;證商營業處所當日借券\u0026#39;, \u0026#39;證商營業處所當日還券\u0026#39;, \u0026#39;證商營業處所借券餘額異動\u0026#39;, \u0026#39;證商營業處所借券餘額\u0026#39;, \u0026#39;證商營業處所借券餘額市值\u0026#39;, \u0026#39;借貸專戶當日借券\u0026#39;, \u0026#39;借貸專戶當日還券\u0026#39;, \u0026#39;借貸專戶借券餘額異動\u0026#39;, \u0026#39;借貸專戶借券餘額\u0026#39;, \u0026#39;借貸專戶借券餘額市值\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;, \u0026#39;整體維持率(%)\u0026#39;] agg[return_cols + margin_cols] agg[return_cols + margin_cols].corr().sort_values(\u0026#39;hold_20Days_ret\u0026#39;, ascending=False) import pandas as pd import numpy as np def calculate_rolling_correlation(df, col1, col2): \u0026#34;\u0026#34;\u0026#34; Calculate rolling correlation between two columns using a fixed window (weekly). Parameters: - df (pd.DataFrame): DataFrame containing the data - col1 (str): Name of the first column - col2 (str): Name of the second column - window (int): Rolling window size (e.g., 4 for four weeks) Returns: - pd.Series: Rolling correlation series \u0026#34;\u0026#34;\u0026#34; if col1 not in df.columns or col2 not in df.columns: raise ValueError(\u0026#34;Specified columns are not in the DataFrame.\u0026#34;) # Ensure data is aligned to avoid misalignment # df = df[[col1, col2]].dropna() # Use rolling window with custom function rolling_corr = df[col1].expanding(min_periods=52).corr(df[col2]) return rolling_corr sub = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] def expanding_corr(df): # 因為是未來的return 做corr 要小心data leakage # 故在signal的部分 要shift df[\u0026#39;margin_corr_5\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_5Days_ret\u0026#39;]).shift(1) df[\u0026#39;margin_short_corr_5\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_5Days_ret\u0026#39;]).shift(1) df[\u0026#39;margin_corr_20\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_20Days_ret\u0026#39;]).shift(4) df[\u0026#39;margin_short_corr_20\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_20Days_ret\u0026#39;]).shift(4) return df agg = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(expanding_corr) agg.reset_index(drop=True, inplace=True) mask1 = (agg[\u0026#39;margin_corr_20\u0026#39;] \u0026lt; -0.15) \u0026amp; (agg[\u0026#39;margin_short_corr_20\u0026#39;] \u0026gt; -0.15) agg[\u0026#39;20_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;20_ticker_pool\u0026#39;] = 1 agg.columns agg[agg[\u0026#39;20_ticker_pool\u0026#39;]==1].groupby(\u0026#39;日期\u0026#39;)[\u0026#39;股票代號\u0026#39;].count().plot() sub[\u0026#39;test_Corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, 100) sub[\u0026#39;test_Corr\u0026#39;].plot() ssub = sub[[\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;test_Corr\u0026#39;]].iloc[-30:-4].iloc[-20::] ssub[[\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;]].corr() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): print(\u0026#39;\u0026#39;*5,ticker) print(agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker), [\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;] ].corr()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(SUB_TICKERS): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] sub[\u0026#39;margin_corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;) sub[\u0026#39;short_corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;) fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;margin_corr\u0026#39;], label=\u0026#39;margin corr\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;short_corr\u0026#39;], label=\u0026#39;margin short corr\u0026#39;) axes[i].legend() # ax2 = axes[i].twinx() # ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) # ax2.legend() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20200101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} Maintenance short selling\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融券維持率(%)\u0026#39;], label=\u0026#39;Maintenance short selling\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;orange\u0026#39;) ax3 = ax1.twinx() ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券餘\u0026#39;], label=\u0026#39;short selling\u0026#39;, color=\u0026#39;black\u0026#39;) # ax3 = ax1.twinx() # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) 週集保固定禮拜五收盤後(禮拜六凌晨)會更新資料 故訊號為禮拜一開盤前初 操作應該是禮拜一收盤時買賣\nagg sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;)] sub[\u0026#39;bins\u0026#39;] = pd.qcut(sub[\u0026#39;融券維持率(%)\u0026#39;], 5) sub.groupby(\u0026#39;bins\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].describe() sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;)] sub[\u0026#39;short_bin\u0026#39;] = pd.qcut(sub[\u0026#39;融券維持率(%)\u0026#39;], 5) sub[\u0026#39;long_bin\u0026#39;] = pd.qcut(sub[\u0026#39;融資維持率(%)\u0026#39;], 5) sub.groupby([\u0026#39;short_bin\u0026#39;, \u0026#39;long_bin\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].describe() res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192.888) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161.379), \u0026#39;hold_20Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,\u0026#39;hold_20Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192.888) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161.379), \u0026#39;hold_20Days_winrate\u0026#39;].mean() res res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194.643) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159.762), \u0026#39;hold_20Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,\u0026#39;hold_20Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194.643) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159.762), \u0026#39;hold_20Days_winrate\u0026#39;].mean() res agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161), \u0026#39;signal\u0026#39;] = 1 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159), \u0026#39;signal\u0026#39;] = 1 這種方式去切threshold 雖然可以得到很好的result 但總是有overfitting的感覺 我依據全部可得的資料切出來的 是不是可以更genral一些\n像是 融券維持率(%)在expanding window下的80分位數上, 融資維持率(%)在expanding window下的20分位數下\nsub = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] sub[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=16).quantile(q=0.8) sub.loc[sub[\u0026#39;日期\u0026#39;]\u0026gt;=\u0026#39;20230901\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;]] sub.loc[sub[\u0026#39;融券維持率(%)\u0026#39;].isna(), [\u0026#39;日期\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;]] sub[\u0026#39;融券維持率(%)\u0026#39;].plot() sub[[\u0026#39;日期\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;]] def quantile_cut(df): df[\u0026#39;融券維持率(%)_h\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=16).quantile(0.8) df[\u0026#39;融資維持率(%)_l\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=16).quantile(0.2) return df agg.reset_index(drop=True, inplace=True) agg = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_cut) agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 mask1 = (agg[\u0026#39;margin_corr_20\u0026#39;] \u0026lt; -0.15) \u0026amp; (agg[\u0026#39;margin_short_corr_20\u0026#39;] \u0026gt; -0.15) agg[\u0026#39;20_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;20_ticker_pool\u0026#39;] = 1 mask1 = (agg[\u0026#39;margin_corr_5\u0026#39;] \u0026lt; -0.1) \u0026amp; (agg[\u0026#39;margin_short_corr_5\u0026#39;] \u0026gt; -0.1) agg[\u0026#39;5_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;5_ticker_pool\u0026#39;] = 1 agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;5_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;5_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp agg.reset_index(drop=True, inplace=True) agg.columns sub_cols = [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;佔集保庫存數比例(%)\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;總市值(億)\u0026#39;, \u0026#39;漲跌停\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;, \u0026#39;整體維持率(%)\u0026#39;, \u0026#39;margin_corr_5\u0026#39;, \u0026#39;margin_short_corr_5\u0026#39;, \u0026#39;margin_corr_20\u0026#39;, \u0026#39;margin_short_corr_20\u0026#39;, \u0026#39;20_ticker_pool\u0026#39;, \u0026#39;融券維持率(%)_h\u0026#39;, \u0026#39;融資維持率(%)_l\u0026#39;, \u0026#39;signal\u0026#39;, \u0026#39;5_ticker_pool\u0026#39;] agg[sub_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/intermid/9tickers_margin.ftr\u0026#39;) ticker = \u0026#39;5274\u0026#39; tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp agg.columns[-60:-30] for ticker in [\u0026#39;3533\u0026#39;, \u0026#39;5274\u0026#39;]: sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} short \u0026gt; q0.8, long \u0026lt; q0.2\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券餘\u0026#39;], label=\u0026#39;Maintenance short selling quantity\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;資餘\u0026#39;], label=\u0026#39;Maintenance margin quantity\u0026#39;, color=\u0026#39;green\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券資比\u0026#39;], label=\u0026#39;Maintenance margin quantity\u0026#39;, color=\u0026#39;blue\u0026#39;) # ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融券維持率(%)\u0026#39;], label=\u0026#39;Maintenance short selling\u0026#39;) # ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資維持率(%)\u0026#39;], label=\u0026#39;Maintenance margin\u0026#39;) indices = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) ] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} weekly depostie less 5\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;佔集保庫存數比例(%)\u0026#39;], label=\u0026#39;weekly depost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;black\u0026#39;) # ax3 = ax1.twinx() # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) ] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} weekly depostie over 400\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;佔集保庫存數比例(%)\u0026#39;], label=\u0026#39;weekly depost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;black\u0026#39;) ax3 = ax1.twinx() ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""},{"content":"from IPython.display import HTML import pandas as pd def display_df_as_html(df): \u0026#34;\u0026#34;\u0026#34;Automatically display DataFrame as an HTML table.\u0026#34;\u0026#34;\u0026#34; display(HTML(df.to_html())) # Apply function to all DataFrame outputs pd.DataFrame._repr_html_ = display_df_as_html company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event.tail() 日期 股票代號 股票名稱 月營收公告 財報公告 除息日 除權日 法說會 減資前 減資後 ... \\ 9891130 20241225 9951 皇田 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891131 20241225 9955 佳龍 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891132 20241225 9958 世紀鋼 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891133 20241225 9960 邁達康 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891134 20241225 9962 有益 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 申報轉讓 庫藏股 注意股票 新股上市 人事異動 停資 停券 最後回補日 今日事件數 RTIME 9891130 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 510725547 9891131 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891132 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891133 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891134 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 [5 rows x 21 columns] ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""},{"content":"import pandas as pd import numpy as np import matplotlib.pyplot as plt pd.options.display.float_format = \u0026#39;{:.4f}\u0026#39;.format SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] 月營收 mon_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/monthly/monthly_revenue.ftr\u0026#39;) mon_df = mon_df[mon_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] mon_df = mon_df[~mon_df[\u0026#39;公告日\u0026#39;].isna()] mon_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(mon_df[\u0026#39;公告日\u0026#39;]) mon_df.sort_values(\u0026#39;公告日_dt\u0026#39;, inplace=True, ascending=True) mon_df.reset_index(drop=True, inplace=True) 收盤價 price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price0050 = price_df[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;0050\u0026#39;] price0050[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price0050[\u0026#39;日期\u0026#39;]) price0050.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price0050.reset_index(drop=True, inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050['日期_dt'] = pd.to_datetime(price0050['日期']) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050.sort_values('日期_dt', inplace=True, ascending=True) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;last_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(n + 2) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price0050 = price0050.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2395123834.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price0050 = price0050.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price_df = price_df.merge(price0050, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_0050\u0026#39;)) 融資 margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) price_df = price_df.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((price_df[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 週集保 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) price_df = price_df.merge(agg, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res = res.merge(price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False), how=\u0026#39;left\u0026#39;, left_on=(\u0026#39;股票代號\u0026#39;), right_on=(\u0026#39;股票代號\u0026#39;), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_baseline\u0026#39;)) res[\u0026#39;diff_ret\u0026#39;] = res[\u0026#39;hold_20Days_ret\u0026#39;] - res[\u0026#39;hold_20Days_ret_baseline\u0026#39;] for ticker in SUB_TICKERS: print(res.loc[res[\u0026#39;股票代號\u0026#39;]==ticker, [\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;diff_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;signal_count\u0026#39;]]) cut 股票代號 diff_ret hold_20Days_winrate signal_count 0 (-7.381, -0.0403] 2059 0.0074 0.5253 297 9 (-0.0403, -0.0209] 2059 -0.0003 0.5539 612 18 (-0.0209, -0.0112] 2059 -0.0105 0.5278 612 27 (-0.0112, -0.00457] 2059 0.0055 0.6105 493 36 (-0.00457, 0.000588] 2059 -0.0055 0.5302 464 45 (0.000588, 0.0064] 2059 -0.0165 0.5211 474 54 (0.0064, 0.0132] 2059 -0.0066 0.5511 470 63 (0.0132, 0.0236] 2059 0.0048 0.5630 579 72 (0.0236, 0.0459] 2059 0.0154 0.4592 368 81 (0.0459, 6.477] 2059 -0.0042 0.4848 330 cut 股票代號 diff_ret hold_20Days_winrate signal_count 5 (-7.381, -0.0403] 3529 0.0076 0.5681 639 14 (-0.0403, -0.0209] 3529 0.0057 0.5977 430 23 (-0.0209, -0.0112] 3529 0.0197 0.6016 251 32 (-0.0112, -0.00457] 3529 -0.0115 0.4541 185 41 (-0.00457, 0.000588] 3529 -0.0182 0.4237 118 50 (0.000588, 0.0064] 3529 0.0286 0.5524 105 59 (0.0064, 0.0132] 3529 0.0080 0.5088 114 68 (0.0132, 0.0236] 3529 0.0233 0.6364 132 77 (0.0236, 0.0459] 3529 -0.0101 0.5516 368 86 (0.0459, 6.477] 3529 -0.0001 0.5152 924 cut 股票代號 diff_ret hold_20Days_winrate signal_count 2 (-7.381, -0.0403] 2383 -0.0163 0.5163 337 11 (-0.0403, -0.0209] 2383 -0.0155 0.6022 450 20 (-0.0209, -0.0112] 2383 0.0208 0.5992 509 29 (-0.0112, -0.00457] 2383 0.0109 0.6031 456 38 (-0.00457, 0.000588] 2383 -0.0056 0.5408 845 47 (0.000588, 0.0064] 2383 0.0085 0.5935 866 56 (0.0064, 0.0132] 2383 0.0112 0.5605 860 65 (0.0132, 0.0236] 2383 -0.0099 0.4559 601 74 (0.0236, 0.0459] 2383 0.0042 0.4363 314 83 (0.0459, 6.477] 2383 0.0311 0.5296 287 cut 股票代號 diff_ret hold_20Days_winrate signal_count 1 (-7.381, -0.0403] 2330 -0.0388 0.4315 788 10 (-0.0403, -0.0209] 2330 0.0045 0.5472 424 19 (-0.0209, -0.0112] 2330 -0.0026 0.5797 364 28 (-0.0112, -0.00457] 2330 0.0076 0.6842 741 37 (-0.00457, 0.000588] 2330 -0.0034 0.6103 839 46 (0.000588, 0.0064] 2330 -0.0058 0.5833 768 55 (0.0064, 0.0132] 2330 -0.0045 0.6129 824 64 (0.0132, 0.0236] 2330 0.0027 0.6062 617 73 (0.0236, 0.0459] 2330 0.0221 0.6621 441 82 (0.0459, 6.477] 2330 -0.0033 0.5289 484 cut 股票代號 diff_ret hold_20Days_winrate signal_count 8 (-7.381, -0.0403] 8069 -0.0083 0.4898 786 17 (-0.0403, -0.0209] 8069 0.0377 0.6390 313 26 (-0.0209, -0.0112] 8069 0.0130 0.5763 321 35 (-0.0112, -0.00457] 8069 -0.0059 0.5538 316 44 (-0.00457, 0.000588] 8069 0.0035 0.5430 256 53 (0.000588, 0.0064] 8069 -0.0044 0.5430 291 62 (0.0064, 0.0132] 8069 0.0173 0.6335 352 71 (0.0132, 0.0236] 8069 0.0035 0.5276 381 80 (0.0236, 0.0459] 8069 -0.0176 0.4596 594 89 (0.0459, 6.477] 8069 -0.0020 0.5591 744 cut 股票代號 diff_ret hold_20Days_winrate signal_count 7 (-7.381, -0.0403] 5274 0.0202 0.6256 438 16 (-0.0403, -0.0209] 5274 -0.0428 0.5028 179 25 (-0.0209, -0.0112] 5274 -0.0071 0.6331 169 34 (-0.0112, -0.00457] 5274 0.0072 0.6823 192 43 (-0.00457, 0.000588] 5274 0.0079 0.6508 126 52 (0.000588, 0.0064] 5274 0.0453 0.7287 129 61 (0.0064, 0.0132] 5274 0.0348 0.7063 160 70 (0.0132, 0.0236] 5274 0.0197 0.6702 188 79 (0.0236, 0.0459] 5274 0.0036 0.6394 416 88 (0.0459, 6.477] 5274 -0.0205 0.5478 712 cut 股票代號 diff_ret hold_20Days_winrate signal_count 4 (-7.381, -0.0403] 3008 0.0105 0.4967 449 13 (-0.0403, -0.0209] 3008 0.0191 0.6574 788 22 (-0.0209, -0.0112] 3008 0.0128 0.6181 720 31 (-0.0112, -0.00457] 3008 0.0030 0.5690 652 40 (-0.00457, 0.000588] 3008 -0.0275 0.4177 565 49 (0.000588, 0.0064] 3008 -0.0320 0.3731 453 58 (0.0064, 0.0132] 3008 -0.0063 0.4907 377 67 (0.0132, 0.0236] 3008 0.0032 0.5278 485 76 (0.0236, 0.0459] 3008 -0.0048 0.5455 627 85 (0.0459, 6.477] 3008 0.0236 0.5260 365 cut 股票代號 diff_ret hold_20Days_winrate signal_count 3 (-7.381, -0.0403] 2454 -0.0014 0.5589 433 12 (-0.0403, -0.0209] 2454 -0.0161 0.4977 663 21 (-0.0209, -0.0112] 2454 0.0020 0.6016 728 30 (-0.0112, -0.00457] 2454 -0.0285 0.4292 643 39 (-0.00457, 0.000588] 2454 0.0040 0.5687 466 48 (0.000588, 0.0064] 2454 0.0165 0.6183 503 57 (0.0064, 0.0132] 2454 -0.0053 0.5879 512 66 (0.0132, 0.0236] 2454 0.0106 0.6314 681 75 (0.0236, 0.0459] 2454 -0.0067 0.5551 726 84 (0.0459, 6.477] 2454 -0.0048 0.5616 276 cut 股票代號 diff_ret hold_20Days_winrate signal_count 6 (-7.381, -0.0403] 3533 -0.0589 0.2222 36 15 (-0.0403, -0.0209] 3533 0.0147 0.6366 344 24 (-0.0209, -0.0112] 3533 0.0306 0.6929 521 33 (-0.0112, -0.00457] 3533 -0.0040 0.5455 528 42 (-0.00457, 0.000588] 3533 -0.0483 0.3852 527 51 (0.000588, 0.0064] 3533 -0.0313 0.4356 606 60 (0.0064, 0.0132] 3533 0.0060 0.5898 529 69 (0.0132, 0.0236] 3533 0.0259 0.6311 534 78 (0.0236, 0.0459] 3533 0.0143 0.4725 345 87 (0.0459, 6.477] 3533 0.1118 0.8333 78 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window): date_numeric = window[:, 0] # Extract the first column (date_numeric) value = window[:, 1] # Extract the second column (value) x_diff = date_numeric[-1] - date_numeric[0] # Time difference y_diff = value[-1] - value[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size][[\u0026#39;date_numeric\u0026#39;, \u0026#39;value\u0026#39;]].to_numpy() slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] # Time difference y_diff = window_df[\u0026#39;value\u0026#39;].iloc[-1] - window_df[\u0026#39;value\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 price_df[\u0026#39;date_numeric\u0026#39;] = (price_df[\u0026#39;日期_dt\u0026#39;] - price_df[\u0026#39;日期_dt\u0026#39;].min()).dt.days price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'date_numeric'], dtype='object') # 120日本益比的切線斜率 # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] - 1 # Time difference y_diff = (window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[-1] - window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] )/ window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) df[f\u0026#39;slope_{window_size}\u0026#39;] = [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment df[f\u0026#39;slope_{window_size}\u0026#39;] = df[f\u0026#39;slope_{window_size}\u0026#39;].shift(1) # 本益比用今天的收盤價去計算 明天才知道result return df # Add slope to the DataFrame # price_df[\u0026#39;slope\u0026#39;] = rolling_slope(price_df, window_size=5) for w in [5, 10, 20, 60, 120]: price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) price_df.loc[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;本益比(近四季)\u0026#39;, \u0026#39;slope_5\u0026#39;, \u0026#39;date_numeric\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ((25.6-29.5)/29.5)/5 -0.026440677966101684 for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).mean().reset_index(drop=True) price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).sum().reset_index(drop=True) ret_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: print(price_df.loc[price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]\u0026gt;0, ret_cols].mean()) # price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=5)) w = 60 j = 60 for ticker in SUB_TICKERS: tmp = price_df[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;] = tmp[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean() ax1.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;], label=\u0026#39;PE\u0026#39;) ax2 = ax1.twinx() ax2.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;],color=\u0026#39;green\u0026#39;, label=\u0026#39;PE slope\u0026#39;) ax3 = ax1.twinx() ax3.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;收盤價\u0026#39;],color=\u0026#39;orange\u0026#39;, label=\u0026#39;price\u0026#39;) ax1.set_title(ticker) indices = tmp.loc[(tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt;= 0.02), \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) ax1.legend() ax2.legend() def vector_backtest(df): # input: df, 需要有signa columns, output : [[trade_data1], [trade_data2], ...] (list中包含多個list) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4] # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; com_code = group[\u0026#39;股票代號\u0026#39;].iloc[-1] start_date = group[\u0026#39;日期\u0026#39;].iloc[0] end_date = group[\u0026#39;日期\u0026#39;].iloc[-1] buy_price = group[\u0026#39;次日收盤價\u0026#39;].iloc[0] sell_price = group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1] ret = (sell_price/buy_price) - 1 holding_days = len(group) event_list = [com_code, start_date, end_date, buy_price, sell_price, ret, holding_days] event_list_all.append(event_list) return event_list_all print(f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;) slope_60_rolling_60_SUM price_df[\u0026#39;本益比_rolling5\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean().reset_index(drop=True) price_df[\u0026#39;本益比_rolling20\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(20).mean().reset_index(drop=True) 看起來本益比切線斜率 累積增加\u0026gt;0 對捕捉上升趨勢還不錯 price_df.reset_index(drop=True, inplace=True) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) # | (price_df[f\u0026#39;slope_{w}\u0026#39;] \u0026lt; price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) \u0026amp; (price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt;= 0) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/312944587.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), ret_cols].mean() hold_5Days_ret 0.0080 hold_10Days_ret 0.0148 hold_20Days_ret 0.0310 hold_60Days_ret 0.0807 hold_120Days_ret 0.1454 dtype: float64 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3156983121.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) | (price_df[\u0026#39;last_60Days_ret_0050\u0026#39;] \u0026lt;= -0.1) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/95528996.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.columns[-140:-120] Index(['收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME'], dtype='object') price_df[\u0026#39;20MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(20).mean().reset_index(drop=True) price_df[\u0026#39;60MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(60).mean().reset_index(drop=True) price_df[\u0026#39;200MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(200).mean().reset_index(drop=True) Local Minima, maxima from scipy.signal import argrelextrema def groupby_extrema(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df[\u0026#39;local_maxima\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima.loc[max_comparisons_larger_idx].values.tolist() df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_sup(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # print(local_minima) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) print(min_comparisons_smaller_idx) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df[\u0026#39;local_minima\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima.loc[min_comparisons_smaller_idx].values.tolist() df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) [np.int64(647), np.int64(727), np.int64(916), np.int64(1198), np.int64(1314), np.int64(1388), np.int64(1801), np.int64(2151), np.int64(2358), np.int64(2549), np.int64(2999), np.int64(3101), np.int64(3290), np.int64(4081), np.int64(4249), np.int64(4392), np.int64(4752)] [np.int64(388), np.int64(960), np.int64(1098), np.int64(1504), np.int64(1633), np.int64(1760), np.int64(2227), np.int64(2331), np.int64(2519), np.int64(2642), np.int64(2956), np.int64(3136), np.int64(3325), np.int64(3444), np.int64(3646), np.int64(3675), np.int64(3740), np.int64(4131), np.int64(4369), np.int64(4417), np.int64(4677), np.int64(4757), np.int64(4858), np.int64(4902), np.int64(5019), np.int64(5178), np.int64(5262), np.int64(5381), np.int64(5749), np.int64(6100), np.int64(6562), np.int64(6835), np.int64(6941), np.int64(7077), np.int64(7161)] [np.int64(799), np.int64(1099), np.int64(2475), np.int64(2879), np.int64(2999), np.int64(3090), np.int64(3347), np.int64(3469), np.int64(3750), np.int64(4090), np.int64(4196), np.int64(4293), np.int64(4472), np.int64(4599), np.int64(4716), np.int64(4844), np.int64(5076), np.int64(5188), np.int64(5317), np.int64(5535), np.int64(5556), np.int64(5818), np.int64(5899), np.int64(6264), np.int64(6430), np.int64(6451), np.int64(6795), np.int64(6893)] [np.int64(380), np.int64(624), np.int64(749), np.int64(1254), np.int64(1441), np.int64(1629), np.int64(1859), np.int64(2107), np.int64(2236), np.int64(2638), np.int64(2710), np.int64(2894), np.int64(2993), np.int64(3240), np.int64(3541), np.int64(3848), np.int64(4122), np.int64(4240), np.int64(4639), np.int64(4952), np.int64(5171), np.int64(5380), np.int64(5662), np.int64(5684), np.int64(5735)] [np.int64(345), np.int64(628), np.int64(1091), np.int64(1513), np.int64(1715), np.int64(1910), np.int64(1946), np.int64(2023), np.int64(2086), np.int64(2190), np.int64(2438), np.int64(2813), np.int64(3199), np.int64(3389), np.int64(3426), np.int64(3459), np.int64(3681), np.int64(3819), np.int64(3965), np.int64(4515), np.int64(4766), np.int64(4890), np.int64(5135), np.int64(5230), np.int64(5349), np.int64(5502)] [np.int64(374), np.int64(465), np.int64(598), np.int64(624), np.int64(1017), np.int64(1173), np.int64(1588), np.int64(1710), np.int64(1939), np.int64(2157), np.int64(2286), np.int64(2761), np.int64(2816), np.int64(3084), np.int64(3111), np.int64(3293)] [np.int64(653), np.int64(953), np.int64(1046), np.int64(1150), np.int64(1469), np.int64(1596), np.int64(1628), np.int64(1706), np.int64(1826), np.int64(1922), np.int64(2362), np.int64(2518), np.int64(2731), np.int64(3190), np.int64(3637), np.int64(3741), np.int64(3757), np.int64(3873), np.int64(4145)] [np.int64(318), np.int64(534), np.int64(796), np.int64(1031), np.int64(1068), np.int64(1110), np.int64(1153), np.int64(1328), np.int64(1394), np.int64(1716), np.int64(1835), np.int64(2269)] [np.int64(765), np.int64(952), np.int64(1659), np.int64(1962), np.int64(2577), np.int64(3066), np.int64(3310), np.int64(3626), np.int64(3773), np.int64(3796), np.int64(3961), np.int64(4354), np.int64(4559), np.int64(4661), np.int64(4841)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3911248321.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, \u0026#39;收盤價\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2624941152.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, '收盤價')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, \u0026#39;收盤價\u0026#39;)) [np.int64(204), np.int64(287), np.int64(387), np.int64(690), np.int64(886), np.int64(1026), np.int64(1259), np.int64(1299), np.int64(1369), np.int64(1471), np.int64(1508), np.int64(1530), np.int64(1583), np.int64(1742), np.int64(2029), np.int64(2081), np.int64(2308), np.int64(2343), np.int64(2501), np.int64(2543), np.int64(2626), np.int64(2713), np.int64(2737), np.int64(2794), np.int64(3012), np.int64(3029), np.int64(3053), np.int64(3107), np.int64(3157), np.int64(3169), np.int64(3267), np.int64(3314), np.int64(3345), np.int64(3420), np.int64(3452), np.int64(3475), np.int64(3494), np.int64(3681), np.int64(3819), np.int64(4028), np.int64(4159), np.int64(4193), np.int64(4316), np.int64(4338), np.int64(4367), np.int64(4410), np.int64(4563), np.int64(4706), np.int64(4746), np.int64(4790)] [np.int64(40), np.int64(133), np.int64(185), np.int64(258), np.int64(317), np.int64(343), np.int64(386), np.int64(431), np.int64(615), np.int64(904), np.int64(943), np.int64(1029), np.int64(1069), np.int64(1159), np.int64(1224), np.int64(1537), np.int64(1562), np.int64(1646), np.int64(1704), np.int64(1757), np.int64(1797), np.int64(1823), np.int64(1875), np.int64(1896), np.int64(1942), np.int64(2037), np.int64(2083), np.int64(2110), np.int64(2125), np.int64(2149), np.int64(2193), np.int64(2253), np.int64(2277), np.int64(2491), np.int64(2553), np.int64(2592), np.int64(2616), np.int64(2641), np.int64(2704), np.int64(2912), np.int64(2930), np.int64(2948), np.int64(3039), np.int64(3102), np.int64(3284), np.int64(3333), np.int64(3400), np.int64(3470), np.int64(3508), np.int64(3668), np.int64(3695), np.int64(3713), np.int64(3951), np.int64(4018), np.int64(4088), np.int64(4291), np.int64(4359), np.int64(4375), np.int64(4390), np.int64(4593), np.int64(4802), np.int64(4895), np.int64(4960), np.int64(5006), np.int64(5243), np.int64(5336), np.int64(5389), np.int64(5488), np.int64(5564), np.int64(5962), np.int64(6047), np.int64(6086), np.int64(6169), np.int64(6187), np.int64(6219), np.int64(6310), np.int64(6506), np.int64(6636), np.int64(6754), np.int64(6786), np.int64(6856), np.int64(6991), np.int64(7030), np.int64(7068), np.int64(7145), np.int64(7262), np.int64(7367), np.int64(7573)] [np.int64(96), np.int64(147), np.int64(203), np.int64(240), np.int64(401), np.int64(468), np.int64(587), np.int64(715), np.int64(789), np.int64(1042), np.int64(1190), np.int64(1235), np.int64(1283), np.int64(1432), np.int64(1463), np.int64(1489), np.int64(1530), np.int64(1632), np.int64(1646), np.int64(1669), np.int64(1894), np.int64(1986), np.int64(2041), np.int64(2101), np.int64(2167), np.int64(2263), np.int64(2449), np.int64(2622), np.int64(2822), np.int64(2847), np.int64(2976), np.int64(3006), np.int64(3078), np.int64(3287), np.int64(3307), np.int64(3349), np.int64(3437), np.int64(3543), np.int64(3629), np.int64(3673), np.int64(3693), np.int64(3710), np.int64(3737), np.int64(3820), np.int64(3890), np.int64(4051), np.int64(4140), np.int64(4164), np.int64(4193), np.int64(4274), np.int64(4496), np.int64(4577), np.int64(4681), np.int64(4806), np.int64(4827), np.int64(5003), np.int64(5026), np.int64(5273), np.int64(5294), np.int64(5333), np.int64(5387), np.int64(5430), np.int64(5477), np.int64(5508), np.int64(5742), np.int64(5760), np.int64(5812), np.int64(5844), np.int64(5999), np.int64(6123), np.int64(6411), np.int64(6484), np.int64(6574), np.int64(6600), np.int64(6702), np.int64(6727), np.int64(6777), np.int64(6840), np.int64(6911)] [np.int64(215), np.int64(229), np.int64(247), np.int64(390), np.int64(584), np.int64(692), np.int64(789), np.int64(833), np.int64(875), np.int64(1018), np.int64(1058), np.int64(1121), np.int64(1136), np.int64(1196), np.int64(1216), np.int64(1234), np.int64(1317), np.int64(1588), np.int64(1622), np.int64(1729), np.int64(1818), np.int64(1829), np.int64(2054), np.int64(2120), np.int64(2193), np.int64(2220), np.int64(2295), np.int64(2394), np.int64(2421), np.int64(2459), np.int64(2476), np.int64(2493), np.int64(2673), np.int64(2817), np.int64(2850), np.int64(2959), np.int64(3232), np.int64(3282), np.int64(3419), np.int64(3494), np.int64(3594), np.int64(3608), np.int64(3664), np.int64(3754), np.int64(3793), np.int64(3845), np.int64(4071), np.int64(4196), np.int64(4214), np.int64(4229), np.int64(4275), np.int64(4324), np.int64(4611), np.int64(4961), np.int64(4997), np.int64(5096), np.int64(5125), np.int64(5173), np.int64(5233), np.int64(5367), np.int64(5429), np.int64(5549), np.int64(5607)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) [np.int64(86), np.int64(106), np.int64(213), np.int64(429), np.int64(450), np.int64(573), np.int64(592), np.int64(639), np.int64(718), np.int64(1006), np.int64(1066), np.int64(1146), np.int64(1188), np.int64(1217), np.int64(1241), np.int64(1277), np.int64(1472), np.int64(1580), np.int64(1650), np.int64(1679), np.int64(1775), np.int64(1854), np.int64(1965), np.int64(2041), np.int64(2244), np.int64(2354), np.int64(2387), np.int64(2428), np.int64(2507), np.int64(2524), np.int64(2648), np.int64(2708), np.int64(2769), np.int64(2828), np.int64(2868), np.int64(3122), np.int64(3142), np.int64(3332), np.int64(3355), np.int64(3370), np.int64(3423), np.int64(3438), np.int64(3644), np.int64(3742), np.int64(3858), np.int64(3932), np.int64(3950), np.int64(3985), np.int64(4114), np.int64(4136), np.int64(4154), np.int64(4174), np.int64(4271), np.int64(4461), np.int64(4573), np.int64(4602), np.int64(4671), np.int64(4805), np.int64(4847), np.int64(4963), np.int64(4982), np.int64(5085), np.int64(5457), np.int64(5559), np.int64(5594)] [np.int64(63), np.int64(113), np.int64(163), np.int64(232), np.int64(292), np.int64(338), np.int64(349), np.int64(424), np.int64(436), np.int64(451), np.int64(520), np.int64(531), np.int64(640), np.int64(671), np.int64(1002), np.int64(1117), np.int64(1129), np.int64(1300), np.int64(1344), np.int64(1529), np.int64(1554), np.int64(1632), np.int64(1645), np.int64(1661), np.int64(1738), np.int64(1798), np.int64(1881), np.int64(1923), np.int64(2102), np.int64(2175), np.int64(2214), np.int64(2246), np.int64(2363), np.int64(2593), np.int64(2704), np.int64(2759), np.int64(2812), np.int64(3083), np.int64(3175), np.int64(3245), np.int64(3313)] [np.int64(123), np.int64(149), np.int64(219), np.int64(260), np.int64(280), np.int64(608), np.int64(637), np.int64(727), np.int64(813), np.int64(894), np.int64(921), np.int64(997), np.int64(1090), np.int64(1115), np.int64(1235), np.int64(1275), np.int64(1370), np.int64(1384), np.int64(1482), np.int64(1502), np.int64(1654), np.int64(1826), np.int64(1838), np.int64(1865), np.int64(1896), np.int64(2014), np.int64(2086), np.int64(2190), np.int64(2208), np.int64(2302), np.int64(2471), np.int64(2513), np.int64(2569), np.int64(2583), np.int64(2681), np.int64(2821), np.int64(2838), np.int64(3028), np.int64(3096), np.int64(3264), np.int64(3308), np.int64(3377), np.int64(3513), np.int64(3590), np.int64(3668), np.int64(3728), np.int64(3814), np.int64(3853), np.int64(3908), np.int64(4095)] [np.int64(38), np.int64(114), np.int64(255), np.int64(302), np.int64(314), np.int64(335), np.int64(674), np.int64(778), np.int64(922), np.int64(1079), np.int64(1276), np.int64(1310), np.int64(1342), np.int64(1486), np.int64(1781), np.int64(1968), np.int64(2036), np.int64(2161), np.int64(2174), np.int64(2223), np.int64(2255), np.int64(2276), np.int64(2310), np.int64(2328), np.int64(2444), np.int64(2476), np.int64(2498), np.int64(2520), np.int64(2659), np.int64(2826)] [np.int64(59), np.int64(146), np.int64(176), np.int64(272), np.int64(395), np.int64(475), np.int64(553), np.int64(571), np.int64(659), np.int64(901), np.int64(960), np.int64(1056), np.int64(1080), np.int64(1112), np.int64(1139), np.int64(1491), np.int64(1530), np.int64(1555), np.int64(1733), np.int64(1809), np.int64(1925), np.int64(1940), np.int64(2024), np.int64(2035), np.int64(2156), np.int64(2201), np.int64(2304), np.int64(2334), np.int64(2395), np.int64(2528), np.int64(2578), np.int64(2629), np.int64(2651), np.int64(2763), np.int64(2811), np.int64(2831), np.int64(2908), np.int64(2930), np.int64(3133), np.int64(3285), np.int64(3345), np.int64(3451), np.int64(3500), np.int64(3582), np.int64(3611), np.int64(3837), np.int64(3914), np.int64(3948), np.int64(4087), np.int64(4230), np.int64(4327), np.int64(4414), np.int64(4433), np.int64(4510), np.int64(4587), np.int64(4607), np.int64(4700), np.int64(4783), np.int64(4799), np.int64(4828), np.int64(4944), np.int64(5083)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/785596803.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, '收盤價')) price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;] ) strategy Logic price_df.reset_index(drop=True, inplace=True) # 近一個月 400張大戶 增加2%以上 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4079245513.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 mask = (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[mask, \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/857034293.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1700805250.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[((price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/168196673.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;20MA\u0026#39;] \u0026gt;= price_df[\u0026#39;200MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3380416550.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/939178834.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/357474516.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 組合上下行 price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/950731482.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3623880085.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1110539843.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt; 0.02), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3456730543.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026gt;= price_df[\u0026#39;60MA\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1528418423.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026lt; price_df[\u0026#39;60MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/538384737.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) # price_df[price_df[\u0026#39;signal\u0026#39;]==1] NOW price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) # (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5)| (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[((price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;0.02) \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3722245375.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 簡易PnL模擬 res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2059', '3008'], dtype='object') from collections import Counter def vector_backtest_ratio(df, buyholddays): \u0026#39;\u0026#39;\u0026#39; for backtest PnL ratio index_count 算目前在該ticker 上累積bet的數量 \u0026#39;\u0026#39;\u0026#39; df.reset_index(drop=True, inplace=True) df[\u0026#39;ratio\u0026#39;] = 0 signal_idx = df[df[\u0026#39;signal\u0026#39;]==1].index all_holding_idx = [] for idx in signal_idx: adding_idx = [i for i in range(idx, idx+buyholddays) if i \u0026lt; len(df)] all_holding_idx += adding_idx df.loc[all_holding_idx, \u0026#39;signal\u0026#39;] = 1 return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 10)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/517245478.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 10)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 20)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2754594864.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 20)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 60)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3282921495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 60)) price_df.reset_index(drop=True, inplace=True) res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/317971430.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2330', '8069', '3008'], dtype='object') 如果是想要抄底的策略 holding 天數可能要拉長到可以等他漲回去 # price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;signal\u0026#39;]==1)].iloc[-20::] res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1410/2410 0.5850622406639004 2454, 2383, 2059, 3008 done res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;slope\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;]\u0026lt;=-0.05), \u0026#39;signal\u0026#39;] = 1 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;slope\u0026#39;]\u0026gt;=0.1), \u0026#39;signal\u0026#39;] = 1 ret_cols = [f\u0026#39;hold_{n}Days_ret\u0026#39; for n in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{n}Days_winrate\u0026#39; for n in [5, 10, 20, 60, 120]] price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() - price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PE price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;本益比(近四季)\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'cut', 'signal'], dtype='object') price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) income_stat_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/quarterly/quarterlyIncomeStatementSingal.ftr\u0026#39;) income_stat_df = income_stat_df[income_stat_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] income_stat_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(income_stat_df[\u0026#39;公告日期\u0026#39;]) income_stat_df.sort_values(\u0026#39;年季\u0026#39;, inplace=True, ascending=True) income_stat_df.reset_index(drop=True, inplace=True) income_stat_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import re income_stat_df.columns = [re.sub(r\u0026#39;\\s+\u0026#39;, \u0026#39;\u0026#39;, i) for i in income_stat_df.columns] income_stat_df.columns[0:30] Index(['年季', '股票代號', '股票名稱', '市場別', '財報類別', '銷貨收入淨額(千)', '銷貨收入(千)', '銷貨退回(千)', '銷貨折讓(千)', '營業收入淨額(千)', '營業成本(千)', '營業毛利(千)', '聯屬公司間未實現利益(千)', '聯屬公司間已實現利益(千)', '營業毛利淨額(千)', '營業費用(千)', '推銷費用(千)', '管理費用(千)', '研發費用(千)', '預期信用減損損益(千)', '其他營業費用(千)', '其他收益及費損(千)', '其他收益(千)', '其他費損(千)', '營業利益(千)', '營業外收入及支出(千)', '利息收入(千)', '銀行存款利息(千)', '按攤銷後成本衡量之金融資產利息收入(千)', '透過其他綜合損益按公允價值衡量之金融資產利息收入(千)'], dtype='object') income_stat_df.columns[-30::] Index(['國外營運機構淨投資避險中屬有效避險部分之避險工具損益(千)', '與待出售非流動資產直接相關之權益–可能重分類至損益(千)', '透過其他綜合損益按公允價值衡量之債務工具投資未實現評價損益(千)', '避險工具之損益–可能重分類至損益(千)', '採權益法認列關聯企業及合資其他綜合損益之份額–可能重分類至損益(千)', '可能重分類至損益之其他項目(千)', '與可能重分類至損益之項目相關之所得稅(千)', '綜合損益(千)', '稅後純益歸屬(千)', '母公司業主–稅後純益(千)', '非控制權益–稅後純益(千)', '共同控制下前手權益–稅後純益(千)', '綜合損益歸屬(千)', '母公司業主–綜合損益(千)', '非控制權益–綜合損益(千)', '共同控制下前手權益–綜合損益(千)', 'EBITDA(千)', '公告基本每股盈餘(元)', '公告稀釋每股盈餘(元)', '原始每股稅前盈餘(元)', '原始每股稅後盈餘(元)', '原始每股綜合盈餘(元)', '每股稅前盈餘(元)', '每股稅後盈餘(元)', '每股綜合盈餘(元)', '更新日期', '公告日期', '建立日期', 'RTIME', '公告日_dt'], dtype='object') income_stat_df[\u0026#39;母公司業主–稅後純益(千)\u0026#39;] 0 \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; 2 \u0026lt;NA\u0026gt; 3 \u0026lt;NA\u0026gt; 4 1602873 ... 818 4498178 819 25715520 820 2435866 821 247845528 822 1456409 Name: 母公司業主–稅後純益(千), Length: 823, dtype: Int64 不同時間段 適合看得指標也不盡相同 我能不能這個概念 -\u0026gt; 用基本面的變化來作為時間段的區分 像是基本面改善期間 -\u0026gt; 適合的策略\n基本面維持不變時的策略\n股價過度反應/過高過低PE對應的策略\n像是 基本面漲, 股價沒漲 -\u0026gt; 可能已經反應過了, 也可能是還沒反應\n順勢 基本面漲 \u0026amp; 股價也漲\n大盤逆風 基本面漲 但股價大跌 -\u0026gt; 先不要進場 等大盤回穩 or PE到一定程度才進場\n貝氏定理 先把營收, EPS, 對比股價的圖Plot出來 判斷大盤行情 上行, 糾結, 下行 在對比各個features在這些期間之下的表現 ex: 大盤下行的時候 全部訊號都沒用 除了PE跌倒歷史quantile多少時可以買入\u0026hellip;, 上行的時候跟著持有也不用管基本面etc reample + merge EPS forward knowing , cal + resample + merge 1. 先把每一季的EPS做加總(4季 agg) 再藉由shift去假設 能夠完美預測未來N季 再resample 至daily def resample_q_forward(df): # print(df[\u0026#39;股票代號\u0026#39;].iloc[-1]) df = df[~df[\u0026#39;公告日期\u0026#39;].isna()] df = df[~df.duplicated(subset=[\u0026#39;公告日期\u0026#39;])] df[\u0026#39;knowNext0Q\u0026#39;] = df[\u0026#39;每股稅後盈餘(元)\u0026#39;].rolling(4).sum() df.set_index(\u0026#39;公告日_dt\u0026#39;, inplace=True) df = df.resample(\u0026#39;D\u0026#39;).ffill() return df 2. 與股價合併 resample_q_df = combine_df = price_df.merge(resample_q_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) combine_df[\u0026#39;Y_M\u0026#39;] = combine_df[\u0026#39;日期_dt\u0026#39;].dt.year.astype(str) + \u0026#39;_\u0026#39; + combine_df[\u0026#39;日期_dt\u0026#39;].dt.month.astype(str).str.zfill(2) sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub[\u0026#39;PEG_0Q\u0026#39;].describe() count 5167.0000 mean 1.5405 std 2.4577 min -1.0632 25% 0.3917 50% 0.7254 75% 1.6816 max 20.2743 Name: PEG_0Q, dtype: float64 3. 有股價 有完美預測一段時間的EPS -\u0026gt; 就有完美預估的PE 找出該期間的MAX, MIN值 主要是用來繪制河流圖 並shift def find_PE_range(df): \u0026#39;\u0026#39;\u0026#39; groupby 年季, ticker 假設知道未來N季的EPS 對應期間股價的P/E 區間的max, min 應該要用於未來畫本益比河流圖所用 \u0026#39;\u0026#39;\u0026#39; tmp = pd.DataFrame() YM = df[\u0026#39;Y_M\u0026#39;].iloc[-1] Q = df[\u0026#39;年季\u0026#39;].iloc[-1] for i in range(1, 5): tmp.loc[Q, f\u0026#39;{i}_max_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].max() tmp.loc[Q, f\u0026#39;{i}_mean_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].mean() tmp.loc[Q, f\u0026#39;{i}_min_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].min() # tmp.loc[Q, f\u0026#39;{i}_max_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].max() # tmp.loc[Q, f\u0026#39;{i}_mean_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].mean() # tmp.loc[Q, f\u0026#39;{i}_min_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].min() tmp[\u0026#39;Q\u0026#39;] = Q return tmp pe_res = combine_df.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]).apply(find_PE_range).reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/3018702681.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. pe_res = combine_df.groupby(['股票代號', '年季']).apply(find_PE_range).reset_index(drop=False) 用前一季之前的All data 來計算 分位數 # Convert the \u0026#39;quarter\u0026#39; column to a Period with quarterly frequency combine_df[\u0026#39;year\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[:4] # Extract the year (first 4 digits) combine_df[\u0026#39;qtr\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[-2:] # Extract the quarter (last 2 digits) # Create a new column with period as \u0026#39;YYYYQ#\u0026#39; format (like 2000Q4, 2001Q1, etc.) combine_df[\u0026#39;period\u0026#39;] = combine_df[\u0026#39;year\u0026#39;] + \u0026#39;Q\u0026#39; + combine_df[\u0026#39;qtr\u0026#39;].replace({\u0026#39;01\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;02\u0026#39;: \u0026#39;2\u0026#39;, \u0026#39;03\u0026#39;: \u0026#39;3\u0026#39;, \u0026#39;04\u0026#39;: \u0026#39;4\u0026#39;}) # Convert to Pandas Period with quarterly frequency combine_df[\u0026#39;period\u0026#39;] = pd.PeriodIndex(combine_df[\u0026#39;period\u0026#39;], freq=\u0026#39;Q\u0026#39;) def quantile_q(df): i = 0 q_list = df[\u0026#39;period\u0026#39;].unique().tolist() sub_df_list = [] for q in q_list: thisQ = df[df[\u0026#39;period\u0026#39;]==q] lastQ = df[(df[\u0026#39;period\u0026#39;]\u0026gt;(q - 40)) \u0026amp; (df[\u0026#39;period\u0026#39;]\u0026lt;q)] # 20 -\u0026gt; 5y, 12 -\u0026gt; 3y for i in range(0, 5): thisQ[f\u0026#39;q20_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.2) thisQ[f\u0026#39;q40_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.4) thisQ[f\u0026#39;q60_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.6) thisQ[f\u0026#39;q80_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.8) # thisQ[f\u0026#39;q20_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.2) # thisQ[f\u0026#39;q40_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.4) # thisQ[f\u0026#39;q60_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.6) # thisQ[f\u0026#39;q80_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.8) sub_df_list.append(thisQ) new_df = pd.concat(sub_df_list) return new_df res = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_q).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/348048885.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res = combine_df.groupby('股票代號').apply(quantile_q).reset_index(drop=True) res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2008Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x1283cb400\u0026gt; png\r\u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2018Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 4 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q_G\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q_G\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q_G\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q_G\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PEG_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x124c216d0\u0026gt; png\rfor i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;0~20_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;20~40_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;40~60_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;60~80_{i}Q_G\u0026#39; if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;80~100_{i}Q_G\u0026#39; for i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;0~20_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;20~40_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;40~60_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;60~80_{i}Q\u0026#39; if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;80~100_{i}Q\u0026#39; res[res[\u0026#39;cata_0Q\u0026#39;]==\u0026#39;0~20_0Q\u0026#39;] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[[\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_0Q\u0026#39;])[[\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() preview_res[\u0026#39;day_ratio\u0026#39;] = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[\u0026#39;收盤價\u0026#39;].count()/6275 preview_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;20~40_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) # for i in range(0, 5): for i in [0, 4]: # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) hist_obj = ax1.hist(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, bins=100, alpha=0.5 ) color = hist_obj[2][0].get_facecolor() ax1.axvline(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].mean(), ymin=0, ymax=500, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, color=color) ax1.legend() png\rpng\rpng\rpng\rpng\rfrom scipy import stats import numpy as np # Generate some sample data with different lengths data1 = np.random.normal(50, 10, 100) # Dataset 1 data2 = np.random.normal(52, 15, 150) # Dataset 2 # Perform a two-sample t-test assuming equal variances (Student\u0026#39;s t-test) t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\u0026#34;) # Perform Welch\u0026#39;s t-test (does not assume equal variances) t_stat_welch, p_value_welch = stats.ttest_ind(data1, data2, equal_var=False) print(f\u0026#34;Welch\u0026#39;s t-test: t-statistic = {t_stat_welch:.4f}, p-value = {p_value_welch:.4f}\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res tmp = pd.DataFrame() for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: i = 0 t = 1 for days in [5, 10, 20, 60, 120]: data1 = sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values data2 = sub.loc[sub[f\u0026#39;cata_{t}Q\u0026#39;] == f\u0026#39;{quantile}_{t}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}, {quantile}_{t}Q, \u0026#39;hold_{days}Days_ret\u0026#39;\u0026#34;) tmp.loc[f\u0026#39;{quantile}_{i}Q vs {t}Q\u0026#39;, f\u0026#39;hold {days} mean return p-value\u0026#39;] = p_value tmp 有多少 forward 0 在低本益比 但其實用forward 4Q是高本益比\n反之亦然\n這類股價其實是由未來營收所帶動的 也許就是我們想要抓的?\nforward 的優勢就在於 用歷史推估 跟由研調預測得出來的結論有明顯差異 材值得做\nsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;60~80_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;80~100_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res # mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) # mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import numpy as np sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) show_df = pd.DataFrame() for i in np.arange(0.1, 1, 0.1): mask2 = (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026gt;= i) \u0026amp; (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026lt; (i + 0.1)) show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, \u0026#39;count\u0026#39;] = len(sub.loc[mask2]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df = pd.DataFrame() sub = res for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: mask1 = (sub[\u0026#39;cata_4Q\u0026#39;] == f\u0026#39;{quantile}_4Q\u0026#39;) show_df.loc[f\u0026#39;mean_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;precision_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res.columns import pandas as pd import matplotlib.pyplot as plt # Example data with 8 categories data = {\u0026#39;Date\u0026#39;: pd.date_range(start=\u0026#39;2024-01-01\u0026#39;, periods=10, freq=\u0026#39;D\u0026#39;), \u0026#39;Signal\u0026#39;: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0], \u0026#39;Category\u0026#39;: [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]} df = pd.DataFrame(data) # Get unique categories (suppose you have exactly 8 categories) categories = df[\u0026#39;Category\u0026#39;].unique() # Define the number of rows and columns for the subplots n_rows, n_cols = 2, 4 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() # Loop through each category and plot for i, category in enumerate(categories): # Filter DataFrame by category category_df = df[df[\u0026#39;Category\u0026#39;] == category] # Get dates where Signal == 1 for that category signal_dates = category_df.loc[category_df[\u0026#39;Signal\u0026#39;] == 1, \u0026#39;Date\u0026#39;] # Plot vertical lines on the respective subplot axes[i].vlines(x=signal_dates, ymin=0, ymax=1, color=\u0026#39;b\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;Signal {category}\u0026#39;) axes[i].set_title(f\u0026#39;Category {category}\u0026#39;) axes[i].set_ylabel(\u0026#39;Signal\u0026#39;) # Format the x-axis for dates (shared x-axis) axes[i].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter(\u0026#39;%Y-%m-%d\u0026#39;)) axes[i].tick_params(axis=\u0026#39;x\u0026#39;, rotation=45) # Hide empty subplots if any (for cases when the grid is larger than needed) for j in range(i + 1, n_rows * n_cols): fig.delaxes(axes[j]) # Set the xlabel for the subplots in the last row for ax in axes[-n_cols:]: ax.set_xlabel(\u0026#39;Date\u0026#39;) # Adjust layout plt.tight_layout() plt.show() len(res[\u0026#39;股票代號\u0026#39;].unique()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q 0~20\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\r\u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal PEG ver. \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt;= 0.7) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt;= 0.9) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q, PEG 0.7~0.9\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax1.legend() signal_dates = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values ax1.vlines(x=signal_dates, label=\u0026#39;signal\u0026#39;) sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values preview_res.loc[\u0026#39;2330\u0026#39;] res_indexPE = res.merge(IndexPE_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;])) IndexPE_res.columns res_indexPE[\u0026#39;股票代號\u0026#39;].unique() sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20030701\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20101231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20101231\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20191231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] i = 1 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20121231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20240509\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] i = 4 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20161231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20231109\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ticker = sub[\u0026#39;股票代號\u0026#39;].iloc[-1] ax1.set_title(f\u0026#39;Index PE vs {ticker}_forward{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;], label=f\u0026#39;{ticker}_PE_{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;agg_PE_{i}Q\u0026#39;], label=f\u0026#39;index_PE_{i}Q\u0026#39;) ax1.legend() ticker = (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) q = 4 tmp = pd.DataFrame() for i in [2, 4, 6, 8]: signal = (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026gt;res_indexPE[f\u0026#39;agg_PE_{q}Q\u0026#39;]) \u0026amp; (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026lt;res_indexPE[f\u0026#39;q{i}0\u0026#39;]) # tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() # res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].describe() tmp cumsum or rolling min/max + shift 就可以了\ndef rolling_max(df): \u0026#39;\u0026#39;\u0026#39; groupby ticker \u0026#39;\u0026#39;\u0026#39; for i in range(1, 5): df[f\u0026#39;{i}_cummax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].cummax().shift(1) df[f\u0026#39;{i}_cummin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].cummin().shift(1) df[f\u0026#39;{i}_cummean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].expanding().mean().shift(1) df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(20).max().shift(1) df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).min().shift(1) df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).mean().shift(1) df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(12).max().shift(1) df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).min().shift(1) df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).mean().shift(1) df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(40).max().shift(1) df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).min().shift(1) df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).mean().shift(1) return df pe_res = pe_res.groupby(\u0026#39;股票代號\u0026#39;).apply(rolling_max).reset_index(drop=True) # cumsum 至上一季 PE最高值, cumsum 至上一季 PE最低值, rolling 5y 至上一季 PE最高值, rolling 5y 至上一季 PE最低值 pe_res.loc[(pe_res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) , [\u0026#39;年季\u0026#39;, \u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] 把 截至上一季 PE的高低點 算出來後 與股價merge combine_df = combine_df.merge(pe_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), right_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_MINMAX\u0026#39;)) combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;) , [\u0026#39;日期\u0026#39;,\u0026#39;PE_1Q\u0026#39; ,\u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2454\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;knowNext1Q\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;, \u0026#39;1_rolling5ymean_PE\u0026#39;]].dropna() for i in range(1, 5): combine_df[f\u0026#39;knowNext{i}Q_5y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummean_PE\u0026#39;] # 在知曉下一季EPS後 利用過往3季 + 未來1季 去算年度EPS # 在用該EPS 與當下股價計算 預知PE # 期間預知PE的min, max 將獨立出來 combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;1_max_PE\u0026#39;, \u0026#39;1_min_PE\u0026#39;, \u0026#39;1_mean_PE\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] 繪製本益比河流圖時 河流應為過去一段時間的min, max ex : under 知曉下一Q EPS的情況下\n過去10年 所有在知曉下一Q對應的EPS\nmin, max 作為河流 對照如今的 預知PE\n可以try 的財務指標\n存貨(千) 研發費用(千) PPE (不動產相關的變化) 先做圖 在想要怎麼辦\ncombine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] combine_df.columns[180:210] combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub.reset_index(drop=True, inplace=True) def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2)) * (data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9): data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 0 return data signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal).reset_index(drop=True) signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal_reverse).reset_index(drop=True) def vector_backtest_delay_entering(df, delay_days): # prodction ver. # input: df, 需要有signal columns, output : [{trade_data1}, {trade_data2}, ...] (list中包含多個dict) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4](cumsum) # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index ## 想要include 最新持有的狀態 -\u0026gt; 若是最後一個row 的連續持有日期 \u0026gt;=4 (3個訊號 隔日才會買進 目前沒有持有) ## return的計算 要改 if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 用來確認退場reaso # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; if len(group) \u0026lt;= delay_days: # 訊號數不足 不會進場 continue else: group.reset_index(drop=True, inplace=True) group = group.iloc[delay_days::] # extract info from group trading_dict = { \u0026#39;股票代號\u0026#39;: group[\u0026#39;股票代號\u0026#39;].iloc[-1], \u0026#39;買入日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[0], \u0026#39;賣出日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[-1], \u0026#39;買入價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].iloc[0], \u0026#39;賣出價\u0026#39; : group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1], \u0026#39;期間最高價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].max(), \u0026#39;持有天數\u0026#39; : len(group), \u0026#39;持有狀態\u0026#39; : \u0026#39;history\u0026#39;, \u0026#39;return\u0026#39; : (group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1]/group[\u0026#39;次日收盤價\u0026#39;].iloc[0]) - 1, } event_list_all.append(trading_dict) # production情況下 每日最新一個group的狀況不一定 \u0026#39;\u0026#39;\u0026#39; 原本是收盤後跑 下午3點跑 改為開盤前 早上8點跑 這樣昨天的data一定更新好了 故 持有狀態的用詞修改 從buy_tomorrow -\u0026gt; buy_today \u0026#39;\u0026#39;\u0026#39; return event_list_all vector_backtest_delay_entering(sub, 0) res = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) res import pandas as pd import numpy as np # Simulated data with multiple cycles dates = pd.to_datetime([ \u0026#39;2024-01-01\u0026#39;, \u0026#39;2024-01-02\u0026#39;, \u0026#39;2024-01-03\u0026#39;, \u0026#39;2024-01-04\u0026#39;, \u0026#39;2024-01-05\u0026#39;, \u0026#39;2024-01-06\u0026#39;, \u0026#39;2024-01-07\u0026#39;, \u0026#39;2024-01-08\u0026#39;, \u0026#39;2024-01-09\u0026#39;, \u0026#39;2024-01-10\u0026#39;, \u0026#39;2024-01-11\u0026#39;, \u0026#39;2024-01-12\u0026#39;, \u0026#39;2024-01-13\u0026#39;, \u0026#39;2024-01-14\u0026#39;, \u0026#39;2024-01-15\u0026#39;, \u0026#39;2024-01-16\u0026#39;, \u0026#39;2024-01-17\u0026#39;, \u0026#39;2024-01-18\u0026#39;, \u0026#39;2024-01-19\u0026#39;, \u0026#39;2024-01-20\u0026#39; ]) # Simulated P/E ratios data = pd.DataFrame({ \u0026#39;PE_ratio\u0026#39;: [20, 21, 19, 22, 23, 10, 9, 11, 14, 16, 18, 20, 35, 36, 10, 9, 12, 15, 18, 20], \u0026#39;Adj Close\u0026#39;: np.random.randn(len(dates)) * 10 + 100 }, index=dates) # Parameters lower_bound = 10 upper_bound = 35 # Initialize the signal and state data[\u0026#39;Signal\u0026#39;] = 0 data.loc[(data[\u0026#39;PE_ratio\u0026#39;] \u0026lt;= lower_bound), \u0026#39;Signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for i in range(len(data)): pe_ratio = data.iloc[i][\u0026#39;PE_ratio\u0026#39;] if state == 0: # Normal period if pe_ratio \u0026lt;= lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if pe_ratio \u0026gt; lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if pe_ratio \u0026gt;= upper_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 0 state = 0 else: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 print(\u0026#34;Filtered Data with Signals:\u0026#34;) print(data) trading_dict = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) # 整理backtest result code = signal_df[\u0026#39;股票代號\u0026#39;].unique().tolist() res_df = pd.DataFrame() for c in code: tmp = trading_dict[c] tmp_df = pd.DataFrame(tmp) if not tmp_df.empty: res_df = pd.concat([res_df, tmp_df], ignore_index=True) code res_df[\u0026#39;precision\u0026#39;] = res_df[\u0026#39;return\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) res_df[[\u0026#39;return\u0026#39;, \u0026#39;precision\u0026#39;,\u0026#39;持有天數\u0026#39;]].describe() res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe() for i in code: print(i) print(res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==i, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe()) trading_dict[\u0026#39;2059\u0026#39;] sub[\u0026#39;forwardPE\u0026#39;].expanding().std() # combine_df = price_df.merge(resample_mon_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) columns 展示 combine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] # Create subplots without shared axes fig, axes = plt.subplots(3, 3, figsize=(12, 8)) # Flatten the axes array for easy iteration axes = axes.flatten() # Group by \u0026#39;Stock\u0026#39; and plot each group in a separate subplot for ax, (name, group) in zip(axes, combine_df.groupby(\u0026#39;股票代號\u0026#39;)): ax.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;收盤價\u0026#39;], label=\u0026#39;Price\u0026#39;) ax.set_title(name) ax.set_xlabel(\u0026#39;Date\u0026#39;) # ax.set_ylabel(\u0026#39;Price\u0026#39;, color=\u0026#39;blue\u0026#39;) ax.legend(loc=2) # Create a secondary y-axis and plot \u0026#39;Volume\u0026#39; ax2 = ax.twinx() ax2.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;稅後純益率(%)\u0026#39;], label=\u0026#39;net profit ratio\u0026#39;, color=\u0026#39;orange\u0026#39;, alpha=0.6) # ax2.set_ylabel(\u0026#39;monthly rev\u0026#39;, color=\u0026#39;green\u0026#39;) ax2.legend(loc=3) # Set axis colors to match the data they represent ax.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;blue\u0026#39;) ax2.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;green\u0026#39;) # Adjust layout to prevent overlap plt.tight_layout() # Show the plot plt.show() combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;, \u0026#39;近三月合併營收(千)\u0026#39;].plot() combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;] image_2024-08-15_11-38-01.png\rfig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;2317\u0026#39;) ax1.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;近12月累計合併營收(千)\u0026#39;], label=\u0026#39;12m_rev_agg\u0026#39;, color=\u0026#39;orange\u0026#39;) ax1.legend(loc=1) 指標相關聯 我覺得應該不只是財務數據 也有其他的東西但我們無法access\n籌碼相關, 分析師估值等\n但以我目前的情況 應該是做估值 並建立買賣點\n-\u0026gt; 存貨\n大概看了一下 營收的趨勢整體多為向上，股價也是 但若將週期縮小至2-3個月 營收與股價背離的情況很常發生\n判斷營收成長 or 衰退的趨勢 其time frame也要抓好\n畢竟營收整個趨勢變化較慢 但方向較穩定 但股價有更多雜訊因素\nsub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = sub[(~sub[\u0026#39;3m_diff\u0026#39;].isna()) \u0026amp; (~sub[\u0026#39;12m_diff\u0026#39;].isna())] sub.isna().sum() combine_df.columns[-60:-30] sub[\u0026#39;optimize\u0026#39;] = (sub[\u0026#39;3m_diff\u0026#39;] \u0026gt; sub[\u0026#39;12m_diff\u0026#39;]).apply(lambda x : 1 if x else 0) sub[\u0026#39;近三月合併營收(千)\u0026#39;] sub[\u0026#39;3m_diff\u0026#39;] 694442123 - 673510177 ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""}]