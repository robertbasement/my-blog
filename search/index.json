[{"content":" 筆記 from IPython.display import HTML import pandas as pd def display_df_as_html(df): \u0026#34;\u0026#34;\u0026#34;Automatically display DataFrame as an HTML table.\u0026#34;\u0026#34;\u0026#34; display(HTML(df.to_html())) # Apply function to all DataFrame outputs pd.DataFrame._repr_html_ = display_df_as_html company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event.tail() 日期 股票代號 股票名稱 月營收公告 財報公告 除息日 除權日 法說會 減資前 減資後 ... \\ 9891130 20241225 9951 皇田 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891131 20241225 9955 佳龍 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891132 20241225 9958 世紀鋼 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891133 20241225 9960 邁達康 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891134 20241225 9962 有益 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 申報轉讓 庫藏股 注意股票 新股上市 人事異動 停資 停券 最後回補日 今日事件數 RTIME 9891130 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 510725547 9891131 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891132 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891133 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891134 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 [5 rows x 21 columns] 參考 ","date":"2025-02-07T23:59:14+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/test/","title":"測試df table"},{"content":" 筆記 import pandas as pd import numpy as np import matplotlib.pyplot as plt pd.options.display.float_format = \u0026#39;{:.4f}\u0026#39;.format SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] 月營收 mon_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/monthly/monthly_revenue.ftr\u0026#39;) mon_df = mon_df[mon_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] mon_df = mon_df[~mon_df[\u0026#39;公告日\u0026#39;].isna()] mon_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(mon_df[\u0026#39;公告日\u0026#39;]) mon_df.sort_values(\u0026#39;公告日_dt\u0026#39;, inplace=True, ascending=True) mon_df.reset_index(drop=True, inplace=True) 收盤價 price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price0050 = price_df[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;0050\u0026#39;] price0050[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price0050[\u0026#39;日期\u0026#39;]) price0050.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price0050.reset_index(drop=True, inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050['日期_dt'] = pd.to_datetime(price0050['日期']) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050.sort_values('日期_dt', inplace=True, ascending=True) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;last_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(n + 2) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price0050 = price0050.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2395123834.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price0050 = price0050.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price_df = price_df.merge(price0050, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_0050\u0026#39;)) 融資 margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) price_df = price_df.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((price_df[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 週集保 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) price_df = price_df.merge(agg, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res = res.merge(price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False), how=\u0026#39;left\u0026#39;, left_on=(\u0026#39;股票代號\u0026#39;), right_on=(\u0026#39;股票代號\u0026#39;), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_baseline\u0026#39;)) res[\u0026#39;diff_ret\u0026#39;] = res[\u0026#39;hold_20Days_ret\u0026#39;] - res[\u0026#39;hold_20Days_ret_baseline\u0026#39;] for ticker in SUB_TICKERS: print(res.loc[res[\u0026#39;股票代號\u0026#39;]==ticker, [\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;diff_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;signal_count\u0026#39;]]) cut 股票代號 diff_ret hold_20Days_winrate signal_count 0 (-7.381, -0.0403] 2059 0.0074 0.5253 297 9 (-0.0403, -0.0209] 2059 -0.0003 0.5539 612 18 (-0.0209, -0.0112] 2059 -0.0105 0.5278 612 27 (-0.0112, -0.00457] 2059 0.0055 0.6105 493 36 (-0.00457, 0.000588] 2059 -0.0055 0.5302 464 45 (0.000588, 0.0064] 2059 -0.0165 0.5211 474 54 (0.0064, 0.0132] 2059 -0.0066 0.5511 470 63 (0.0132, 0.0236] 2059 0.0048 0.5630 579 72 (0.0236, 0.0459] 2059 0.0154 0.4592 368 81 (0.0459, 6.477] 2059 -0.0042 0.4848 330 cut 股票代號 diff_ret hold_20Days_winrate signal_count 5 (-7.381, -0.0403] 3529 0.0076 0.5681 639 14 (-0.0403, -0.0209] 3529 0.0057 0.5977 430 23 (-0.0209, -0.0112] 3529 0.0197 0.6016 251 32 (-0.0112, -0.00457] 3529 -0.0115 0.4541 185 41 (-0.00457, 0.000588] 3529 -0.0182 0.4237 118 50 (0.000588, 0.0064] 3529 0.0286 0.5524 105 59 (0.0064, 0.0132] 3529 0.0080 0.5088 114 68 (0.0132, 0.0236] 3529 0.0233 0.6364 132 77 (0.0236, 0.0459] 3529 -0.0101 0.5516 368 86 (0.0459, 6.477] 3529 -0.0001 0.5152 924 cut 股票代號 diff_ret hold_20Days_winrate signal_count 2 (-7.381, -0.0403] 2383 -0.0163 0.5163 337 11 (-0.0403, -0.0209] 2383 -0.0155 0.6022 450 20 (-0.0209, -0.0112] 2383 0.0208 0.5992 509 29 (-0.0112, -0.00457] 2383 0.0109 0.6031 456 38 (-0.00457, 0.000588] 2383 -0.0056 0.5408 845 47 (0.000588, 0.0064] 2383 0.0085 0.5935 866 56 (0.0064, 0.0132] 2383 0.0112 0.5605 860 65 (0.0132, 0.0236] 2383 -0.0099 0.4559 601 74 (0.0236, 0.0459] 2383 0.0042 0.4363 314 83 (0.0459, 6.477] 2383 0.0311 0.5296 287 cut 股票代號 diff_ret hold_20Days_winrate signal_count 1 (-7.381, -0.0403] 2330 -0.0388 0.4315 788 10 (-0.0403, -0.0209] 2330 0.0045 0.5472 424 19 (-0.0209, -0.0112] 2330 -0.0026 0.5797 364 28 (-0.0112, -0.00457] 2330 0.0076 0.6842 741 37 (-0.00457, 0.000588] 2330 -0.0034 0.6103 839 46 (0.000588, 0.0064] 2330 -0.0058 0.5833 768 55 (0.0064, 0.0132] 2330 -0.0045 0.6129 824 64 (0.0132, 0.0236] 2330 0.0027 0.6062 617 73 (0.0236, 0.0459] 2330 0.0221 0.6621 441 82 (0.0459, 6.477] 2330 -0.0033 0.5289 484 cut 股票代號 diff_ret hold_20Days_winrate signal_count 8 (-7.381, -0.0403] 8069 -0.0083 0.4898 786 17 (-0.0403, -0.0209] 8069 0.0377 0.6390 313 26 (-0.0209, -0.0112] 8069 0.0130 0.5763 321 35 (-0.0112, -0.00457] 8069 -0.0059 0.5538 316 44 (-0.00457, 0.000588] 8069 0.0035 0.5430 256 53 (0.000588, 0.0064] 8069 -0.0044 0.5430 291 62 (0.0064, 0.0132] 8069 0.0173 0.6335 352 71 (0.0132, 0.0236] 8069 0.0035 0.5276 381 80 (0.0236, 0.0459] 8069 -0.0176 0.4596 594 89 (0.0459, 6.477] 8069 -0.0020 0.5591 744 cut 股票代號 diff_ret hold_20Days_winrate signal_count 7 (-7.381, -0.0403] 5274 0.0202 0.6256 438 16 (-0.0403, -0.0209] 5274 -0.0428 0.5028 179 25 (-0.0209, -0.0112] 5274 -0.0071 0.6331 169 34 (-0.0112, -0.00457] 5274 0.0072 0.6823 192 43 (-0.00457, 0.000588] 5274 0.0079 0.6508 126 52 (0.000588, 0.0064] 5274 0.0453 0.7287 129 61 (0.0064, 0.0132] 5274 0.0348 0.7063 160 70 (0.0132, 0.0236] 5274 0.0197 0.6702 188 79 (0.0236, 0.0459] 5274 0.0036 0.6394 416 88 (0.0459, 6.477] 5274 -0.0205 0.5478 712 cut 股票代號 diff_ret hold_20Days_winrate signal_count 4 (-7.381, -0.0403] 3008 0.0105 0.4967 449 13 (-0.0403, -0.0209] 3008 0.0191 0.6574 788 22 (-0.0209, -0.0112] 3008 0.0128 0.6181 720 31 (-0.0112, -0.00457] 3008 0.0030 0.5690 652 40 (-0.00457, 0.000588] 3008 -0.0275 0.4177 565 49 (0.000588, 0.0064] 3008 -0.0320 0.3731 453 58 (0.0064, 0.0132] 3008 -0.0063 0.4907 377 67 (0.0132, 0.0236] 3008 0.0032 0.5278 485 76 (0.0236, 0.0459] 3008 -0.0048 0.5455 627 85 (0.0459, 6.477] 3008 0.0236 0.5260 365 cut 股票代號 diff_ret hold_20Days_winrate signal_count 3 (-7.381, -0.0403] 2454 -0.0014 0.5589 433 12 (-0.0403, -0.0209] 2454 -0.0161 0.4977 663 21 (-0.0209, -0.0112] 2454 0.0020 0.6016 728 30 (-0.0112, -0.00457] 2454 -0.0285 0.4292 643 39 (-0.00457, 0.000588] 2454 0.0040 0.5687 466 48 (0.000588, 0.0064] 2454 0.0165 0.6183 503 57 (0.0064, 0.0132] 2454 -0.0053 0.5879 512 66 (0.0132, 0.0236] 2454 0.0106 0.6314 681 75 (0.0236, 0.0459] 2454 -0.0067 0.5551 726 84 (0.0459, 6.477] 2454 -0.0048 0.5616 276 cut 股票代號 diff_ret hold_20Days_winrate signal_count 6 (-7.381, -0.0403] 3533 -0.0589 0.2222 36 15 (-0.0403, -0.0209] 3533 0.0147 0.6366 344 24 (-0.0209, -0.0112] 3533 0.0306 0.6929 521 33 (-0.0112, -0.00457] 3533 -0.0040 0.5455 528 42 (-0.00457, 0.000588] 3533 -0.0483 0.3852 527 51 (0.000588, 0.0064] 3533 -0.0313 0.4356 606 60 (0.0064, 0.0132] 3533 0.0060 0.5898 529 69 (0.0132, 0.0236] 3533 0.0259 0.6311 534 78 (0.0236, 0.0459] 3533 0.0143 0.4725 345 87 (0.0459, 6.477] 3533 0.1118 0.8333 78 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window): date_numeric = window[:, 0] # Extract the first column (date_numeric) value = window[:, 1] # Extract the second column (value) x_diff = date_numeric[-1] - date_numeric[0] # Time difference y_diff = value[-1] - value[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size][[\u0026#39;date_numeric\u0026#39;, \u0026#39;value\u0026#39;]].to_numpy() slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] # Time difference y_diff = window_df[\u0026#39;value\u0026#39;].iloc[-1] - window_df[\u0026#39;value\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 price_df[\u0026#39;date_numeric\u0026#39;] = (price_df[\u0026#39;日期_dt\u0026#39;] - price_df[\u0026#39;日期_dt\u0026#39;].min()).dt.days price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'date_numeric'], dtype='object') # 120日本益比的切線斜率 # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] - 1 # Time difference y_diff = (window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[-1] - window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] )/ window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) df[f\u0026#39;slope_{window_size}\u0026#39;] = [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment df[f\u0026#39;slope_{window_size}\u0026#39;] = df[f\u0026#39;slope_{window_size}\u0026#39;].shift(1) # 本益比用今天的收盤價去計算 明天才知道result return df # Add slope to the DataFrame # price_df[\u0026#39;slope\u0026#39;] = rolling_slope(price_df, window_size=5) for w in [5, 10, 20, 60, 120]: price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) price_df.loc[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;本益比(近四季)\u0026#39;, \u0026#39;slope_5\u0026#39;, \u0026#39;date_numeric\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ((25.6-29.5)/29.5)/5 -0.026440677966101684 for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).mean().reset_index(drop=True) price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).sum().reset_index(drop=True) ret_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: print(price_df.loc[price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]\u0026gt;0, ret_cols].mean()) # price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=5)) w = 60 j = 60 for ticker in SUB_TICKERS: tmp = price_df[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;] = tmp[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean() ax1.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;], label=\u0026#39;PE\u0026#39;) ax2 = ax1.twinx() ax2.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;],color=\u0026#39;green\u0026#39;, label=\u0026#39;PE slope\u0026#39;) ax3 = ax1.twinx() ax3.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;收盤價\u0026#39;],color=\u0026#39;orange\u0026#39;, label=\u0026#39;price\u0026#39;) ax1.set_title(ticker) indices = tmp.loc[(tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt;= 0.02), \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) ax1.legend() ax2.legend() def vector_backtest(df): # input: df, 需要有signa columns, output : [[trade_data1], [trade_data2], ...] (list中包含多個list) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4] # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; com_code = group[\u0026#39;股票代號\u0026#39;].iloc[-1] start_date = group[\u0026#39;日期\u0026#39;].iloc[0] end_date = group[\u0026#39;日期\u0026#39;].iloc[-1] buy_price = group[\u0026#39;次日收盤價\u0026#39;].iloc[0] sell_price = group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1] ret = (sell_price/buy_price) - 1 holding_days = len(group) event_list = [com_code, start_date, end_date, buy_price, sell_price, ret, holding_days] event_list_all.append(event_list) return event_list_all print(f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;) slope_60_rolling_60_SUM price_df[\u0026#39;本益比_rolling5\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean().reset_index(drop=True) price_df[\u0026#39;本益比_rolling20\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(20).mean().reset_index(drop=True) 看起來本益比切線斜率 累積增加\u0026gt;0 對捕捉上升趨勢還不錯 price_df.reset_index(drop=True, inplace=True) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) # | (price_df[f\u0026#39;slope_{w}\u0026#39;] \u0026lt; price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) \u0026amp; (price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt;= 0) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/312944587.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), ret_cols].mean() hold_5Days_ret 0.0080 hold_10Days_ret 0.0148 hold_20Days_ret 0.0310 hold_60Days_ret 0.0807 hold_120Days_ret 0.1454 dtype: float64 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3156983121.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) | (price_df[\u0026#39;last_60Days_ret_0050\u0026#39;] \u0026lt;= -0.1) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/95528996.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.columns[-140:-120] Index(['收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME'], dtype='object') price_df[\u0026#39;20MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(20).mean().reset_index(drop=True) price_df[\u0026#39;60MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(60).mean().reset_index(drop=True) price_df[\u0026#39;200MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(200).mean().reset_index(drop=True) Local Minima, maxima from scipy.signal import argrelextrema def groupby_extrema(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df[\u0026#39;local_maxima\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima.loc[max_comparisons_larger_idx].values.tolist() df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_sup(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # print(local_minima) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) print(min_comparisons_smaller_idx) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df[\u0026#39;local_minima\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima.loc[min_comparisons_smaller_idx].values.tolist() df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) [np.int64(647), np.int64(727), np.int64(916), np.int64(1198), np.int64(1314), np.int64(1388), np.int64(1801), np.int64(2151), np.int64(2358), np.int64(2549), np.int64(2999), np.int64(3101), np.int64(3290), np.int64(4081), np.int64(4249), np.int64(4392), np.int64(4752)] [np.int64(388), np.int64(960), np.int64(1098), np.int64(1504), np.int64(1633), np.int64(1760), np.int64(2227), np.int64(2331), np.int64(2519), np.int64(2642), np.int64(2956), np.int64(3136), np.int64(3325), np.int64(3444), np.int64(3646), np.int64(3675), np.int64(3740), np.int64(4131), np.int64(4369), np.int64(4417), np.int64(4677), np.int64(4757), np.int64(4858), np.int64(4902), np.int64(5019), np.int64(5178), np.int64(5262), np.int64(5381), np.int64(5749), np.int64(6100), np.int64(6562), np.int64(6835), np.int64(6941), np.int64(7077), np.int64(7161)] [np.int64(799), np.int64(1099), np.int64(2475), np.int64(2879), np.int64(2999), np.int64(3090), np.int64(3347), np.int64(3469), np.int64(3750), np.int64(4090), np.int64(4196), np.int64(4293), np.int64(4472), np.int64(4599), np.int64(4716), np.int64(4844), np.int64(5076), np.int64(5188), np.int64(5317), np.int64(5535), np.int64(5556), np.int64(5818), np.int64(5899), np.int64(6264), np.int64(6430), np.int64(6451), np.int64(6795), np.int64(6893)] [np.int64(380), np.int64(624), np.int64(749), np.int64(1254), np.int64(1441), np.int64(1629), np.int64(1859), np.int64(2107), np.int64(2236), np.int64(2638), np.int64(2710), np.int64(2894), np.int64(2993), np.int64(3240), np.int64(3541), np.int64(3848), np.int64(4122), np.int64(4240), np.int64(4639), np.int64(4952), np.int64(5171), np.int64(5380), np.int64(5662), np.int64(5684), np.int64(5735)] [np.int64(345), np.int64(628), np.int64(1091), np.int64(1513), np.int64(1715), np.int64(1910), np.int64(1946), np.int64(2023), np.int64(2086), np.int64(2190), np.int64(2438), np.int64(2813), np.int64(3199), np.int64(3389), np.int64(3426), np.int64(3459), np.int64(3681), np.int64(3819), np.int64(3965), np.int64(4515), np.int64(4766), np.int64(4890), np.int64(5135), np.int64(5230), np.int64(5349), np.int64(5502)] [np.int64(374), np.int64(465), np.int64(598), np.int64(624), np.int64(1017), np.int64(1173), np.int64(1588), np.int64(1710), np.int64(1939), np.int64(2157), np.int64(2286), np.int64(2761), np.int64(2816), np.int64(3084), np.int64(3111), np.int64(3293)] [np.int64(653), np.int64(953), np.int64(1046), np.int64(1150), np.int64(1469), np.int64(1596), np.int64(1628), np.int64(1706), np.int64(1826), np.int64(1922), np.int64(2362), np.int64(2518), np.int64(2731), np.int64(3190), np.int64(3637), np.int64(3741), np.int64(3757), np.int64(3873), np.int64(4145)] [np.int64(318), np.int64(534), np.int64(796), np.int64(1031), np.int64(1068), np.int64(1110), np.int64(1153), np.int64(1328), np.int64(1394), np.int64(1716), np.int64(1835), np.int64(2269)] [np.int64(765), np.int64(952), np.int64(1659), np.int64(1962), np.int64(2577), np.int64(3066), np.int64(3310), np.int64(3626), np.int64(3773), np.int64(3796), np.int64(3961), np.int64(4354), np.int64(4559), np.int64(4661), np.int64(4841)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3911248321.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, \u0026#39;收盤價\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2624941152.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, '收盤價')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, \u0026#39;收盤價\u0026#39;)) [np.int64(204), np.int64(287), np.int64(387), np.int64(690), np.int64(886), np.int64(1026), np.int64(1259), np.int64(1299), np.int64(1369), np.int64(1471), np.int64(1508), np.int64(1530), np.int64(1583), np.int64(1742), np.int64(2029), np.int64(2081), np.int64(2308), np.int64(2343), np.int64(2501), np.int64(2543), np.int64(2626), np.int64(2713), np.int64(2737), np.int64(2794), np.int64(3012), np.int64(3029), np.int64(3053), np.int64(3107), np.int64(3157), np.int64(3169), np.int64(3267), np.int64(3314), np.int64(3345), np.int64(3420), np.int64(3452), np.int64(3475), np.int64(3494), np.int64(3681), np.int64(3819), np.int64(4028), np.int64(4159), np.int64(4193), np.int64(4316), np.int64(4338), np.int64(4367), np.int64(4410), np.int64(4563), np.int64(4706), np.int64(4746), np.int64(4790)] [np.int64(40), np.int64(133), np.int64(185), np.int64(258), np.int64(317), np.int64(343), np.int64(386), np.int64(431), np.int64(615), np.int64(904), np.int64(943), np.int64(1029), np.int64(1069), np.int64(1159), np.int64(1224), np.int64(1537), np.int64(1562), np.int64(1646), np.int64(1704), np.int64(1757), np.int64(1797), np.int64(1823), np.int64(1875), np.int64(1896), np.int64(1942), np.int64(2037), np.int64(2083), np.int64(2110), np.int64(2125), np.int64(2149), np.int64(2193), np.int64(2253), np.int64(2277), np.int64(2491), np.int64(2553), np.int64(2592), np.int64(2616), np.int64(2641), np.int64(2704), np.int64(2912), np.int64(2930), np.int64(2948), np.int64(3039), np.int64(3102), np.int64(3284), np.int64(3333), np.int64(3400), np.int64(3470), np.int64(3508), np.int64(3668), np.int64(3695), np.int64(3713), np.int64(3951), np.int64(4018), np.int64(4088), np.int64(4291), np.int64(4359), np.int64(4375), np.int64(4390), np.int64(4593), np.int64(4802), np.int64(4895), np.int64(4960), np.int64(5006), np.int64(5243), np.int64(5336), np.int64(5389), np.int64(5488), np.int64(5564), np.int64(5962), np.int64(6047), np.int64(6086), np.int64(6169), np.int64(6187), np.int64(6219), np.int64(6310), np.int64(6506), np.int64(6636), np.int64(6754), np.int64(6786), np.int64(6856), np.int64(6991), np.int64(7030), np.int64(7068), np.int64(7145), np.int64(7262), np.int64(7367), np.int64(7573)] [np.int64(96), np.int64(147), np.int64(203), np.int64(240), np.int64(401), np.int64(468), np.int64(587), np.int64(715), np.int64(789), np.int64(1042), np.int64(1190), np.int64(1235), np.int64(1283), np.int64(1432), np.int64(1463), np.int64(1489), np.int64(1530), np.int64(1632), np.int64(1646), np.int64(1669), np.int64(1894), np.int64(1986), np.int64(2041), np.int64(2101), np.int64(2167), np.int64(2263), np.int64(2449), np.int64(2622), np.int64(2822), np.int64(2847), np.int64(2976), np.int64(3006), np.int64(3078), np.int64(3287), np.int64(3307), np.int64(3349), np.int64(3437), np.int64(3543), np.int64(3629), np.int64(3673), np.int64(3693), np.int64(3710), np.int64(3737), np.int64(3820), np.int64(3890), np.int64(4051), np.int64(4140), np.int64(4164), np.int64(4193), np.int64(4274), np.int64(4496), np.int64(4577), np.int64(4681), np.int64(4806), np.int64(4827), np.int64(5003), np.int64(5026), np.int64(5273), np.int64(5294), np.int64(5333), np.int64(5387), np.int64(5430), np.int64(5477), np.int64(5508), np.int64(5742), np.int64(5760), np.int64(5812), np.int64(5844), np.int64(5999), np.int64(6123), np.int64(6411), np.int64(6484), np.int64(6574), np.int64(6600), np.int64(6702), np.int64(6727), np.int64(6777), np.int64(6840), np.int64(6911)] [np.int64(215), np.int64(229), np.int64(247), np.int64(390), np.int64(584), np.int64(692), np.int64(789), np.int64(833), np.int64(875), np.int64(1018), np.int64(1058), np.int64(1121), np.int64(1136), np.int64(1196), np.int64(1216), np.int64(1234), np.int64(1317), np.int64(1588), np.int64(1622), np.int64(1729), np.int64(1818), np.int64(1829), np.int64(2054), np.int64(2120), np.int64(2193), np.int64(2220), np.int64(2295), np.int64(2394), np.int64(2421), np.int64(2459), np.int64(2476), np.int64(2493), np.int64(2673), np.int64(2817), np.int64(2850), np.int64(2959), np.int64(3232), np.int64(3282), np.int64(3419), np.int64(3494), np.int64(3594), np.int64(3608), np.int64(3664), np.int64(3754), np.int64(3793), np.int64(3845), np.int64(4071), np.int64(4196), np.int64(4214), np.int64(4229), np.int64(4275), np.int64(4324), np.int64(4611), np.int64(4961), np.int64(4997), np.int64(5096), np.int64(5125), np.int64(5173), np.int64(5233), np.int64(5367), np.int64(5429), np.int64(5549), np.int64(5607)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) [np.int64(86), np.int64(106), np.int64(213), np.int64(429), np.int64(450), np.int64(573), np.int64(592), np.int64(639), np.int64(718), np.int64(1006), np.int64(1066), np.int64(1146), np.int64(1188), np.int64(1217), np.int64(1241), np.int64(1277), np.int64(1472), np.int64(1580), np.int64(1650), np.int64(1679), np.int64(1775), np.int64(1854), np.int64(1965), np.int64(2041), np.int64(2244), np.int64(2354), np.int64(2387), np.int64(2428), np.int64(2507), np.int64(2524), np.int64(2648), np.int64(2708), np.int64(2769), np.int64(2828), np.int64(2868), np.int64(3122), np.int64(3142), np.int64(3332), np.int64(3355), np.int64(3370), np.int64(3423), np.int64(3438), np.int64(3644), np.int64(3742), np.int64(3858), np.int64(3932), np.int64(3950), np.int64(3985), np.int64(4114), np.int64(4136), np.int64(4154), np.int64(4174), np.int64(4271), np.int64(4461), np.int64(4573), np.int64(4602), np.int64(4671), np.int64(4805), np.int64(4847), np.int64(4963), np.int64(4982), np.int64(5085), np.int64(5457), np.int64(5559), np.int64(5594)] [np.int64(63), np.int64(113), np.int64(163), np.int64(232), np.int64(292), np.int64(338), np.int64(349), np.int64(424), np.int64(436), np.int64(451), np.int64(520), np.int64(531), np.int64(640), np.int64(671), np.int64(1002), np.int64(1117), np.int64(1129), np.int64(1300), np.int64(1344), np.int64(1529), np.int64(1554), np.int64(1632), np.int64(1645), np.int64(1661), np.int64(1738), np.int64(1798), np.int64(1881), np.int64(1923), np.int64(2102), np.int64(2175), np.int64(2214), np.int64(2246), np.int64(2363), np.int64(2593), np.int64(2704), np.int64(2759), np.int64(2812), np.int64(3083), np.int64(3175), np.int64(3245), np.int64(3313)] [np.int64(123), np.int64(149), np.int64(219), np.int64(260), np.int64(280), np.int64(608), np.int64(637), np.int64(727), np.int64(813), np.int64(894), np.int64(921), np.int64(997), np.int64(1090), np.int64(1115), np.int64(1235), np.int64(1275), np.int64(1370), np.int64(1384), np.int64(1482), np.int64(1502), np.int64(1654), np.int64(1826), np.int64(1838), np.int64(1865), np.int64(1896), np.int64(2014), np.int64(2086), np.int64(2190), np.int64(2208), np.int64(2302), np.int64(2471), np.int64(2513), np.int64(2569), np.int64(2583), np.int64(2681), np.int64(2821), np.int64(2838), np.int64(3028), np.int64(3096), np.int64(3264), np.int64(3308), np.int64(3377), np.int64(3513), np.int64(3590), np.int64(3668), np.int64(3728), np.int64(3814), np.int64(3853), np.int64(3908), np.int64(4095)] [np.int64(38), np.int64(114), np.int64(255), np.int64(302), np.int64(314), np.int64(335), np.int64(674), np.int64(778), np.int64(922), np.int64(1079), np.int64(1276), np.int64(1310), np.int64(1342), np.int64(1486), np.int64(1781), np.int64(1968), np.int64(2036), np.int64(2161), np.int64(2174), np.int64(2223), np.int64(2255), np.int64(2276), np.int64(2310), np.int64(2328), np.int64(2444), np.int64(2476), np.int64(2498), np.int64(2520), np.int64(2659), np.int64(2826)] [np.int64(59), np.int64(146), np.int64(176), np.int64(272), np.int64(395), np.int64(475), np.int64(553), np.int64(571), np.int64(659), np.int64(901), np.int64(960), np.int64(1056), np.int64(1080), np.int64(1112), np.int64(1139), np.int64(1491), np.int64(1530), np.int64(1555), np.int64(1733), np.int64(1809), np.int64(1925), np.int64(1940), np.int64(2024), np.int64(2035), np.int64(2156), np.int64(2201), np.int64(2304), np.int64(2334), np.int64(2395), np.int64(2528), np.int64(2578), np.int64(2629), np.int64(2651), np.int64(2763), np.int64(2811), np.int64(2831), np.int64(2908), np.int64(2930), np.int64(3133), np.int64(3285), np.int64(3345), np.int64(3451), np.int64(3500), np.int64(3582), np.int64(3611), np.int64(3837), np.int64(3914), np.int64(3948), np.int64(4087), np.int64(4230), np.int64(4327), np.int64(4414), np.int64(4433), np.int64(4510), np.int64(4587), np.int64(4607), np.int64(4700), np.int64(4783), np.int64(4799), np.int64(4828), np.int64(4944), np.int64(5083)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/785596803.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, '收盤價')) price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;] ) strategy Logic price_df.reset_index(drop=True, inplace=True) # 近一個月 400張大戶 增加2%以上 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4079245513.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 mask = (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[mask, \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/857034293.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1700805250.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[((price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/168196673.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;20MA\u0026#39;] \u0026gt;= price_df[\u0026#39;200MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3380416550.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/939178834.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/357474516.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 組合上下行 price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/950731482.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3623880085.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1110539843.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt; 0.02), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3456730543.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026gt;= price_df[\u0026#39;60MA\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1528418423.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026lt; price_df[\u0026#39;60MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/538384737.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) # price_df[price_df[\u0026#39;signal\u0026#39;]==1] NOW price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) # (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5)| (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[((price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;0.02) \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3722245375.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 簡易PnL模擬 res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2059', '3008'], dtype='object') from collections import Counter def vector_backtest_ratio(df, buyholddays): \u0026#39;\u0026#39;\u0026#39; for backtest PnL ratio index_count 算目前在該ticker 上累積bet的數量 \u0026#39;\u0026#39;\u0026#39; df.reset_index(drop=True, inplace=True) df[\u0026#39;ratio\u0026#39;] = 0 signal_idx = df[df[\u0026#39;signal\u0026#39;]==1].index all_holding_idx = [] for idx in signal_idx: adding_idx = [i for i in range(idx, idx+buyholddays) if i \u0026lt; len(df)] all_holding_idx += adding_idx df.loc[all_holding_idx, \u0026#39;signal\u0026#39;] = 1 return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 10)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/517245478.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 10)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 20)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2754594864.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 20)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 60)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3282921495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 60)) price_df.reset_index(drop=True, inplace=True) res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/317971430.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2330', '8069', '3008'], dtype='object') 如果是想要抄底的策略 holding 天數可能要拉長到可以等他漲回去 # price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;signal\u0026#39;]==1)].iloc[-20::] res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1410/2410 0.5850622406639004 2454, 2383, 2059, 3008 done res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;slope\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;]\u0026lt;=-0.05), \u0026#39;signal\u0026#39;] = 1 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;slope\u0026#39;]\u0026gt;=0.1), \u0026#39;signal\u0026#39;] = 1 ret_cols = [f\u0026#39;hold_{n}Days_ret\u0026#39; for n in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{n}Days_winrate\u0026#39; for n in [5, 10, 20, 60, 120]] price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() - price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PE price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;本益比(近四季)\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'cut', 'signal'], dtype='object') price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) income_stat_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/quarterly/quarterlyIncomeStatementSingal.ftr\u0026#39;) income_stat_df = income_stat_df[income_stat_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] income_stat_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(income_stat_df[\u0026#39;公告日期\u0026#39;]) income_stat_df.sort_values(\u0026#39;年季\u0026#39;, inplace=True, ascending=True) income_stat_df.reset_index(drop=True, inplace=True) income_stat_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import re income_stat_df.columns = [re.sub(r\u0026#39;\\s+\u0026#39;, \u0026#39;\u0026#39;, i) for i in income_stat_df.columns] income_stat_df.columns[0:30] Index(['年季', '股票代號', '股票名稱', '市場別', '財報類別', '銷貨收入淨額(千)', '銷貨收入(千)', '銷貨退回(千)', '銷貨折讓(千)', '營業收入淨額(千)', '營業成本(千)', '營業毛利(千)', '聯屬公司間未實現利益(千)', '聯屬公司間已實現利益(千)', '營業毛利淨額(千)', '營業費用(千)', '推銷費用(千)', '管理費用(千)', '研發費用(千)', '預期信用減損損益(千)', '其他營業費用(千)', '其他收益及費損(千)', '其他收益(千)', '其他費損(千)', '營業利益(千)', '營業外收入及支出(千)', '利息收入(千)', '銀行存款利息(千)', '按攤銷後成本衡量之金融資產利息收入(千)', '透過其他綜合損益按公允價值衡量之金融資產利息收入(千)'], dtype='object') income_stat_df.columns[-30::] Index(['國外營運機構淨投資避險中屬有效避險部分之避險工具損益(千)', '與待出售非流動資產直接相關之權益–可能重分類至損益(千)', '透過其他綜合損益按公允價值衡量之債務工具投資未實現評價損益(千)', '避險工具之損益–可能重分類至損益(千)', '採權益法認列關聯企業及合資其他綜合損益之份額–可能重分類至損益(千)', '可能重分類至損益之其他項目(千)', '與可能重分類至損益之項目相關之所得稅(千)', '綜合損益(千)', '稅後純益歸屬(千)', '母公司業主–稅後純益(千)', '非控制權益–稅後純益(千)', '共同控制下前手權益–稅後純益(千)', '綜合損益歸屬(千)', '母公司業主–綜合損益(千)', '非控制權益–綜合損益(千)', '共同控制下前手權益–綜合損益(千)', 'EBITDA(千)', '公告基本每股盈餘(元)', '公告稀釋每股盈餘(元)', '原始每股稅前盈餘(元)', '原始每股稅後盈餘(元)', '原始每股綜合盈餘(元)', '每股稅前盈餘(元)', '每股稅後盈餘(元)', '每股綜合盈餘(元)', '更新日期', '公告日期', '建立日期', 'RTIME', '公告日_dt'], dtype='object') income_stat_df[\u0026#39;母公司業主–稅後純益(千)\u0026#39;] 0 \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; 2 \u0026lt;NA\u0026gt; 3 \u0026lt;NA\u0026gt; 4 1602873 ... 818 4498178 819 25715520 820 2435866 821 247845528 822 1456409 Name: 母公司業主–稅後純益(千), Length: 823, dtype: Int64 不同時間段 適合看得指標也不盡相同 我能不能這個概念 -\u0026gt; 用基本面的變化來作為時間段的區分 像是基本面改善期間 -\u0026gt; 適合的策略\n基本面維持不變時的策略\n股價過度反應/過高過低PE對應的策略\n像是 基本面漲, 股價沒漲 -\u0026gt; 可能已經反應過了, 也可能是還沒反應\n順勢 基本面漲 \u0026amp; 股價也漲\n大盤逆風 基本面漲 但股價大跌 -\u0026gt; 先不要進場 等大盤回穩 or PE到一定程度才進場\n貝氏定理 先把營收, EPS, 對比股價的圖Plot出來 判斷大盤行情 上行, 糾結, 下行 在對比各個features在這些期間之下的表現 ex: 大盤下行的時候 全部訊號都沒用 除了PE跌倒歷史quantile多少時可以買入\u0026hellip;, 上行的時候跟著持有也不用管基本面etc reample + merge EPS forward knowing , cal + resample + merge 1. 先把每一季的EPS做加總(4季 agg) 再藉由shift去假設 能夠完美預測未來N季 再resample 至daily def resample_q_forward(df): # print(df[\u0026#39;股票代號\u0026#39;].iloc[-1]) df = df[~df[\u0026#39;公告日期\u0026#39;].isna()] df = df[~df.duplicated(subset=[\u0026#39;公告日期\u0026#39;])] df[\u0026#39;knowNext0Q\u0026#39;] = df[\u0026#39;每股稅後盈餘(元)\u0026#39;].rolling(4).sum() df.set_index(\u0026#39;公告日_dt\u0026#39;, inplace=True) df = df.resample(\u0026#39;D\u0026#39;).ffill() return df 2. 與股價合併 resample_q_df = combine_df = price_df.merge(resample_q_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) combine_df[\u0026#39;Y_M\u0026#39;] = combine_df[\u0026#39;日期_dt\u0026#39;].dt.year.astype(str) + \u0026#39;_\u0026#39; + combine_df[\u0026#39;日期_dt\u0026#39;].dt.month.astype(str).str.zfill(2) sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub[\u0026#39;PEG_0Q\u0026#39;].describe() count 5167.0000 mean 1.5405 std 2.4577 min -1.0632 25% 0.3917 50% 0.7254 75% 1.6816 max 20.2743 Name: PEG_0Q, dtype: float64 3. 有股價 有完美預測一段時間的EPS -\u0026gt; 就有完美預估的PE 找出該期間的MAX, MIN值 主要是用來繪制河流圖 並shift def find_PE_range(df): \u0026#39;\u0026#39;\u0026#39; groupby 年季, ticker 假設知道未來N季的EPS 對應期間股價的P/E 區間的max, min 應該要用於未來畫本益比河流圖所用 \u0026#39;\u0026#39;\u0026#39; tmp = pd.DataFrame() YM = df[\u0026#39;Y_M\u0026#39;].iloc[-1] Q = df[\u0026#39;年季\u0026#39;].iloc[-1] for i in range(1, 5): tmp.loc[Q, f\u0026#39;{i}_max_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].max() tmp.loc[Q, f\u0026#39;{i}_mean_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].mean() tmp.loc[Q, f\u0026#39;{i}_min_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].min() # tmp.loc[Q, f\u0026#39;{i}_max_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].max() # tmp.loc[Q, f\u0026#39;{i}_mean_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].mean() # tmp.loc[Q, f\u0026#39;{i}_min_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].min() tmp[\u0026#39;Q\u0026#39;] = Q return tmp pe_res = combine_df.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]).apply(find_PE_range).reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/3018702681.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. pe_res = combine_df.groupby(['股票代號', '年季']).apply(find_PE_range).reset_index(drop=False) 用前一季之前的All data 來計算 分位數 # Convert the \u0026#39;quarter\u0026#39; column to a Period with quarterly frequency combine_df[\u0026#39;year\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[:4] # Extract the year (first 4 digits) combine_df[\u0026#39;qtr\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[-2:] # Extract the quarter (last 2 digits) # Create a new column with period as \u0026#39;YYYYQ#\u0026#39; format (like 2000Q4, 2001Q1, etc.) combine_df[\u0026#39;period\u0026#39;] = combine_df[\u0026#39;year\u0026#39;] + \u0026#39;Q\u0026#39; + combine_df[\u0026#39;qtr\u0026#39;].replace({\u0026#39;01\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;02\u0026#39;: \u0026#39;2\u0026#39;, \u0026#39;03\u0026#39;: \u0026#39;3\u0026#39;, \u0026#39;04\u0026#39;: \u0026#39;4\u0026#39;}) # Convert to Pandas Period with quarterly frequency combine_df[\u0026#39;period\u0026#39;] = pd.PeriodIndex(combine_df[\u0026#39;period\u0026#39;], freq=\u0026#39;Q\u0026#39;) def quantile_q(df): i = 0 q_list = df[\u0026#39;period\u0026#39;].unique().tolist() sub_df_list = [] for q in q_list: thisQ = df[df[\u0026#39;period\u0026#39;]==q] lastQ = df[(df[\u0026#39;period\u0026#39;]\u0026gt;(q - 40)) \u0026amp; (df[\u0026#39;period\u0026#39;]\u0026lt;q)] # 20 -\u0026gt; 5y, 12 -\u0026gt; 3y for i in range(0, 5): thisQ[f\u0026#39;q20_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.2) thisQ[f\u0026#39;q40_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.4) thisQ[f\u0026#39;q60_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.6) thisQ[f\u0026#39;q80_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.8) # thisQ[f\u0026#39;q20_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.2) # thisQ[f\u0026#39;q40_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.4) # thisQ[f\u0026#39;q60_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.6) # thisQ[f\u0026#39;q80_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.8) sub_df_list.append(thisQ) new_df = pd.concat(sub_df_list) return new_df res = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_q).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/348048885.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res = combine_df.groupby('股票代號').apply(quantile_q).reset_index(drop=True) res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2008Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x1283cb400\u0026gt; png\r\u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2018Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 4 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q_G\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q_G\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q_G\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q_G\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PEG_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x124c216d0\u0026gt; png\rfor i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;0~20_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;20~40_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;40~60_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;60~80_{i}Q_G\u0026#39; if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;80~100_{i}Q_G\u0026#39; for i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;0~20_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;20~40_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;40~60_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;60~80_{i}Q\u0026#39; if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;80~100_{i}Q\u0026#39; res[res[\u0026#39;cata_0Q\u0026#39;]==\u0026#39;0~20_0Q\u0026#39;] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[[\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_0Q\u0026#39;])[[\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() preview_res[\u0026#39;day_ratio\u0026#39;] = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[\u0026#39;收盤價\u0026#39;].count()/6275 preview_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;20~40_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) # for i in range(0, 5): for i in [0, 4]: # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) hist_obj = ax1.hist(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, bins=100, alpha=0.5 ) color = hist_obj[2][0].get_facecolor() ax1.axvline(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].mean(), ymin=0, ymax=500, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, color=color) ax1.legend() png\rpng\rpng\rpng\rpng\rfrom scipy import stats import numpy as np # Generate some sample data with different lengths data1 = np.random.normal(50, 10, 100) # Dataset 1 data2 = np.random.normal(52, 15, 150) # Dataset 2 # Perform a two-sample t-test assuming equal variances (Student\u0026#39;s t-test) t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\u0026#34;) # Perform Welch\u0026#39;s t-test (does not assume equal variances) t_stat_welch, p_value_welch = stats.ttest_ind(data1, data2, equal_var=False) print(f\u0026#34;Welch\u0026#39;s t-test: t-statistic = {t_stat_welch:.4f}, p-value = {p_value_welch:.4f}\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res tmp = pd.DataFrame() for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: i = 0 t = 1 for days in [5, 10, 20, 60, 120]: data1 = sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values data2 = sub.loc[sub[f\u0026#39;cata_{t}Q\u0026#39;] == f\u0026#39;{quantile}_{t}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}, {quantile}_{t}Q, \u0026#39;hold_{days}Days_ret\u0026#39;\u0026#34;) tmp.loc[f\u0026#39;{quantile}_{i}Q vs {t}Q\u0026#39;, f\u0026#39;hold {days} mean return p-value\u0026#39;] = p_value tmp 有多少 forward 0 在低本益比 但其實用forward 4Q是高本益比\n反之亦然\n這類股價其實是由未來營收所帶動的 也許就是我們想要抓的?\nforward 的優勢就在於 用歷史推估 跟由研調預測得出來的結論有明顯差異 材值得做\nsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;60~80_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;80~100_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res # mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) # mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import numpy as np sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) show_df = pd.DataFrame() for i in np.arange(0.1, 1, 0.1): mask2 = (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026gt;= i) \u0026amp; (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026lt; (i + 0.1)) show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, \u0026#39;count\u0026#39;] = len(sub.loc[mask2]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df = pd.DataFrame() sub = res for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: mask1 = (sub[\u0026#39;cata_4Q\u0026#39;] == f\u0026#39;{quantile}_4Q\u0026#39;) show_df.loc[f\u0026#39;mean_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;precision_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res.columns import pandas as pd import matplotlib.pyplot as plt # Example data with 8 categories data = {\u0026#39;Date\u0026#39;: pd.date_range(start=\u0026#39;2024-01-01\u0026#39;, periods=10, freq=\u0026#39;D\u0026#39;), \u0026#39;Signal\u0026#39;: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0], \u0026#39;Category\u0026#39;: [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]} df = pd.DataFrame(data) # Get unique categories (suppose you have exactly 8 categories) categories = df[\u0026#39;Category\u0026#39;].unique() # Define the number of rows and columns for the subplots n_rows, n_cols = 2, 4 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() # Loop through each category and plot for i, category in enumerate(categories): # Filter DataFrame by category category_df = df[df[\u0026#39;Category\u0026#39;] == category] # Get dates where Signal == 1 for that category signal_dates = category_df.loc[category_df[\u0026#39;Signal\u0026#39;] == 1, \u0026#39;Date\u0026#39;] # Plot vertical lines on the respective subplot axes[i].vlines(x=signal_dates, ymin=0, ymax=1, color=\u0026#39;b\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;Signal {category}\u0026#39;) axes[i].set_title(f\u0026#39;Category {category}\u0026#39;) axes[i].set_ylabel(\u0026#39;Signal\u0026#39;) # Format the x-axis for dates (shared x-axis) axes[i].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter(\u0026#39;%Y-%m-%d\u0026#39;)) axes[i].tick_params(axis=\u0026#39;x\u0026#39;, rotation=45) # Hide empty subplots if any (for cases when the grid is larger than needed) for j in range(i + 1, n_rows * n_cols): fig.delaxes(axes[j]) # Set the xlabel for the subplots in the last row for ax in axes[-n_cols:]: ax.set_xlabel(\u0026#39;Date\u0026#39;) # Adjust layout plt.tight_layout() plt.show() len(res[\u0026#39;股票代號\u0026#39;].unique()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q 0~20\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\r\u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal PEG ver. \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt;= 0.7) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt;= 0.9) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q, PEG 0.7~0.9\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax1.legend() signal_dates = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values ax1.vlines(x=signal_dates, label=\u0026#39;signal\u0026#39;) sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values preview_res.loc[\u0026#39;2330\u0026#39;] res_indexPE = res.merge(IndexPE_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;])) IndexPE_res.columns res_indexPE[\u0026#39;股票代號\u0026#39;].unique() sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20030701\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20101231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20101231\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20191231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] i = 1 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20121231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20240509\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] i = 4 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20161231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20231109\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ticker = sub[\u0026#39;股票代號\u0026#39;].iloc[-1] ax1.set_title(f\u0026#39;Index PE vs {ticker}_forward{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;], label=f\u0026#39;{ticker}_PE_{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;agg_PE_{i}Q\u0026#39;], label=f\u0026#39;index_PE_{i}Q\u0026#39;) ax1.legend() ticker = (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) q = 4 tmp = pd.DataFrame() for i in [2, 4, 6, 8]: signal = (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026gt;res_indexPE[f\u0026#39;agg_PE_{q}Q\u0026#39;]) \u0026amp; (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026lt;res_indexPE[f\u0026#39;q{i}0\u0026#39;]) # tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() # res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].describe() tmp cumsum or rolling min/max + shift 就可以了\ndef rolling_max(df): \u0026#39;\u0026#39;\u0026#39; groupby ticker \u0026#39;\u0026#39;\u0026#39; for i in range(1, 5): df[f\u0026#39;{i}_cummax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].cummax().shift(1) df[f\u0026#39;{i}_cummin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].cummin().shift(1) df[f\u0026#39;{i}_cummean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].expanding().mean().shift(1) df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(20).max().shift(1) df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).min().shift(1) df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).mean().shift(1) df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(12).max().shift(1) df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).min().shift(1) df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).mean().shift(1) df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(40).max().shift(1) df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).min().shift(1) df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).mean().shift(1) return df pe_res = pe_res.groupby(\u0026#39;股票代號\u0026#39;).apply(rolling_max).reset_index(drop=True) # cumsum 至上一季 PE最高值, cumsum 至上一季 PE最低值, rolling 5y 至上一季 PE最高值, rolling 5y 至上一季 PE最低值 pe_res.loc[(pe_res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) , [\u0026#39;年季\u0026#39;, \u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] 把 截至上一季 PE的高低點 算出來後 與股價merge combine_df = combine_df.merge(pe_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), right_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_MINMAX\u0026#39;)) combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;) , [\u0026#39;日期\u0026#39;,\u0026#39;PE_1Q\u0026#39; ,\u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2454\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;knowNext1Q\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;, \u0026#39;1_rolling5ymean_PE\u0026#39;]].dropna() for i in range(1, 5): combine_df[f\u0026#39;knowNext{i}Q_5y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummean_PE\u0026#39;] # 在知曉下一季EPS後 利用過往3季 + 未來1季 去算年度EPS # 在用該EPS 與當下股價計算 預知PE # 期間預知PE的min, max 將獨立出來 combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;1_max_PE\u0026#39;, \u0026#39;1_min_PE\u0026#39;, \u0026#39;1_mean_PE\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] 繪製本益比河流圖時 河流應為過去一段時間的min, max ex : under 知曉下一Q EPS的情況下\n過去10年 所有在知曉下一Q對應的EPS\nmin, max 作為河流 對照如今的 預知PE\n可以try 的財務指標\n存貨(千) 研發費用(千) PPE (不動產相關的變化) 先做圖 在想要怎麼辦\ncombine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] combine_df.columns[180:210] combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub.reset_index(drop=True, inplace=True) def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2)) * (data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9): data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 0 return data signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal).reset_index(drop=True) signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal_reverse).reset_index(drop=True) def vector_backtest_delay_entering(df, delay_days): # prodction ver. # input: df, 需要有signal columns, output : [{trade_data1}, {trade_data2}, ...] (list中包含多個dict) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4](cumsum) # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index ## 想要include 最新持有的狀態 -\u0026gt; 若是最後一個row 的連續持有日期 \u0026gt;=4 (3個訊號 隔日才會買進 目前沒有持有) ## return的計算 要改 if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 用來確認退場reaso # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; if len(group) \u0026lt;= delay_days: # 訊號數不足 不會進場 continue else: group.reset_index(drop=True, inplace=True) group = group.iloc[delay_days::] # extract info from group trading_dict = { \u0026#39;股票代號\u0026#39;: group[\u0026#39;股票代號\u0026#39;].iloc[-1], \u0026#39;買入日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[0], \u0026#39;賣出日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[-1], \u0026#39;買入價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].iloc[0], \u0026#39;賣出價\u0026#39; : group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1], \u0026#39;期間最高價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].max(), \u0026#39;持有天數\u0026#39; : len(group), \u0026#39;持有狀態\u0026#39; : \u0026#39;history\u0026#39;, \u0026#39;return\u0026#39; : (group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1]/group[\u0026#39;次日收盤價\u0026#39;].iloc[0]) - 1, } event_list_all.append(trading_dict) # production情況下 每日最新一個group的狀況不一定 \u0026#39;\u0026#39;\u0026#39; 原本是收盤後跑 下午3點跑 改為開盤前 早上8點跑 這樣昨天的data一定更新好了 故 持有狀態的用詞修改 從buy_tomorrow -\u0026gt; buy_today \u0026#39;\u0026#39;\u0026#39; return event_list_all vector_backtest_delay_entering(sub, 0) res = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) res import pandas as pd import numpy as np # Simulated data with multiple cycles dates = pd.to_datetime([ \u0026#39;2024-01-01\u0026#39;, \u0026#39;2024-01-02\u0026#39;, \u0026#39;2024-01-03\u0026#39;, \u0026#39;2024-01-04\u0026#39;, \u0026#39;2024-01-05\u0026#39;, \u0026#39;2024-01-06\u0026#39;, \u0026#39;2024-01-07\u0026#39;, \u0026#39;2024-01-08\u0026#39;, \u0026#39;2024-01-09\u0026#39;, \u0026#39;2024-01-10\u0026#39;, \u0026#39;2024-01-11\u0026#39;, \u0026#39;2024-01-12\u0026#39;, \u0026#39;2024-01-13\u0026#39;, \u0026#39;2024-01-14\u0026#39;, \u0026#39;2024-01-15\u0026#39;, \u0026#39;2024-01-16\u0026#39;, \u0026#39;2024-01-17\u0026#39;, \u0026#39;2024-01-18\u0026#39;, \u0026#39;2024-01-19\u0026#39;, \u0026#39;2024-01-20\u0026#39; ]) # Simulated P/E ratios data = pd.DataFrame({ \u0026#39;PE_ratio\u0026#39;: [20, 21, 19, 22, 23, 10, 9, 11, 14, 16, 18, 20, 35, 36, 10, 9, 12, 15, 18, 20], \u0026#39;Adj Close\u0026#39;: np.random.randn(len(dates)) * 10 + 100 }, index=dates) # Parameters lower_bound = 10 upper_bound = 35 # Initialize the signal and state data[\u0026#39;Signal\u0026#39;] = 0 data.loc[(data[\u0026#39;PE_ratio\u0026#39;] \u0026lt;= lower_bound), \u0026#39;Signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for i in range(len(data)): pe_ratio = data.iloc[i][\u0026#39;PE_ratio\u0026#39;] if state == 0: # Normal period if pe_ratio \u0026lt;= lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if pe_ratio \u0026gt; lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if pe_ratio \u0026gt;= upper_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 0 state = 0 else: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 print(\u0026#34;Filtered Data with Signals:\u0026#34;) print(data) trading_dict = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) # 整理backtest result code = signal_df[\u0026#39;股票代號\u0026#39;].unique().tolist() res_df = pd.DataFrame() for c in code: tmp = trading_dict[c] tmp_df = pd.DataFrame(tmp) if not tmp_df.empty: res_df = pd.concat([res_df, tmp_df], ignore_index=True) code res_df[\u0026#39;precision\u0026#39;] = res_df[\u0026#39;return\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) res_df[[\u0026#39;return\u0026#39;, \u0026#39;precision\u0026#39;,\u0026#39;持有天數\u0026#39;]].describe() res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe() for i in code: print(i) print(res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==i, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe()) trading_dict[\u0026#39;2059\u0026#39;] sub[\u0026#39;forwardPE\u0026#39;].expanding().std() # combine_df = price_df.merge(resample_mon_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) columns 展示 combine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] # Create subplots without shared axes fig, axes = plt.subplots(3, 3, figsize=(12, 8)) # Flatten the axes array for easy iteration axes = axes.flatten() # Group by \u0026#39;Stock\u0026#39; and plot each group in a separate subplot for ax, (name, group) in zip(axes, combine_df.groupby(\u0026#39;股票代號\u0026#39;)): ax.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;收盤價\u0026#39;], label=\u0026#39;Price\u0026#39;) ax.set_title(name) ax.set_xlabel(\u0026#39;Date\u0026#39;) # ax.set_ylabel(\u0026#39;Price\u0026#39;, color=\u0026#39;blue\u0026#39;) ax.legend(loc=2) # Create a secondary y-axis and plot \u0026#39;Volume\u0026#39; ax2 = ax.twinx() ax2.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;稅後純益率(%)\u0026#39;], label=\u0026#39;net profit ratio\u0026#39;, color=\u0026#39;orange\u0026#39;, alpha=0.6) # ax2.set_ylabel(\u0026#39;monthly rev\u0026#39;, color=\u0026#39;green\u0026#39;) ax2.legend(loc=3) # Set axis colors to match the data they represent ax.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;blue\u0026#39;) ax2.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;green\u0026#39;) # Adjust layout to prevent overlap plt.tight_layout() # Show the plot plt.show() combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;, \u0026#39;近三月合併營收(千)\u0026#39;].plot() combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;] image_2024-08-15_11-38-01.png\rfig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;2317\u0026#39;) ax1.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;近12月累計合併營收(千)\u0026#39;], label=\u0026#39;12m_rev_agg\u0026#39;, color=\u0026#39;orange\u0026#39;) ax1.legend(loc=1) 指標相關聯 我覺得應該不只是財務數據 也有其他的東西但我們無法access\n籌碼相關, 分析師估值等\n但以我目前的情況 應該是做估值 並建立買賣點\n-\u0026gt; 存貨\n大概看了一下 營收的趨勢整體多為向上，股價也是 但若將週期縮小至2-3個月 營收與股價背離的情況很常發生\n判斷營收成長 or 衰退的趨勢 其time frame也要抓好\n畢竟營收整個趨勢變化較慢 但方向較穩定 但股價有更多雜訊因素\nsub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = sub[(~sub[\u0026#39;3m_diff\u0026#39;].isna()) \u0026amp; (~sub[\u0026#39;12m_diff\u0026#39;].isna())] sub.isna().sum() combine_df.columns[-60:-30] sub[\u0026#39;optimize\u0026#39;] = (sub[\u0026#39;3m_diff\u0026#39;] \u0026gt; sub[\u0026#39;12m_diff\u0026#39;]).apply(lambda x : 1 if x else 0) sub[\u0026#39;近三月合併營收(千)\u0026#39;] sub[\u0026#39;3m_diff\u0026#39;] 694442123 - 673510177 參考 ","date":"2025-02-07T23:02:53+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/final_test2/","title":"Final_test2"},{"content":" 安裝與設定Firebase CLI 安裝CLI\ncurl -sL https://firebase.tools | bash Set path for zsh on Mac\nRun vim ~/.zshrc Press i Paste export PATH=\u0026quot;$PATH\u0026quot;:\u0026quot;$HOME/.pub-cache/bin\u0026quot; Press esc Type :wq! and press enter 登入帳號\nfirebase login 執行Firebase CLI 安裝Flutter套件\ndart pub global activate flutterfire_cli 在 Flutter 專案的根目錄中執行下列指令\nflutterfire configure --project=專案名稱 初始化Firebase 修改main.dart\nimport \u0026#39;package:firebase_core/firebase_core.dart\u0026#39;; import \u0026#39;firebase_options.dart\u0026#39;; Future\u0026lt;void\u0026gt; main() async { WidgetsFlutterBinding.ensureInitialized(); await Firebase.initializeApp(options: DefaultFirebaseOptions.currentPlatform); runApp(FlashChat()); } 開啟驗證功能 Go to Firebase Console \u0026gt; Authentication Turn on one or more authentication methods 使用註冊功能 註冊按鈕\nfinal FirebaseAuth _auth = FirebaseAuth.instance; String email; String password; //... ElevatedButton( title: \u0026#39;Register\u0026#39;, onPress: () async { try { var result = await _auth.createUserWithEmailAndPassword( email: email, password: password); var user = result.user; if (user != null) { Navigator.pushNamed(context, ChatScreen.id); } } catch (error) { print(error); } } ) 使用登入功能 登入按鈕\nfinal FirebaseAuth _auth = FirebaseAuth.instance; String email; String password; //... ElevatedButton( title: \u0026#39;Login\u0026#39;, onPress: () async { try { var result = await _auth.signInUserWithEmailAndPassword( email: email, password: password); var user = result.user; if (user != null) { Navigator.pushNamed(context, ChatScreen.id); } } catch (error) { print(error); } } ) 使用登出功能 final FirebaseAuth _auth = FirebaseAuth.instance; //... ElevatedButton( title: \u0026#39;Logout\u0026#39;, onPress: () async { _auth.signOut(); Navigator.pop(context); } ) 取得當前用戶 取得登入者狀態，覆寫在initState內\nfinal FirebaseAuth _auth = FirebaseAuth.instance; User LoggedInUser; @override void initState() { getCurrentUser(); super.initState(); } //取得目前用戶 void getCurrentUser() async { try { final user = await _auth.currentUser; print(user.email); if (user != null) { LoggedInUser = user; } } catch (error) { print(error); } } 參考 https://firebase.google.com/docs/cli?authuser=0\u0026hl=zh#install_the_firebase_cli\nhttps://stackoverflow.com/questions/71487625/how-can-i-resolve-zsh-command-not-found-flutterfire-in-macos\nhttps://stackoverflow.com/questions/68023874/firebase-configuration-not-found\nhttps://stackoverflow.com/questions/70232931/firebaseoptions-cannot-be-null-when-creating-the-default-app/70234018#70234018\n","date":"2023-01-23T01:19:38+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2023/20230123_firebase%E8%BA%AB%E4%BB%BD%E9%A9%97%E8%AD%89%E7%B3%BB%E7%B5%B1%E5%A5%97%E7%94%A8%E5%9C%A8flutter.md/","title":"Firebase身份驗證系統"},{"content":" 筆記 pwd 當前資料夾\nls 當前目錄下的資料\n-l 長格式\n-lh 長格式，人類閱讀\ncd 切換資料夾 cd folder/file\nman 查看使用說明 man ls\ntouch 建立新檔案 touch file\nrm 刪除檔案 rm file\n刪除資料夾rm -rf folder\ncp 複製檔案 cp pic.png picCopy.png\npic.png複製目標\npicCopy.png複製出來的檔案\ncp -R複製整個目錄\nmv 移動檔案至資料夾下mv file folder\n將檔案移至當前目錄mv folder/file .\n將檔案改名mv file01 file02\nmkdir 建立資料夾mkdir newFolder\ncat 查看檔案cat test.txt\n參考 ","date":"2023-01-20T15:43:55+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2023/20230120_linux%E7%B0%A1%E6%98%93%E6%8C%87%E4%BB%A4.md/","title":"Linux簡易指令"},{"content":" 單純的匯入憑證 1.功能欄收尋mmc，開啟主控台。\n2.檔案-\u0026gt;新增/移除坎入式管理單元\n3.新增憑證至主控台根目錄下\n4.點擊個人-\u0026gt;憑證\n5.動作-\u0026gt;所有工作-\u0026gt;匯入\n6.匯入憑證p12檔或cert檔\n","date":"2023-01-11T17:41:47+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2023/20230111_%E5%8C%AF%E5%85%A5%E6%86%91%E8%AD%89%E8%87%B3%E9%9B%BB%E8%85%A6%E4%B8%A6%E6%AA%A2%E6%9F%A5%E6%86%91%E8%AD%89%E6%97%A5%E6%9C%9F.md/","title":"匯入憑證至電腦並檢查憑證日期"},{"content":" 筆記 因應各種不同狀況需要查詢不同的資料\n記錄一下比較不常用的函數與功能\n非對稱式金鑰的加解密 建置金鑰\nCREATE ASYMMETRIC KEY MY_ASY_KEY WITH ALGORITHM = RSA_512 ENCRYPTION BY PASSWORD = \u0026#39;asy_pwd\u0026#39; DECLARE @MY_ASY_PWD = N\u0026#39;asy_pwd\u0026#39; 加密\n--[encValue]的型態是varbinary(max) SET [encValue] = ENCRYPTBYASYMKEY( ASYMKEY_ID( \u0026#39;金鑰名稱\u0026#39;), N\u0026#39;加密的參數\u0026#39;) 要注意型態(nvarchar要加N)，避免解密的時候錯誤\n加密\nSELECT CONVERT( nvarchar(150), ENCRYPTBYASYMKEY( ASYMKEY_ID( \u0026#39;金鑰名稱\u0026#39;), [encValue], @MY_ASY_PWD)) Query五分鐘內的資料 SELECT * FROM [xxTable] WHERE [CreateTime] \u0026gt; DATEADD(MINUTE, -5, GETDATE()) 使用DATEADD增加-5分鐘，取得前五分鐘的時間\n如果沒有Update的話就INSERT一筆 UPDATE [用戶資料表] SET [PhoneNumber] = @新的手機號碼 WHERE [UserID] = @用戶ID IF @@ROWCOUNT = 0 INSERT INTO [用戶資料表]([UserID], [PhoneNumber]) VALUES(@用戶ID, @新的手機號碼) @@ROWCOUNT 代表的是受影響的筆數\n連續Query 要查詢用戶A最後登入的手機\n且那隻手機最後登入的是用戶A(手機沒有被用戶B登入過)\nBEGIN DECLARE @用戶ID varchar(10) = ? DECLARE @裝置ID varchar(50) DECLARE @裝置最後使用用戶ID varchar(10) --將查詢到的DeviceId賦值至@裝置ID SELECT TOP 1 @裝置ID = [DeviceID] FROM [Phone_Log_Table] WHERE UserID = @用戶ID ORDER BY [UpdateTime] DESC --用@裝置ID查詢最後的UserID，並賦值至@裝置最後使用用戶ID SELECT TOP 1 @裝置最後使用用戶ID = [UserID] FROM [Phone_Log_Table] WHERE [DeviceID] = @裝置ID ORDER BY [UpdateTime] DESC --回傳新的Table SELECT @用戶ID AS UserID @裝置ID AS DeviceID @裝置最後使用用戶ID AS LastDeviceUserID END 參考 ","date":"2022-10-14T11:05:45+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20221014_sqlsever%E5%A4%A7%E8%A3%9C%E5%B8%96.md/","title":"SqlSever大補帖"},{"content":" 筆記 部落格要一直寫下去是不間單，工作一忙回到家倒頭就睡，沒時間跟精神來記錄一下\n我本人基本上沒有在使用IG，但內心也有一個要發廢文的衝動\n把這邊當IG在用來的心態寫東西\n記錄一下Hugo操作的指令\n免得下次又要再去查怎麼用\nHugo指令 新增文章 hugo new post/\u0026lt;md file path\u0026gt; 這樣就可以在content/post/下看到新創的markdown檔\n文章調整 基本上我所有的文章都是從jupyter轉換過來\n在用hugo new post create好md檔之後 得把jupyter轉換過的md檔複製到 hugo格式中 筆記的位置 需要run 這個指令under root (content folder的上一層)\njupyter nbconvert --to markdown --output-dir=\u0026lt;output dir\u0026gt; \u0026lt;ipynb file\u0026gt; 有一個問題是 轉換後圖會被存在另一個folder中\n假設你的jupyter file叫 test.ipynb 在轉換的output dir中還會有一個folder 叫 test_files.ipynb 此時可以把你的圖片都丟到 static/images中 並用以下command line\nsed -i \u0026#39;\u0026#39; \u0026#39;s/your_notebook_files\\//\\/images\\//g\u0026#39; your_notebook.md 開幾本地server hugo server 先在本地測試預覽用的\n打包成靜態網頁檔 hugo hugo -d ../GitHub/MindBreaker3310.github.io 執行完後，打包的靜態網頁會輸出在public/資料夾下\n或是給他destination flag輸出到指定資料夾\nGitHub Page相關 我這邊是打包成靜態網頁檔直接蓋掉Github Page對應在本機的檔案\n接著commit push收工\nMarkDown相關 \u0026gt;## MarkDown相關\n段落標題，如上\n### 段落內的小區塊\n段落內的小區塊 #### 段落的段落\n段落的段落 **就是粗體** *就是斜體*\n就是粗體 就是斜體\n+ 列表的Fu\n列表的Fu ![圖片下方的文字](images/圖片檔名.jpg)\n上圖片\r其他有需要再去查吧 https://markdown.tw/\n後記 希望未來還能持續更新，GOGO~\n","date":"2022-09-28T14:24:26+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220928_blog%E6%93%8D%E4%BD%9C%E6%89%8B%E5%86%8A.md/","title":"Blog操作手冊"},{"content":" 前言 之前寫了關於RabbitMQ的筆記\n其實是記錄如何使用masstransit套件來快速的傳遞message\n這個套件支援的功能與能夠設定的細節當然是沒有原生來得好\n所以重新學習一下如何使用官方的套件\nHello World! 實作最簡單的\nProducer直接將Message丟入Queue再由Consumer處理完畢\n架構圖\r發送端程式碼 class Send { public static void Main() { var factory = new ConnectionFactory() { HostName = \u0026#34;localhost\u0026#34; }; using (var connection = factory.CreateConnection())//連線至rabbitmq server using (var channel = connection.CreateModel())//建立模型 { //宣告queue(如果不存在才會宣告) channel.QueueDeclare(queue: \u0026#34;hello\u0026#34;,//queue名稱 durable: false, exclusive: false, autoDelete: false, arguments: null); //要傳送的訊息 string message = \u0026#34;Hello World!\u0026#34;; var body = Encoding.UTF8.GetBytes(message); //傳送至queue channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: \u0026#34;hello\u0026#34;,//queue名稱 basicProperties: null, body: body); Console.WriteLine(\u0026#34; [x] Sent {0}\u0026#34;, message); } Console.WriteLine(\u0026#34; Press [enter] to exit.\u0026#34;); Console.ReadLine(); } } 接收端程式碼 class Receive { public static void Main() { var factory = new ConnectionFactory() { HostName = \u0026#34;localhost\u0026#34; }; using (var connection = factory.CreateConnection()) using (var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \u0026#34;hello\u0026#34;, durable: false, exclusive: false, autoDelete: false, arguments: null); //建立Consumer var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; //ea = EventArgs { var body = ea.Body.ToArray(); var message = Encoding.UTF8.GetString(body); Console.WriteLine(\u0026#34; [x] Received {0}\u0026#34;, message); }; //回傳Ack channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: true, consumer: consumer); Console.WriteLine(\u0026#34; Press [enter] to exit.\u0026#34;); Console.ReadLine(); } } } Work queues 發送端基本一樣，但是可以有多個接收端，避免被單一個Consumer卡住\n架構圖\r發送端程式碼 class NewTask { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \u0026#34;localhost\u0026#34; }; using (var connection = factory.CreateConnection())//連線至rabbitmq server using (var channel = connection.CreateModel())//建立模型 { //宣告queue(如果不存在才會宣告) channel.QueueDeclare(queue: \u0026#34;task-queue\u0026#34;, durable: true,//重開RabbitMQ仍會存在 exclusive: false, autoDelete: false, arguments: null); //要傳送的訊息 var message = GetMessage(args); var body = Encoding.UTF8.GetBytes(message); //傳送至queue channel.BasicPublish(exchange: \u0026#34;\u0026#34;, routingKey: \u0026#34;task-queue\u0026#34;,//queue名稱 basicProperties: null, body: body); Console.WriteLine(\u0026#34; [x] Sent {0}\u0026#34;, message); } Console.WriteLine(\u0026#34; Press [enter] to exit.\u0026#34;); Console.ReadLine(); } private static string GetMessage(string[] args) { //如果輸入參數為空，代入Hello World! return args.Length \u0026gt; 0 ? string.Join(\u0026#34; \u0026#34;, args) : \u0026#34;Hello World!\u0026#34;; } } 這裡宣告的Queue durable是true，所以當RabbitMQ server重開後，仍會存在。\n接收端程式碼 class Worker { public static void Main(string[] args) { var factory = new ConnectionFactory() { HostName = \u0026#34;localhost\u0026#34; }; using (var connection = factory.CreateConnection()) using (var channel = connection.CreateModel()) { channel.QueueDeclare(queue: \u0026#34;task-queue\u0026#34;, durable: true, exclusive: false, autoDelete: false, arguments: null); var consumer = new EventingBasicConsumer(channel); consumer.Received += (model, ea) =\u0026gt; { var body = ea.Body.ToArray(); var message = Encoding.UTF8.GetString(body); Console.WriteLine(\u0026#34; [x] Received {0}\u0026#34;, message); //增加延遲 int dots = message.Split(\u0026#39;.\u0026#39;).Length - 1; Thread.Sleep(dots * 1000); Console.WriteLine(\u0026#34; [x] Done\u0026#34;); //處理中返回錯誤訊息 //channel.BasicAck(deliveryTag: ea.DeliveryTag, multiple: false); }; //告入rabbitMQ 已經處理完畢，可以釋放空間。 channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, autoAck: true, consumer: consumer); //錯誤的話 //channel.BasicConsume(queue: \u0026#34;hello\u0026#34;, // autoAck: false, // consumer: consumer); Console.WriteLine(\u0026#34; Press [enter] to exit.\u0026#34;); Console.ReadLine(); } } } 參考 ","date":"2022-07-06T15:04:29+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220706_rabbitmq%E9%87%8D%E6%96%B0%E7%90%86%E8%A7%A3.md/","title":"RabbitMQ重新理解"},{"content":" 筆記 記錄一下這個特別的controller寫法\n通通都只有一個入口，傳入加密的電文，解析電文後\n會得知要執行的class名稱與DLL名稱\n由名稱字串到執行功能的步驟\n來做到動態的呼叫的方法\n使用反射\n不囉說 直接看程式\n//xxxService 專案名稱 //xxxFolder 資料夾名稱 //xxxClass 名稱 //\u0026#34;xxxClass的位置, DLL名稱(通常是專案名稱)\u0026#34; string targetFile = \u0026#34;xxxService.xxxFolder.xxxClass, xxxService\u0026#34;; //方法名稱 string targetMethod = \u0026#34;DoSomething\u0026#34;; //傳入參數 Object[] args = [{xxxInputObject}]; //讀取dll Type dll = Type.GetType(target); //實作dll Object InstanceObj = dll.InvokeMember(null, BindingFlags.DeclaredOnly | //invokeAttr一個或多個BindingFlags組成，會指定執行搜尋的方式 BindingFlags.Public | BindingFlags.NonPublic | BindingFlags.Instance | BindingFlags.CreateInstance, null, null, null); //執行實作物件的方法 Object result = dll.InvokeMember(targetMethod,//要呼叫的屬性或方法名稱 BindingFlags.InvokeMethod, //invoke參數 null, InstanceObj, //要執行的obj args); //傳入的參數 //回傳執行結果 return result; 參考 https://www.dotblogs.com.tw/joysdw12/2012/09/13/74761\n","date":"2022-06-29T10:48:46+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220629_%E5%8F%8D%E5%B0%84%E6%96%B9%E6%B3%95%E7%B4%80%E9%8C%84.md/","title":"C#反射方法紀錄"},{"content":" 筆記 還不會在dcoker內透過mongo express(GUI工具)同時連線多個MongoDB，只能先用指令先擋著了。\n常用查看資料內容的方法大致如下\n其他用在再看文檔就好\n//使用mongo cli mongo //顯示資料庫 show dbs //使用資料庫(myDb為例) use myDb //讀取資料 db.myCollection.find() db.myCollection.find().pretty() db.get(\u0026#39;myCollection\u0026#39;).find() db.get(\u0026#39;myCollection\u0026#39;).find().pretty() //有條件的讀取 db.myCollection.find({條件}, {欄位}) db.myCollection.find({name: \u0026#39;Max\u0026#39;}, {name : 1, age : 1}) db.myCollection.find({name: \u0026#39;Max\u0026#39;}, {name : 1, age : 1, height : 1}) // \u0026gt;18歲 db.myCollection.find({age: {$gt : 18} }, {name : 1, age : 1}) // \u0026gt;=18歲 db.myCollection.find({age: {$gte : 18} }, {name : 1, age : 1}) // \u0026lt;18歲 db.myCollection.find({age: {$lt : 18} }, {name : 1, age : 1}) // \u0026lt;=18歲 db.myCollection.find({age: {$lte : 18} }, {name : 1, age : 1}) 參考 https://www.mongodb.com/docs/v4.4/crud/\nhttps://www.runoob.com/mongodb/mongodb-operators.html\n","date":"2022-06-27T14:07:21+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220627_mongodb_cli%E6%93%8D%E4%BD%9C.md/","title":"MongoDb Cli 讀取資料"},{"content":" 筆記 老闆最近希望讓我去開發與設計一個管理公司內部合約與公文的檔管系統\n以前在學校學習的已經還給老師啦XD\n趁這個機會複習一下\n一個系統開發不只包含了coding也同時有設計、品管、預算、測試、寫文件、上線與維護\n常用的開發流程分為Waterfall與Agile\nWaterfall Waterfall最適合幾乎確定需求且開發中不會有太多變動\n主要可以分為五個步驟\n收集與分析需求 決定系統架構 實作 驗證 維護 收集與分析需求 與利益相關者保持距離並徹底紀錄需求\n下面已建立note app為例\n可以使用“必須”來條列式需求\n功能需求：\nAPP必須可以記錄文字，也可以插入圖片或手寫塗鴉。 部分筆記內容必須設定密碼，避免被別人看見。 筆記內容必須可以自動同步到雲端硬碟上。 非功能性需求：\n必須支援ios10或更新版 必須減少不必要的資料傳輸，以降低伺服器的負擔 從功能需求我們可以分析出三個情境(epic)\n筆記的建立與編輯 隱私問題 雲端同步 情境1：筆記建立與編輯\n身為一個user，我要可以快速記下筆記。 身為一個user，我要能把圖片以附件的方式附上，避免影響到筆記的排版。 身為一個user，我要有手寫功能，讓我的筆記更有溫度。 情境2：隱私\n身為一個user，我要建立隱私筆記，只有我能存取它。 身為一個user，我要用密碼保護我的隱私筆記。 情境3：雲端同步\n身為一個user，我要打開app時，資料就已經同步成最新版。 身為一個user，我要能夠自動同步到雲端硬碟上，隨時備份不怕資料不見。 依照情境畫出Use Cases圖\n筆記建立與編輯\r隱私\r雲端同步\r畫出class之間的關聯圖\n畫出流程圖\n決定系統架構 這個步驟就像是建築的藍圖一樣，設計必須清晰明瞭\n要用什麼package/components？ 每個component的type是什麼？ 這些type怎麼互動或達成功能所需 我們的系統安全嗎？ 效能如何？ 如何處理錯誤？ 我們的系統穩固嗎？ 之後會不會擴展？ 使用哪些第三方套件？ 實作＆測試 就是實作，發與測試，平常在做的。\n交給User測試功能性、安全性、效能、實用性\n這兩個步驟會一直重複到沒有bug\n維護 在這個階段就是抓抓小蟲\n小幅度強化功能\nAgile 敏捷開發是為了因應需求一直變動，沒辦法再開發之前就知道最終的產品會是長什麼樣子，透過不斷重複的週期(Sprint)循環，每次都一點點收集分析資料、設計、實作、測試，每一個循環就像小瀑布一樣。\n常聽到的Scrum就是一種實作Agile的方式\n","date":"2022-01-26T13:31:49+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220126_%E5%AD%B8%E7%BF%92uml.md/","title":"學習UML"},{"content":" 筆記 Api Gateway的設計有好幾種，通常來說一般只用一個Api Gw來當一個入口並不是個好主意，可以設計成SPA網頁用一個、手機App用一個、傳統網站用一個。\n這邊使用的Api Gw是Ocelot\nOcelot是一個輕量化、容易擴充、開源的專案👍\n前置作業 開啟新專案 \u0026raquo; Empty .Net Project\nNuGet安裝必要套件Ocelot\n如果要使用快取功能的話，還要安裝Ocelot.Cache.CacheManager\n註冊與使用Ocelot服務 要使用快取功能才要加上AddCacheManager\npublic void ConfigureServices(IServiceCollection services) { services.AddOcelot() .AddCacheManager(settings =\u0026gt; settings.WithDictionaryHandle()); } public async void Configure(IApplicationBuilder app, IWebHostEnvironment env) { //前略... await app.UseOcelot(); } 建立閘道路由json檔案 建立一個類似appsettings.json依照環境是Development還是Debug來覆寫的檔案\nocelot.json(維持空的) ocelot.Development.json ocelot.Local.json(本地測試) 依照命名VS會自動合併\n專案的環境變數ASPNETCORE_ENVIRONMENT要設定成Local\n設定Program.cs public static IHostBuilder CreateHostBuilder(string[] args) =\u0026gt; Host.CreateDefaultBuilder(args) .ConfigureAppConfiguration((hostingContext, config) =\u0026gt; { //會依照ASPNETCORE_ENVIRONMENT來讀取不同的檔案 config.AddJsonFile($\u0026#34;Ocelot.{hostingContext.HostingEnvironment.EnvironmentName}.json\u0026#34;, true, true); }) .ConfigureWebHostDefaults(webBuilder =\u0026gt; { webBuilder.UseStartup\u0026lt;Startup\u0026gt;(); }) .ConfigureLogging((hostBuilderContext, loggingBuilder) =\u0026gt; { loggingBuilder.AddConfiguration(hostBuilderContext.Configuration.GetSection(\u0026#34;Logging\u0026#34;)); loggingBuilder.AddConsole(); loggingBuilder.AddDebug(); }); 設定閘道路由 在這邊設定連近來與連出去的位置，還可以加上額外設定，FileCacheOptions(檔案快取)、RateLimitOptions(流量管控)等等\u0026hellip;\n{ \u0026#34;Routes\u0026#34;: [ //Catalog API { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/api/v1/Catalog\u0026#34;,//要連接到的api路由 \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;DownstreamHostAndPorts\u0026#34;: [//要連到的server位置 { \u0026#34;Host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;Port\u0026#34;: \u0026#34;8000\u0026#34; } ], \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/Catalog\u0026#34;,//外面連到閘道的路由 \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;POST\u0026#34;, \u0026#34;PUT\u0026#34; ],//允許的方法 \u0026#34;FileCacheOptions\u0026#34;: { \u0026#34;TtlSeconds\u0026#34;: 30 }//檔案快取選項:設定存活時間 }, { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/api/v1/Catalog/{id}\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;DownstreamHostAndPorts\u0026#34;: [ { \u0026#34;Host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;Port\u0026#34;: \u0026#34;8000\u0026#34; } ], \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/Catalog/{id}\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;GET\u0026#34;, \u0026#34;DELETE\u0026#34; ] }, //Basket API { \u0026#34;DownstreamPathTemplate\u0026#34;: \u0026#34;/api/v1/Basket/Checkout\u0026#34;, \u0026#34;DownstreamScheme\u0026#34;: \u0026#34;http\u0026#34;, \u0026#34;DownstreamHostAndPorts\u0026#34;: [ { \u0026#34;Host\u0026#34;: \u0026#34;localhost\u0026#34;, \u0026#34;Port\u0026#34;: \u0026#34;8001\u0026#34; } ], \u0026#34;UpstreamPathTemplate\u0026#34;: \u0026#34;/Basket/Checkout\u0026#34;, \u0026#34;UpstreamHttpMethod\u0026#34;: [ \u0026#34;POST\u0026#34; ], \u0026#34;RateLimitOptions\u0026#34;: { //限制請求量3秒內只有第一筆會被接受 \u0026#34;ClientWhitelist\u0026#34;: [], \u0026#34;EnableRateLimiting\u0026#34;: true, \u0026#34;Period\u0026#34;: \u0026#34;3s\u0026#34;, \u0026#34;PeriodTimespan\u0026#34;: 1, \u0026#34;Limit\u0026#34;: 1 } ], \u0026#34;GlobalConfiguration\u0026#34;: { \u0026#34;BaseUrl\u0026#34;: \u0026#34;http://localhost:5010\u0026#34; } } Gateway Aggregation 聚合模式 概念如圖所示，原本一個加入購物車的活動可能需要用到Catalog.API與Basket.API，需要經過閘道去多次呼叫特定API\n聚合模式下就是提供一個API，這個API會再去呼叫其他多個API\n設定基礎服務 建立新專案後 在appsettings加入要連線的Url\n\u0026#34;ApiSettings\u0026#34;: { \u0026#34;CatalogUrl\u0026#34;: \u0026#34;http://localhost:8001\u0026#34;, \u0026#34;BasketUrl\u0026#34;: \u0026#34;http://localhost:8002\u0026#34;, \u0026#34;OrderingUrl\u0026#34;: \u0026#34;http://localhost:8003\u0026#34; } 在Startup設定HttpClient服務\npublic void ConfigureServices(IServiceCollection services) { services.AddHttpClient\u0026lt;ICatalogService, CatalogService\u0026gt;(c =\u0026gt; c.BaseAddress = new Uri(Configuration[\u0026#34;ApiSettings:CatalogUrl\u0026#34;])); services.AddHttpClient\u0026lt;IBasketService, BasketService\u0026gt;(c =\u0026gt; c.BaseAddress = new Uri(Configuration[\u0026#34;ApiSettings:BasketUrl\u0026#34;])); services.AddHttpClient\u0026lt;IOrderService, OrderService\u0026gt;(c =\u0026gt; c.BaseAddress = new Uri(Configuration[\u0026#34;ApiSettings:OrderingUrl\u0026#34;])); } 建立要呼叫後端API輸入或輸出的model public class OrderResponseModel { public string UserName { get; set; } public decimal TotalPrice { get; set; } // BillingAddress public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; } public string AddressLine { get; set; } public string Country { get; set; } public string State { get; set; } public string ZipCode { get; set; } // Payment public string CardName { get; set; } public string CardNumber { get; set; } public string Expiration { get; set; } public string CVV { get; set; } public int PaymentMethod { get; set; } } 建立後端Service public class OrderService : IOrderService { private readonly HttpClient _client; public OrderService(HttpClient client) { _client = client; } public async Task\u0026lt;IEnumerable\u0026lt;OrderResponseModel\u0026gt;\u0026gt; GetOrdersByUserName(string userName) { var response = await _client.GetAsync($\u0026#34;api/v1/Order/{userName}\u0026#34;); var dataAsString = await response.Content.ReadAsStringAsync().ConfigureAwait(false); return JsonSerializer.Deserialize\u0026lt;List\u0026lt;OrderResponseModel\u0026gt;\u0026gt;(dataAsString, new JsonSerializerOptions { PropertyNameCaseInsensitive = true }); } } 建立Controller Controller被呼叫時，會去呼叫basketService、catalogService與orderService\n[HttpGet(\u0026#34;{userName}\u0026#34;, Name = \u0026#34;GetShopping\u0026#34;)] [ProducesResponseType(typeof(ShoppingModel), (int)HttpStatusCode.OK)] public async Task\u0026lt;ActionResult\u0026lt;ShoppingModel\u0026gt;\u0026gt; GetShopping(string userName) { var basket = await _basketService.GetBasket(userName); foreach (var item in basket.Items) { var product = await _catalogService.GetProductById(item.ProductId); item.ProductName = product.Name; item.Category = product.Category; item.Summary = product.Summary; item.Description = product.Description; item.ImageFile = product.ImageFile; } var orders = await _orderService.GetOrdersByUserName(userName); var shoppingModel = new ShoppingModel() { UserName = userName, BasketWithProduct = basket, Orders = orders }; return Ok(shoppingModel); } 最後在原本的ocelotGateway的josn檔裡面設定這個api的位置就好了\n","date":"2022-01-14T13:20:59+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2022/20220114_apigateway%E7%AD%86%E8%A8%98.md/","title":"APIGateway筆記"},{"content":" 前置作業 RabbitMQ的兔兔icon怪可愛的，可以想像成郵局，可以收信也可以送信，是一堆兔兔幫你送信~🐰\n安裝Docker 透過docker-compose來設定下載，alpine是輕量化體積較小的版本\n#docker-compose.yml abbitmq: image: rabbitmq:3-management-alpine #docker-compose.override.yml rabbitmq: container_name: rabbitmq restart: always ports: - \u0026#34;5672:5672\u0026#34; - \u0026#34;15672:15672\u0026#34; #DashBoard的port docker up上去後，測試看看能不能連線到localhost:15672，可以就會進到登入畫面，第一次直接登入帳密都是guest。\nMassTransit🚎 集體搭車去RabbitMQ的概念(?)，這是專給.Net用的套件，讓我們更簡單的去使用RabbitMQ的功能\n建立Event製造機 建立EventBus.Messages項目專案\n安裝必要套件\n\u0026lt;PackageReference Include=\u0026#34;MassTransit\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MassTransit.AspNetCore\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MassTransit.RabbitMQ\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; 建立Base Event有ID與建構日期，讓其他Event去繼承它。\npublic class IntegrationBaseEvent { public IntegrationBaseEvent() { Id = Guid.NewGuid(); CreationDate = DateTime.UtcNow; } public IntegrationBaseEvent(Guid id, DateTime createDate) { Id = id; CreationDate = createDate; } public Guid Id { get; private set; } public DateTime CreationDate { get; private set; } } 建立結帳Event\npublic class BasketCheckoutEvent : IntegrationBaseEvent { public string UserName { get; set; } public decimal TotalPrice { get; set; } // BillingAddress public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; } public string AddressLine { get; set; } public string Country { get; set; } public string State { get; set; } public string ZipCode { get; set; } // Payment public string CardName { get; set; } public string CardNumber { get; set; } public string Expiration { get; set; } public string CVV { get; set; } public int PaymentMethod { get; set; } } 建立Common/EventBusConstants\n設定Queue的名子\npublic class EventBusConstants { public const string BasketCheckoutQueue = \u0026#34;basketcheckout-queue\u0026#34;; } Event發送端 建立好EventBus.Messages後就可以開始來試著發送Event出去\n設定Dependencies添加EventBus.Messages\n安裝必要套件三件組後，在startup裡註冊MassTransit必要服務，並設定使用RabbitMq!\n\u0026lt;PackageReference Include=\u0026#34;MassTransit\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MassTransit.AspNetCore\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; \u0026lt;PackageReference Include=\u0026#34;MassTransit.RabbitMQ\u0026#34; Version=\u0026#34;7.1.6\u0026#34; /\u0026gt; 註冊RabbitMQ服務 //可以看到AddMassTransit需要輸入Action type的參數，就是委託把不確定的動作，交由呼叫端來寫。 services.AddMassTransit(config =\u0026gt; { config.UsingRabbitMq((context, config) =\u0026gt; { //使用高級列隊協議amqp://帳號:密碼@網址:port (方便檢視，應該寫在appsettings) config.Host(\u0026#34;amqp://guest:guest@localhost:5672\u0026#34;); }); }); services.AddMassTransitHostedService(); 建立發送Event的API [Route(\u0026#34;[action]\u0026#34;)] [HttpPost] [ProducesResponseType((int)HttpStatusCode.Accepted)] [ProducesResponseType((int)HttpStatusCode.BadRequest)] public async Task\u0026lt;ActionResult\u0026gt; Checkout([FromBody] BasketCheckout basketCheckout)//雖然說可以直接用BasketCheckoutEvent類型，但是分開寫日後維護上比較輕鬆。 { //取得購物車內總金額 var basket = await _repository.GetBasket(basketCheckout.UserName); if(basket == null) { return BadRequest(); } //建立BasketCheckout Event var eventMessage = _mapper.Map\u0026lt;BasketCheckoutEvent\u0026gt;(basketCheckout); //設定Event裡面的總金額 eventMessage.TotalPrice = basket.TotalPrice; //傳送Event給RabbitMQ await _publishEndpoint.Publish(eventMessage); //清空購物車 await _repository.DeleteBasket(basket.UserName); return Accepted(); } Event接收端 老樣子，安裝必備套件，註冊服務，但是註冊的地方有點不一樣，需要多做一些設定。\nservices.AddMassTransit(config =\u0026gt; { //設定Event處理器BasketCheckoutConsumer(下面會建) config.AddConsumer\u0026lt;BasketCheckoutConsumer\u0026gt;(); config.UsingRabbitMq((busRegistrationContext, rabbitMqBusFactoryConfig) =\u0026gt; { //使用高級列隊協議amqp://帳號:密碼@網址:port rabbitMqBusFactoryConfig.Host(Configuration[\u0026#34;EventBusSettings:HostAddress\u0026#34;]); //設定接收端點(Queue的名子, (端點設定)=\u0026gt;{設定Event處理器} rabbitMqBusFactoryConfig.ReceiveEndpoint(EventBusConstants.BasketCheckoutQueue, endpointConfig =\u0026gt; { endpointConfig.ConfigureConsumer\u0026lt;BasketCheckoutConsumer\u0026gt;(busRegistrationContext); }); }); }); services.AddMassTransitHostedService(); //也別忘記註冊我們的Event處理器 services.AddScoped\u0026lt;BasketCheckoutConsumer\u0026gt;(); 建立Event處理器 裡面的步驟很簡單，先把接收到RabbitMq裡面的Event Map成在Ordering.API可以用的格式，發送給mediator來處理，mediator會自動分類交由正確的的handler來處理接下來的邏輯，最後回傳結果。\n//實作介面IConsumer\u0026lt;要處理的Event\u0026gt;，要與publish過來的Event同class。 public class BasketCheckoutConsumer : IConsumer\u0026lt;BasketCheckoutEvent\u0026gt;// { private readonly IMediator _mediator; private readonly IMapper _mapper; private readonly ILogger\u0026lt;BasketCheckoutConsumer\u0026gt; _logger; public BasketCheckoutConsumer(IMediator mediator, IMapper mapper, ILogger\u0026lt;BasketCheckoutConsumer\u0026gt; logger) { _mediator = mediator ?? throw new ArgumentNullException(nameof(mediator)); _mapper = mapper ?? throw new ArgumentNullException(nameof(mapper)); _logger = logger ?? throw new ArgumentNullException(nameof(logger)); } public async Task Consume(ConsumeContext\u0026lt;BasketCheckoutEvent\u0026gt; context) { var command = _mapper.Map\u0026lt;CheckoutOrderCommand\u0026gt;(context.Message); var result = await _mediator.Send(command); _logger.LogInformation(\u0026#34;BasketCheckoutEvent Consume成功~~ Order Id : {newOrderId}\u0026#34;, result); } } 到這邊就可以在Basket.API產生Event，再透過rabbitmq傳送，最後Event交由Ording.API處理了\n參考 實作官網教學\nRabbitMQ介紹\n","date":"2021-12-28T11:33:55+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211228_rabbitmq%E7%AD%86%E8%A8%98.md/","title":"RabbitMQ筆記"},{"content":" 建立Dockerfile 對專案項目按右鍵 \u0026raquo; Add \u0026raquo; Docker Support \u0026raquo; Linux \u0026raquo; 確定\n該項目下面就會有Dockerfile，裡面是建立容器的指令文字檔\n建立Docker Compose 對專案項目按右鍵 \u0026raquo; Add \u0026raquo; Container Orchestrator Support(容器協調器支援) \u0026raquo; Docker Compose \u0026raquo; Linux \u0026raquo; 確定\n可以將多個container合而為一，也會多一個Docker Compose 項目\n#docker-compose.yml service: orderdb: #加入的service image: mcr.microsoft.com/mssql/server:2019-latest #pull映像檔的位置 #docker-compose.override.yml service: orderdb: container_name: orderdb environment: ACCEPT_EULA: \u0026#34;Y\u0026#34; SA_PASSWORD: \u0026#34;Max4129889\u0026#34; #system administrator密碼 restart: always ports: - \u0026#34;1433:1433\u0026#34; 整合、執行映像檔 在終端機執行Docker-compose\ndocker-compose -f ./docker-compose.yml -f ./docker-compose.override.yml up -d 到這邊基本上就搞定了，查看一下容器有沒有好好運作~\n如果出現ERROR: yaml.parser.ParserError: while parsing a block mapping之類的錯誤\n很有可能是排版有誤，可以透過yml檢視器來進行查看\n出現docker.errors.DockerException: Error while fetching server API version: ('Connection aborted.', ConnectionRefusedError(61, 'Connection refused'))無法連線等問題\n需要先開啟Docker Desktop後再執行\ndocker ps SQL GUI 在windows裡的Visual Studio可以使用Server Explorer直接連線DB進行查看\n在Mac下的Visual Studio貌似沒有這個功能，必須改用別的工具來進行查看\nDBreaver\n免費、好用、支持多種DB，推薦一下~😄\n參考 https://hub.docker.com/_/microsoft-mssql-server\nhttps://docs.microsoft.com/zh-tw/sql/linux/quickstart-install-connect-docker?view=sql-server-ver15\u0026pivots=cs1-bash\nyml檢視器\n","date":"2021-12-27T10:52:40+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211227_docker%E5%AE%B9%E5%99%A8%E5%8C%96_mssqlserver.md/","title":"Docker容器化"},{"content":" nslookup 紀錄一下今天學到的指令，想要查詢網站或是資料庫的ip位置，就可以使用nslookup來查詢，在windows、mac也都可以用。\nMacBook-Air ~ % nslookup www.google.com Server:\t172.20.10.1 Address:\t172.20.10.1#53 Non-authoritative answer: Name:\twww.google.com Address: 142.251.42.228 前面是DNS的位置\nNon-authoritative answer則是代表直接讀取DNS暫存，未認證的答案。\n","date":"2021-12-23T09:46:07+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211223_nslookup%E6%9F%A5%E8%A9%A2ip%E4%BD%8D%E7%BD%AE.md/","title":"nslookup查詢ip位置"},{"content":" 簡單介紹 在先前的簡潔架構Application Layer有寫通用的非同步Repository介面(Asynchronous Generic Repository)\n在這裡面有很多奇怪的東西😱\n先來看看通用的非同步Repository介面長什麼樣子\npublic interface IAsyncRepository\u0026lt;T\u0026gt; where T : EntityBase { Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAllAsync(); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, string includeString = null, bool disableTracking = true); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, List\u0026lt;Expression\u0026lt;Func\u0026lt;T, object\u0026gt;\u0026gt;\u0026gt; includes = null, bool disableTracking = true); Task\u0026lt;T\u0026gt; GetByIdAsync(int id); Task\u0026lt;T\u0026gt; AddAsync(T entity); Task UpdateAsync(T entity); Task DeleteAsync(T entity); } 在GetAsync()裡面有很多東西Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt;、Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt;、List\u0026lt;Expression\u0026lt;Func\u0026lt;T, object\u0026gt;\u0026gt;\u0026gt;\nFunc是Delegate類別，是一種可以reference method的類別，代表可以把方法當作參數丟進來。\nExpression是屬於Linq下的一個類別\nIQueryable\u0026lt;T\u0026gt;對特定已知的類型，查詢功能\nIOrderedQueryable\u0026lt;T\u0026gt;排序後的結果\n所以我們可以這樣呼叫\nIQueryable\u0026lt;T\u0026gt; query = _dbContext.Set\u0026lt;T\u0026gt;(); if (disableTracking) query = query.AsNoTracking(); if (!string.IsNullOrWhiteSpace(includeString)) query = query.Include(includeString); if (predicate != null) query = query.Where(predicate); if (orderBy != null) return await orderBy(query).ToListAsync(); return await query.ToListAsync(); } 參考 ","date":"2021-12-22T15:24:54+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211222_linqexpression.md/","title":"Linq Expression"},{"content":"基礎設施層，將我們Application Layer說的那些處理，連接到資料庫上。\n在這一層我們將使用Entity Framework Core AKA EF Core，EFCore的目的是讓程式設計師能夠以熟習的語言去操作資料庫，而非使用sql語法然後再轉成我們的資料模型。\n先去NuGet裝Microsoft.EntityFrameworkCore.SqlServer，使用.Net 5.0的話版本只支援到5.0.x以下，6.0.0不支援。\nOrdering.API 這跟infrastructure一樣，都是最外面一層，寫一起比較好整理吧\nController 得利於mediator的handler，我們整個controller就是一個清爽，基本上就是建立Request，丟給Handler來處理，最後把資料回傳就搞定了。\n[ApiController] [Route(\u0026#34;[controller]\u0026#34;)] public class OrderController : ControllerBase { private readonly IMediator _mediator; public OrderController(IMediator mediator) { _mediator = mediator; } [HttpGet(\u0026#34;{userName}\u0026#34;, Name = \u0026#34;GetOrder\u0026#34;)] [ProducesResponseType(typeof(IEnumerable\u0026lt;OrdersVm\u0026gt;), (int)HttpStatusCode.OK)] public async Task\u0026lt;ActionResult\u0026lt;IEnumerable\u0026lt;OrdersVm\u0026gt;\u0026gt;\u0026gt; GetOrdersByUserName(string userName) { //建立Request var query = new GetOrdersListQuery(userName); //發送給Handler處理 List\u0026lt;OrdersVm\u0026gt; orders = await _mediator.Send(query); return Ok(orders); } [HttpPost(Name = \u0026#34;CheckoutOrder\u0026#34;)] [ProducesResponseType(StatusCodes.Status200OK)] public async Task\u0026lt;ActionResult\u0026lt;int\u0026gt;\u0026gt; CheckoutOrder([FromBody] CheckoutOrderCommand command) { var result = await _mediator.Send(command); return Ok(result); } [HttpPost(Name = \u0026#34;UpdateOrder\u0026#34;)] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] [ProducesDefaultResponseType] public async Task\u0026lt;ActionResult\u0026gt; UpdateOrder([FromBody] UpdateOrderCommand command) { await _mediator.Send(command); return NoContent(); } [HttpPost(\u0026#34;{id}\u0026#34;, Name = \u0026#34;DeleteOrder\u0026#34;)] [ProducesResponseType(StatusCodes.Status200OK)] [ProducesResponseType(StatusCodes.Status404NotFound)] [ProducesDefaultResponseType] public async Task\u0026lt;ActionResult\u0026gt; DeleteOrder(int id) { var command = new DeleteOrderCommand() { Id = id }; await _mediator.Send(command); return NoContent(); } } Persistence 我們在寫入資料庫前要紀錄新增、修改時間。\nOrderContext //繼承EFCore的DbContext框架類別 public class OrderContext : DbContext { public OrderContext(DbContextOptions options) : base(options) { } //Orders資料表 public DbSet\u0026lt;Order\u0026gt; Orders { get; set; } //我們可以override許多DbContext所提供的方法 //複寫SaveChangesAsync功能 public override Task\u0026lt;int\u0026gt; SaveChangesAsync(CancellationToken cancellationToken = default) { //在儲存變更前修改日期 foreach(var entry in ChangeTracker.Entries\u0026lt;EntityBase\u0026gt;()) { //判斷寫入的狀態(Added、Unchanged、Modified、Deleted) switch (entry.State) { case EntityState.Added: entry.Entity.CreatedDate = DateTime.Now; entry.Entity.CreatedBy = \u0026#34;Max\u0026#34;; break; case EntityState.Modified: entry.Entity.LastModifiedDate = DateTime.Now; entry.Entity.LastModifiedBy = \u0026#34;Max\u0026#34;; break; } } return base.SaveChangesAsync(cancellationToken); } } Repositories RepositoryBase 操作資料庫的部分，將在Application layer的IAsyncRepository連起來。\npublic class RepositoryBase\u0026lt;T\u0026gt; : IAsyncRepository\u0026lt;T\u0026gt; where T : EntityBase { protected readonly OrderContext _dbContext; public RepositoryBase(OrderContext dbcontext) { _dbContext = dbcontext; } public async Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAllAsync() { return await _dbContext.Set\u0026lt;T\u0026gt;().ToListAsync(); } public async Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate) { return await _dbContext.Set\u0026lt;T\u0026gt;().Where(predicate).ToListAsync(); } public async Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, string includeString = null, bool disableTracking = true) { IQueryable\u0026lt;T\u0026gt; query = _dbContext.Set\u0026lt;T\u0026gt;(); if (disableTracking) query = query.AsNoTracking(); if (!string.IsNullOrWhiteSpace(includeString)) query = query.Include(includeString); if (predicate != null) query = query.Where(predicate); if (orderBy != null) return await orderBy(query).ToListAsync(); return await query.ToListAsync(); } public async Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, List\u0026lt;Expression\u0026lt;Func\u0026lt;T, object\u0026gt;\u0026gt;\u0026gt; includes = null, bool disableTracking = true) { IQueryable\u0026lt;T\u0026gt; query = _dbContext.Set\u0026lt;T\u0026gt;(); if (disableTracking) query = query.AsNoTracking(); if (includes != null) query = includes.Aggregate(query, (current, include) =\u0026gt; current.Include(include)); if (predicate != null) query = query.Where(predicate); if (orderBy != null) return await orderBy(query).ToListAsync(); return await query.ToListAsync(); } public virtual async Task\u0026lt;T\u0026gt; GetByIdAsync(int id) { return await _dbContext.Set\u0026lt;T\u0026gt;().FindAsync(id); } public async Task\u0026lt;T\u0026gt; AddAsync(T entity) { _dbContext.Set\u0026lt;T\u0026gt;().Add(entity); await _dbContext.SaveChangesAsync(); return entity; } public async Task UpdateAsync(T entity) { _dbContext.Entry(entity).State = EntityState.Modified; await _dbContext.SaveChangesAsync(); } public async Task DeleteAsync(T entity) { _dbContext.Set\u0026lt;T\u0026gt;().Remove(entity); await _dbContext.SaveChangesAsync(); } } 實作IOrderRepository\npublic class OrderRepository : RepositoryBase\u0026lt;Order\u0026gt;, IOrderRepository { //繼承RepositoryBase，也可以使用_dbContext public OrderRepository(OrderContext dbConext) : base(dbConext) { } public async Task\u0026lt;IEnumerable\u0026lt;Order\u0026gt;\u0026gt; GetOrdersByUserName(string userName) { var orderList = await _dbContext.Orders.Where(o =\u0026gt; o.UserName == userName).ToListAsync(); return orderList; } } Mail Mail Service是使用SendGrid的API，簡單好用。\nNuGet裝SendGrid\n//繼承我們Application layer的IEmailService public class EmailService : IEmailService { public EmailSettings _emailSettings; public ILogger\u0026lt;EmailService\u0026gt; _logger; public EmailService(IOptions\u0026lt;EmailSettings\u0026gt; emailSettings, ILogger\u0026lt;EmailService\u0026gt; logger) { _emailSettings = emailSettings.Value; _logger = logger; } public async Task\u0026lt;bool\u0026gt; SendEmail(Email email) { var client = new SendGridClient(_emailSettings.ApiKey);//使用SendGrid發送email的服務 var from = new EmailAddress(_emailSettings.FromAddress, _emailSettings.FromName);//寄件人 var subject = email.Subject;//主旨 var to = new EmailAddress(email.To);//收件人 //email本體 var emailBody = email.Body; var htmlContent = \u0026#34;\u0026lt;strong\u0026gt;and easy to do anywhere, even with C#\u0026lt;/strong\u0026gt;\u0026#34;; var msg = MailHelper.CreateSingleEmail(from, to, subject, emailBody, htmlContent);//建立信件 var response = await client.SendEmailAsync(msg);//發送信件 if(response.StatusCode == System.Net.HttpStatusCode.Accepted || response.StatusCode == System.Net.HttpStatusCode.OK) { _logger.LogInformation(\u0026#34;Email發送成功\u0026#34;); return true; } _logger.LogError(\u0026#34;Email發送失敗\u0026#34;); return false; } } DI Service Collection 打包要註冊的服務\npublic static class InfrastructureServiceRegistration { public static IServiceCollection AddInfrastructureService(this IServiceCollection services, IConfiguration configuration) { //ConnectionString來自於Ordering.API的appsettings.json services.AddDbContext\u0026lt;OrderContext\u0026gt;(options =\u0026gt; options.UseSqlServer(configuration.GetConnectionString(\u0026#34;OrderingConnectionString\u0026#34;))); services.AddScoped(typeof(IAsyncRepository\u0026lt;\u0026gt;), typeof(RepositoryBase\u0026lt;\u0026gt;)); services.AddScoped\u0026lt;IOrderRepository, OrderRepository\u0026gt;(); services.Configure\u0026lt;EmailSettings\u0026gt;(c =\u0026gt; configuration.GetSection(\u0026#34;EmailSettings\u0026#34;)); services.AddTransient\u0026lt;IEmailService, EmailService\u0026gt;(); return services; } } 一次在Order.API的Startup.cs內註冊Application與Infrastructure的服務\n// This method gets called by the runtime. Use this method to add services to the container. public void ConfigureServices(IServiceCollection services) { services.AddApplicationServices(); services.AddInfrastructureServices(Configuration); services.AddControllers(); services.AddSwaggerGen(c =\u0026gt; { c.SwaggerDoc(\u0026#34;v1\u0026#34;, new OpenApiInfo { Title = \u0026#34;Ordering.API\u0026#34;, Version = \u0026#34;v1\u0026#34; }); }); } 生成Migration檔案 遷移資料庫可以想像成資料庫的版本控制，記錄我們用成對資料庫的資料結構做的變更，保持 EF Core 模型與資料庫結構描述同步，EF Core 模型成為真實來源，請使用移轉。 當變更 EF Core 模型時，這種方式會以遞增方式將對應的結構描述變更套用至資料庫。\n先在Order.API裝Microsoft.EntityFrameworkCore.Tools，我們希望生成的檔案在Infrastructure內，所以接著在Package Manage Console裡把預設專案切換到Order.Infrastructure後，輸入Add-Migration InitialCreate。\n以上是依照課程步驟，這在windows下也許可行，但很遺憾我的在Mac上跑，一直出現錯誤😠。\nUnable to create an object of type 'OrderContext'. For the different patterns supported at design time, see https://go.microsoft.com/fwlink/?linkid=851728\n最後找了很久，在Mac上要生成Migration檔案的步驟如下\ncd 到DbContext的那一個項目資料夾下，這邊是Ordering.Infrastructure/\n接著執行dotnet restore\ndotnet ef --startup-project ../Ordering.Api/ migrations add InitialCreate --verbose --startup-project 設定啟動專案\nmigrations add 生成Migration檔案\n--verbose 輸出log，方便查詢錯誤\n參考: https://stackoverflow.com/questions/55123853/unable-to-create-an-object-of-type-dbcontexts-name-for-the-different-patte\n最後會生成一個Migration資料夾，裡面包含紀錄版本的程式碼、紀錄資料模型如何對應到資料庫的，最後是Model快照。\n更多操作或說明: https://ithelp.ithome.com.tw/articles/10240606\n遷移資料庫 我們在Order.API的Program裡，在host執行前進行資料庫遷移的動作，並把seeder的方法當作參數傳送進去。\npublic class Program { public static void Main(string[] args) { var host = CreateHostBuilder(args).Build(); //把方法當作參數傳送過去 host.MigrateDatabase\u0026lt;OrderContext\u0026gt;((context, services)=\u0026gt; { //記得加上using Microsoft.Extensions.DependencyInjection; //這樣才可以使用GetService的方法 var logger = services.GetService\u0026lt;ILogger\u0026lt;OrderContextSeed\u0026gt;\u0026gt;(); OrderContextSeed.SeedAsync(context, logger).Wait(); }); host.Run(); } } 這邊會進行資料庫遷移的動作，若發生錯誤則會重新執行。\npublic static class HostExtensions { //Action\u0026lt;A,B\u0026gt;代表兩個輸入不回傳的封裝函數，就像(A,B)=\u0026gt;{ ... }方法 public static IHost MigrateDatabase\u0026lt;TContext\u0026gt;(this IHost host, Action\u0026lt;TContext, IServiceProvider\u0026gt; seeder, int? retry = 10) where TContext : DbContext { using (var scope = host.Services.CreateScope()) { var services = scope.ServiceProvider; var logger = services.GetRequiredService\u0026lt;ILogger\u0026lt;TContext\u0026gt;\u0026gt;(); var context = services.GetService\u0026lt;TContext\u0026gt;();//取得OrderContext的地方 try { logger.LogInformation($\u0026#34;開始遷移資料庫成{typeof(TContext).Name}的形狀\u0026#34;); context.Database.Migrate();//執行遷移 seeder(context, services);//執行seeder，傳送進來的方法。 logger.LogInformation($\u0026#34;遷移資料庫成{typeof(TContext).Name}的形狀結束\u0026#34;); } catch (Exception err) { logger.LogError(err, \u0026#34;寫入資料庫時發生錯誤\u0026#34;); if (retry \u0026gt; 0) { retry--; System.Threading.Thread.Sleep(2000); MigrateDatabase\u0026lt;TContext\u0026gt;(host, seeder, retry); } } } return host; } } 之所以要這樣寫的原因是MigrateDataBase\u0026lt;TContext\u0026gt;是透過泛型來處理，\n直到var context = services.GetService\u0026lt;TContext\u0026gt;();才取得OrderContext的地方\n寫在裡面並沒有辦法確定TContext的類型，寫在外面的話就可以確定\n因為host.MigrateDatabase\u0026lt;OrderContext\u0026gt;在這邊就確定型別的同時，也確定seeder的第一個參數了\n連接資料庫與Docker容器化 DB是使用Microsoft SQL Server的映像檔 詳細的操作可以參考這篇Docker容器化_MSSQLServer\n架設好資料庫後，在appsettings裡加上連接字串，Server位置為localhost預設port為1433，帳密為sa/Max4129889\n\u0026#34;ConnectionStrings\u0026#34;: { \u0026#34;OrderingConnectionString\u0026#34;: \u0026#34;Server=localhost;Database=OrderDb;User Id=sa;Password=Max4129889;\u0026#34; } 到這邊基本上就可以測試一下我們的Ordering.API，沒問題後接著也把Ordering.API容器化，跟這篇Docker容器化_MSSQLServer裡面的操作一樣，Dockerfile、Docker-compose.yml也都會自動設定好，我們只要在Docker-compose.override.yml裡做一些設定即可。\n這邊的連結字串改成一行冒號、雙引號要做調整，最重要的是Server=orderdb，改指向orderdb(MSSQL的微服務)。\nordering.api: container_name: ordering.api environment: - ASPNETCORE_ENVIRONMENT=Development - \u0026#34;ConnectionStrings__OrderingConnectionString=Server=orderdb;Database=OrderDb;User Id=sa;Password=Max4129889;\u0026#34; depends_on: - orderdb ports: - \u0026#34;8004:80\u0026#34; 最後執行docker-compose指令，搞定收工。\n參考 Docker容器化_MSSQLServer\n簡潔架構 Application Layer\n簡潔架構 Infrastructure Layer\nhttps://www.udemy.com/course/microservices-architecture-and-implementation-on-dotnet/\n","date":"2021-12-22T13:32:25+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211222_%E7%B0%A1%E6%BD%94%E6%9E%B6%E6%A7%8Binfrastructure.md/","title":"簡潔架構 Infrastructure Layer"},{"content":" 憑證 主要的功能是確認公鑰擁有者的身份，避免我們拿到冒用者的公鑰。\n要怎麼確定呢？找大家都信任的公正的第三方來，就是數位憑證認證機構(Certificate Authority，CA)。\n要取得憑證，應先向CA提出申請，CA判明申請者的身分後，為之分配一個公鑰，並將該公鑰與其身分資訊繫結，為該整體簽名，簽名後的整體即為憑證，發還給申請者。\n在公司用的通常是萬用憑證，連同子網域都可以用的憑證*.google.com，blog.google.com、mail.google.com等，都可以直接使用相同的憑證。\n溝通流程 用戶 - - - - - - HTTPS 伺服器您好，我支援TLS XX版本 - - - - - \u0026raquo; 伺服器\n用戶 \u0026laquo; - - - - - - - Hi 這是我的憑證 - - - - - - - - - - - - 伺服器\n用戶 確認憑證沒有問題\u0026hellip;(用CA的公鑰對那個憑證上的簽字進行驗證)\n確認不是中間人後，就可以進行金鑰交換的步驟了，並經過各種演算法讓你可以直接傳資料，且不用擔心被竊聽。\n參考 https://zh.wikipedia.org/wiki/%E8%AF%81%E4%B9%A6%E9%A2%81%E5%8F%91%E6%9C%BA%E6%9E%84\nhttps://www.youtube.com/watch?v=63tKc67T2jM\nhttps://medium.com/@clu1022/%E9%82%A3%E4%BA%9B%E9%97%9C%E6%96%BCssl-tls%E7%9A%84%E4%BA%8C%E4%B8%89%E4%BA%8B-%E4%B9%9D-ssl-communication-31a2a8a888a6\n","date":"2021-12-21T13:22:15+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211221_%E6%8F%9B%E6%86%91%E8%AD%89.md/","title":"換憑證"},{"content":" 購買原因 加入了XBOX Game Pass後，遊戲玩不完，空間不夠放了啊，原先地平線5是放在傳統硬碟裡，開車開到一半，路直接不見，進入遊戲也要等個3分鐘，速度實在太慢了。\n沒什麼時間做功課，趕在雙12結束前下單優惠比較多，原本想要透過pchome+Line導購，一沒注意時間錯過了導購回饋的時間，改去蝦皮原價屋買，回饋少了一點，但也還行吧，2244$，沒時間解釋了，快上車。\n由於我的主機板x470i剩主板後面一個m.2插槽可以用，背面沒有散熱片可以用，itx機殼又容易積熱，所以主要訴求是希望硬碟溫度能夠低，發熱量小點。\n藍藍的看起來很清涼🥶\r順帶一提，過去擁有不少顆傳統硬碟(大概8、9顆)，只壞過WD牌的，個人覺得最耐操的是HGST(在被WD買下前)，可惜現在都買不到了，現在這顆我也還在服役，就是速度慢了些。再給吃過HGST口水的WD一個機會。\n移動遊戲到新硬碟裡 設定 \u0026raquo; 應用程式 \u0026raquo; 找到遊戲 \u0026raquo; 移動\n就可以直接移動到新的硬碟去了，還好不用重新下載幾百G的檔案。\n曬一下電腦照 itx就是桌面吸塵器\r這台電腦自從裝好後就再也沒拆過了，這組裝實在太麻煩了XD，有夠難裝，線也是我自己弄的，組完還蠻有成就感的。兩年前組好(顯卡二手+線材+沿用舊傳統硬碟)總花費大概為30000出頭，是非常貴的一格價格，我把實習賺的錢全部都砸在這台電腦上，要組itx很多東西都是要買特定規格的，能省錢的地方不多，而且電腦通常一組就好幾年，可以買價格合理，品質耐用的產品。\nCPU AMD Ryzen™ 5 3600 主機板 ROG STRIX X470-I GAMING 記憶體 Micron Ballistix Sport LT 3200 8G *2 顯示卡 ROG-STRIX-GTX1060-O6G-GAMING 電源 CORSAIR SF450 80Plus SSD PLEXTOR M9PeGn 1TB M.2 2280 PCIe SSD SSD WD Blue™ SN550 NVMe™ 硬碟 HGST 7200RPM 750GB 硬碟 TOSHIBA 5200RPM 500GB 機殼 K01 6.5L A4 散熱器 CRYORIG C7 後記 平常待機溫度大概40℃左右，遊戲中的溫度在55℃就沒有再上去了，可能啟動什麼保護機制之類的吧，後面的散熱還是太差了，CPU、GPU兩頭燒。\n","date":"2021-12-21T09:41:12+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211220_sn550%E9%96%8B%E7%AE%B1.md/","title":"WD Blue™ SN550 小開箱"},{"content":" 取得磁碟狀態 工作上總是一堆鳥事，在甲方裡工作有時候又要處理一些完全沒有意義的雜事，浪費時間。\n總之因為不明原因，我需要每週紀錄主機的磁碟剩餘容量百分比\u0026hellip;\n要取得磁碟訊息很簡單，使用System.IO的DriveInfo.GetDrives()可以取得所有磁碟，再把DriveInfo的屬性取出來\nstring diskStatus = \u0026#34;\u0026#34;; DriveInfo[] allDrives = DriveInfo.GetDrives(); foreach (DriveInfo d in allDrives) { if (d.IsReady == true)//確定磁碟就緒 { int freePercent = (int)(d.TotalFreeSpace / (float)d.TotalSize * 100); diskStatus += $\u0026#34; {d.Name}{freePercent} \u0026#34; } } 寫入紀錄(過時，改由Mail發送) 這邊一切以簡單為主，直接用寫入文字檔的方式來進行\n//如果有額外輸入檔案路徑的話，就把第一個參數當作路徑，沒有就丟在桌面 //若不想在排程器那裡設定開始位置的話，就用絕對路徑吧。 string path = args.Length == 1 ? args[0] : \u0026#34;DiskLog.txt\u0026#34;; //記錄時間 string now = DateRime.Now.ToString(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); using StreamWriter file = new (path, append: true); file.WriteLine($\u0026#34;{now}\u0026gt;\u0026gt; {diskStatus}\u0026#34;); 新增排程 這邊基本就點點滑鼠就搞定了\n電腦管理 \u0026raquo; 工作排程器 \u0026raquo; 建立工作\n輸入名稱\n觸發程序 \u0026raquo; 新增 \u0026raquo; 每週\n動作 \u0026raquo; 新增 \u0026raquo; 程式或指令碼(選擇我們程式的exe檔) \u0026raquo; 新增引數(輸入檔案路徑) \u0026raquo; 開始位置(預設為C:\\WINDOWS\\System32)\n加上錯誤處理 沒什麼意外是不會錯啦，但總是有意外XD，加個try..catch處理就好，最後大概如下。\ntry { string diskStatus = \u0026#34;\u0026#34;; DriveInfo[] allDrives = DriveInfo.GetDrives(); foreach (DriveInfo d in allDrives) { if (d.IsReady == true)//確定磁碟就緒 { int freePercent = (int)(d.TotalFreeSpace / (float)d.TotalSize * 100); diskStatus += $\u0026#34; {d.Name}{freePercent} \u0026#34; } } //如果有額外輸入檔案路徑的話，就把第一個參數當作路徑，沒有就丟在桌面 //若不想在排程器那裡設定開始位置的話，就用絕對路徑吧。 string path = args.Length == 1 ? args[0] : \u0026#34;DiskLog.txt\u0026#34;; //記錄時間 string now = DateRime.Now.ToString(\u0026#34;yyyy/MM/dd HH:mm:ss\u0026#34;); using StreamWriter file = new (path, append: true); file.WriteLine($\u0026#34;{now}\u0026gt;\u0026gt; {diskStatus}\u0026#34;); } catch(Exception ex) { Console.WriteLine(ex); Console.ReadKey();//卡個畫面 } 取得IP與發送Email服務(更新) 取得本機IP位置\nstring ip = Dns.GetHostEntry(Dns.GetHostName()).AddressList .Where(q =\u0026gt; q.AddressFamily == System.Net.Sockets.AddressFamily.InterNetwork) .FirstOrDefault().ToString(); 發送Mail\nprivate static void SendMail(string now, string ip, string diskStatus) { MailMessage mailMsg = new MailMessage(); mailMsg.Subject = $\u0026#34;{ip} \u0026gt;\u0026gt; {dickStatus}\u0026#34;; //主旨 mailMsg.To.Add(new MailAddress(\u0026#34;xxx@gmail.com\u0026#34;));//收件人地址 mailMsg.From = new MailAddress(\u0026#34;ooo@gmail.com\u0026#34;, \u0026#34;主機紀錄機器人\u0026#34;);//寄件人地址 mailMsg.Body = $\u0026#34;{ip} \u0026gt;\u0026gt; {dickStatus}\u0026#34;; //內文 //設定mail server SmtpClient client = new SmtpClient(); client.Credentials = new System.Net.NetworkCredential(\u0026#34;XXX@gmail.com\u0026#34;, \u0026#34;****\u0026#34;); //這裡要填正確的帳號跟密碼 client.Host = \u0026#34;smtp.gmail.com\u0026#34;; //設定smtp Server client.Port = 25; //設定Port client.EnableSsl = true; //gmail預設開啟驗證 client.Send(mailMsg); //寄出信件 client.Dispose(); } 參考 https://docs.microsoft.com/zh-tw/dotnet/api/system.io.driveinfo.getdrives?view=net-6.0\nhttps://ithelp.ithome.com.tw/articles/10190120\n","date":"2021-12-17T17:09:56+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211217_windows%E6%8E%92%E7%A8%8B%E7%B4%80%E9%8C%84%E4%B8%BB%E6%A9%9F%E7%A3%81%E7%A2%9F%E7%8B%80%E6%85%8B.md/","title":"windows排程紀錄主機磁碟狀態"},{"content":" Application Layer 注重於商業需求而不是實作一些外部系統的東西，DB之類的。\n在這一層裡有三個主要的資料夾Contracts、Features、Behaviors，分別為存放服務介面、Use case、驗證用戶行為。\n主要在於Fetures，根據DDD並使用MediatR為每一個需求做獨自的CQRS操作，\nContracts 存放各Services的interface的地方\nPersistence 通用的非同步Repository介面(Asynchronous Generic Repository)\n裡面包含常用的功能。\n//泛型T必需繼承Domina Layer的EntityBase(Id、createdBy、createDate、LastModifiedDate等等的東西) public interface IAsyncRepository\u0026lt;T\u0026gt; where T : EntityBase { Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAllAsync(); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, string includeString = null, bool disableTracking = true); Task\u0026lt;IReadOnlyList\u0026lt;T\u0026gt;\u0026gt; GetAsync(Expression\u0026lt;Func\u0026lt;T, bool\u0026gt;\u0026gt; predicate = null, Func\u0026lt;IQueryable\u0026lt;T\u0026gt;, IOrderedQueryable\u0026lt;T\u0026gt;\u0026gt; orderBy = null, List\u0026lt;Expression\u0026lt;Func\u0026lt;T, object\u0026gt;\u0026gt;\u0026gt; includes = null, bool disableTracking = true); Task\u0026lt;T\u0026gt; GetByIdAsync(int id); Task\u0026lt;T\u0026gt; AddAsync(T entity); Task UpdateAsync(T entity); Task DeleteAsync(T entity); } 下訂單Repository介面，在這邊我們可以建立自己的方法、功能，後面處理Request時會用到。\npublic interface IOrderRepository : IAsyncRepository\u0026lt;Order\u0026gt;//Order來自Domian Layer的Entity { Task\u0026lt;IEnumerable\u0026lt;Order\u0026gt;\u0026gt; GetOrdersByUserName(string userName); } Infrastructure Email發送服務介面，Email class建立在Models/Email.cs\npublic interface IEmailService { Task\u0026lt;bool\u0026gt; SendEmail(Email email); } Features 存放Use case，目前只有Orders一個Use case，並實作CQRS。\n建資料夾 Features/Orders/Commands Features/Orders/Queries\nQueries只有一個方法，GetOrderList。\nCommands裡面有三個方法，CheckOrder、UpdateOrder、DeleteOrder。\nQueries/GetOrderList 先處理Queries\nFeatures/Orders/Queries/GetOrdersList/GetOrdersListQuery.cs Features/Orders/Queries/GetOrdersList/GetOrdersListQueryHandler.cs Features/Orders/Queries/GetOrdersList/OrdersVm.cs\nGetOrdersListQuery IRequest介面來自於MediatR DI Version，裡面List\u0026lt;OrdersVm\u0026gt;代表要回傳的type\nusing MediatR; public class GetOrdersListQuery : IRequest\u0026lt;List\u0026lt;OrdersVm\u0026gt;\u0026gt; { public string UserName { get; set; } public GetOrdersListQuery(string userName) { UserName = userName ?? throw new ArgumentNullException(nameof(userName)); } } GetOrdersListQueryHandler 當Query被觸發時Handler會負責處理，實作IRequestHandler會得到Handle這個Function，並寫入我們要進行的操作\n//IRequestHandler\u0026lt;要處理的IRequest, 輸出的type\u0026gt; public class GetOrdersListQueryHandler : IRequestHandler\u0026lt;GetOrdersListQuery, List\u0026lt;OrdersVm\u0026gt;\u0026gt; { private readonly IOrderRepository _orderRepository; private readonly IMapper _mapper; //使用在Contract裡面寫的orderRepository public GetOrdersListQueryHandler(IOrderRepository orderRepository, IMapper mapper) { _orderRepository = orderRepository; _mapper = mapper; } public async Task\u0026lt;List\u0026lt;OrdersVm\u0026gt;\u0026gt; Handle(GetOrdersListQuery request, CancellationToken cancellationToken) { var orderList = await _orderRepository.GetOrdersByUserName(request.UserName); return _mapper.Map\u0026lt;List\u0026lt;OrdersVm\u0026gt;\u0026gt;(orderList); } } OrdersVm 可以看到這個class是放在Queries/GetOrdersList裡面，只給GetOrdersList這個Use Case用，與Entity層的Order.cs無關，雖然他們長得一樣。\npublic class OrdersVm { public int Id { get; set; } public string UserName { get; set; } public decimal TotalPrice { get; set; } // BillingAddress public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; } public string AddressLine { get; set; } public string Country { get; set; } public string State { get; set; } public string ZipCode { get; set; } // Payment public string CardName { get; set; } public string CardNumber { get; set; } public string Expiration { get; set; } public string CVV { get; set; } public int PaymentMethod { get; set; } } Commands/CheckoutOrder 接下來要處理Command的部分\n先處理CheckoutOrder\n//Features/Orders/Commands/CheckoutOrder/CheckoutOrderCommand.cs //回傳int訂單編號 public class CheckoutOrderCommand : IRequest\u0026lt;int\u0026gt; { public string UserName { get; set; } public decimal TotalPrice { get; set; } // BillingAddress public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; } public string AddressLine { get; set; } public string Country { get; set; } public string State { get; set; } public string ZipCode { get; set; } // Payment public string CardName { get; set; } public string CardNumber { get; set; } public string Expiration { get; set; } public string CVV { get; set; } public int PaymentMethod { get; set; } } 一樣使用MediatR的功能，透過handler來處理\n//Features/Orders/Commands/CheckoutOrder/CheckoutOrderCommandHandler.cs public class CheckoutOrderCommandHandler : IRequestHandler\u0026lt;CheckoutOrderCommand, int\u0026gt; { private readonly IOrderRepository _orderRepository; private readonly IMapper _mapper; //Application層下的mappings private readonly IEmailService _emailService;//Application層下的contracts/infastucture private readonly ILogger\u0026lt;CheckoutOrderCommandHandler\u0026gt; _logger; //依賴注入需要的元件 public CheckoutOrderCommandHandler(IOrderRepository orderRepository, IMapper mapper, IEmailService emailService, ILogger\u0026lt;CheckoutOrderCommandHandler\u0026gt; logger) { _orderRepository = orderRepository ?? throw new ArgumentNullException(nameof(orderRepository)); _mapper = mapper ?? throw new ArgumentNullException(nameof(mapper)); _emailService = emailService ?? throw new ArgumentNullException(nameof(emailService)); _logger = logger ?? throw new ArgumentNullException(nameof(logger)); } //實作IRequestHandler public async Task\u0026lt;int\u0026gt; Handle(CheckoutOrderCommand request, CancellationToken cancellationToken) { var orderEntity = _mapper.Map\u0026lt;Order\u0026gt;(request); var newOrder = await _orderRepository.AddAsync(orderEntity); _logger.LogInformation($\u0026#34;訂單{newOrder.Id}建立成功\u0026#34;); await SendMail(newOrder); return newOrder.Id; } private async Task SendMail(Order order) { var email = new Email() { To = \u0026#34;test@gmail.com\u0026#34;, Body = $\u0026#34;Order was created.\u0026#34;, Subject = \u0026#34;Order was created\u0026#34; }; try { await _emailService.SendEmail(email); } catch (Exception ex) { _logger.LogError($\u0026#34;訂單{order.Id}發生錯誤，mail service: {ex.Message}\u0026#34;); } } } 最後會加上一個驗證，在Behaviors那邊加入。\nusing FluentValidation;//使用驗證套件 public class CheckoutOrderCommandValidator : AbstractValidator\u0026lt;CheckoutOrderCommand\u0026gt; { public CheckoutOrderCommandValidator() { //p代表property RuleFor(p =\u0026gt; p.UserName)//驗證UserName .NotEmpty().WithMessage(\u0026#34;UserName 必填\u0026#34;)//不可為空值，若為空值回傳訊息 .NotNull() .MaximumLength(50).WithMessage(\u0026#34;UserName 字數過長\u0026#34;); RuleFor(p =\u0026gt; p.EmailAddress) .NotEmpty().WithMessage(\u0026#34;EmailAddress 必填\u0026#34;); RuleFor(p =\u0026gt; p.TotalPrice) .NotEmpty().WithMessage(\u0026#34;TotalPrice 必填\u0026#34;) .GreaterThan(0).WithMessage(\u0026#34;TotalPrice 需要大於0\u0026#34;); } } Commands/DeleteOrder UpdateOrder、DeleteOrder基本與CheckoutOrder類似，不過有幾個地方不太一樣。\nCommand只需要IRequest，不需用泛型。\npublic class DeleteOrderCommand : IRequest { public int Id { get; set; } } 如果Command本身沒有要回傳值的話，就回傳Unit.Value給MediatR知道\npublic async Task\u0026lt;Unit\u0026gt; Handle(DeleteOrderCommand request, CancellationToken cancellationToken) { var orderToDelete = await _orderRepository.GetByIdAsync(request.Id); if(orderToDelete == null) { throw new Exception($\u0026#34;找不到訂單{request.Id}\u0026#34;); } await _orderRepository.DeleteAsync(orderToDelete); _logger.LogInformation($\u0026#34;訂單{request.Id}刪除完成\u0026#34;); return Unit.Value;//如果Command本身沒有要回傳值的話，就回傳Unit.Value給MediatR知道 } Behaviors 我們會在Handler前後進行驗證User使用的行為(輸入)是否正常\n整個流程大概如下\nCaller \u0026raquo; Request \u0026raquo; 前處理 \u0026raquo; Handler \u0026raquo; 後處理\n//實作MediatR提供的IPipelineBehavior來註冊前、後處理 public class ValidationBehaviour\u0026lt;TRequest, TResponse\u0026gt; : IPipelineBehavior\u0026lt;TRequest, TResponse\u0026gt; { //這將會讀取所有Validator，只要有繼承AbstractValidator\u0026lt;TRequest\u0026gt;(來自FluentValidation) private readonly IEnumerable\u0026lt;IValidator\u0026lt;TRequest\u0026gt;\u0026gt; _validators; public ValidationBehaviour(IEnumerable\u0026lt;IValidator\u0026lt;TRequest\u0026gt;\u0026gt; validators) { _validators = validators; } public async Task\u0026lt;TResponse\u0026gt; Handle(TRequest request, CancellationToken cancellationToken, RequestHandlerDelegate\u0026lt;TResponse\u0026gt; next) { if (_validators.Any())//如果有Validator的話 { //驗證輸入 var context = new ValidationContext\u0026lt;TRequest\u0026gt;(request); //等待所有非同步執行結果 ( 對所有驗證項目進行非同步工作 ) var validationResults = await Task.WhenAll(_validators.Select(v =\u0026gt; v.ValidateAsync(context, cancellationToken))); //查看結果 var failures = validationResults.SelectMany(r =\u0026gt; r.Errors).Where(f =\u0026gt; f != null).ToList(); //如果有錯的話 if (failures.Count != 0) { throw new ValidationException(failures); } } //前處理的部份到此結束 var response = await next();//Handler處理完回傳 //後處理的部分從此開始 //.... //後處理結束 return response;//回傳回應結果 } } DI Service Collection 因為使用的服務有點多，把他們集中管理成一個Service Collection，之後直接註冊這個Collection就好了。\npublic static class ApplicationServiceRegistration { public static IServiceCollection AddApplicationServices(this IServiceCollection services) { services.AddAutoMapper(Assembly.GetExecutingAssembly()); services.AddValidatorsFromAssembly(Assembly.GetExecutingAssembly()); services.AddMediatR(Assembly.GetExecutingAssembly()); services.AddTransient(typeof(IPipelineBehavior\u0026lt;,\u0026gt;), typeof(UnhandledExceptionBehaviour\u0026lt;,\u0026gt;)); services.AddTransient(typeof(IPipelineBehavior\u0026lt;,\u0026gt;), typeof(ValidationBehaviour\u0026lt;,\u0026gt;)); return services; } } 到這邊Application Layer就到一段落了，實在很多很長，主要實作了CQRS與學習MediatR的操作，也更看清楚整個簡潔架構的設計。\n參考 簡潔架構 Application Layer\n簡潔架構 Infrastructure Layer\nhttps://www.udemy.com/course/microservices-architecture-and-implementation-on-dotnet/\n","date":"2021-12-17T11:44:52+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211217_%E7%B0%A1%E6%BD%94%E6%9E%B6%E6%A7%8Bapplication.md/","title":"簡潔架構 Application Layer"},{"content":" 筆記 雖說在工作上能不用第三方套件就不用，但練習的時候想做什麼就做什麼吧，一切輕鬆、簡單最好了。可以考慮用看看。\n紀錄一下常用的功能，範例取自訂單結帳前處理的部分。\nusing FluentValidation;//使用套件 public class CheckoutOrderCommandValidator : AbstractValidator\u0026lt;CheckoutOrderCommand\u0026gt;//要驗證的class { public CheckoutOrderCommandValidator() { //p代表property RuleFor(p =\u0026gt; p.UserName)//驗證UserName .NotEmpty().WithMessage(\u0026#34;UserName 必填\u0026#34;)//不可為空值，若為空值回傳訊息 .NotNull() .MaximumLength(50).WithMessage(\u0026#34;UserName 字數過長\u0026#34;); RuleFor(p =\u0026gt; p.EmailAddress) .NotEmpty().WithMessage(\u0026#34;EmailAddress 必填\u0026#34;); RuleFor(p =\u0026gt; p.TotalPrice) .NotEmpty().WithMessage(\u0026#34;TotalPrice 必填\u0026#34;) .GreaterThan(0).WithMessage(\u0026#34;TotalPrice 需要大於0\u0026#34;); } } 取得各個Validator\n//這將會讀取所有Validator，只要有繼承AbstractValidator\u0026lt;TRequest\u0026gt;(來自FluentValidation) private readonly IEnumerable\u0026lt;IValidator\u0026lt;TRequest\u0026gt;\u0026gt; _validators; public ValidationBehaviour(IEnumerable\u0026lt;IValidator\u0026lt;TRequest\u0026gt;\u0026gt; validators) { _validators = validators; } 使用Validator\nif (_validators.Any())//如果有Validator的話 { //驗證輸入 var context = new ValidationContext\u0026lt;TRequest\u0026gt;(request); //等待所有非同步執行結果 ( 對所有驗證項目進行非同步工作 ) var validationResults = await Task.WhenAll(_validators.Select(v =\u0026gt; v.ValidateAsync(context, cancellationToken))); //查看結果 var failures = validationResults.SelectMany(r =\u0026gt; r.Errors).Where(f =\u0026gt; f != null).ToList(); //如果有錯的話 if (failures.Count != 0) { throw new ValidationException(failures); } } ","date":"2021-12-16T14:50:26+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211216_fluentvalidation%E9%A9%97%E8%AD%89%E5%A5%97%E4%BB%B6.md/","title":"FluentValidation"},{"content":" 案發原因 不知道有多久沒有更新我的Line了，也沒有什麼值得我更新的功能，這樣穩穩著用就挺好的，早上收到Line錢包提醒我必須在12/31號前更新到最新版，平常出門已經很習慣Pay來Pay去了，得很方便，所以只能更新了。\nBOOM!\n更新完後Line直接閃退，再也打不開了，卸載重裝、重新開機都試過了，更新iOS到最新版本還是打不開，只好寫email給客服來處理，來回處理了兩天左右，客服發送消息給我說他們修正了問題，請至App Store更新最新版，這次更新完後終於可以登入了，還是要給他們的工程師點讚，這個效率算很快了。\nBOOM!ANGIN!\n原以為事情到這裡就告一個段落了，沒想到更新後導致的問題一一浮現，平常在使用的iPad 3居然連不到我手機的熱點了，一查才發現iOS 15加強了wifi存取保護(Wi-Fi Protected Access)，從wpa2升級到wpa3，導致不支援wpa3的設備將無法連接，而我的iPad 3就這樣再也連不上網路了。更慘的是網路上查了一輪，還是沒找到解決方法。\n只能祈求之後會開放可以改wpa2的選項，雖然我覺得很難。._.\n","date":"2021-12-16T13:10:12+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211216_%E6%9B%B4%E6%96%B0%E5%BE%9E%E4%BE%86%E5%B0%B1%E6%B2%92%E6%9C%89%E5%A5%BD%E4%BA%8B.md/","title":"更新從來就沒有好事情"},{"content":" 筆記 工作上剛好遇到一個需求，要過濾用戶輸入的英文ID\n判斷規則\n格式限定半形大寫英文 符號只能輸入.、-、/、\\還有空白 長度最長為50字元 至少有三個英文字，不可只有符號 原本打算先判斷輸入的正確的英文與符號且長度為3~50，在判斷英文字至少三個。\nusing System.Text.RegularExpressions; string EnglishName = \u0026#34;TEST-123\u0026#34;//user input Regex.IsMatch(EnglishName, \u0026#34;@^[A-Z//.\\\\\\s]{3,50}$\u0026#34;); Regex.IsMatch(EnglishName, \u0026#34;@^[A-Z{3,}$\u0026#34;); 使用預查來處理這個問題\n正向肯定預查 (?=pattern) 表示從當前位置開始，預測後面的文字必須匹配上pattern 正向否定預查 (?!pattern) 表示從當前位置開始，預測後面的文字必須匹配不上pattern 反向肯定預查 (?\u0026lt;=pattern) 表示從當前位置開始，預測前面的文字必須匹配上pattern 反向否定預查 (?\u0026lt;!pattern) 表示從當前位置開始，預測前面的文字必須匹配不上pattern 有三個英文字後，才會判斷是否為長度3~50且正確的英文與符號。\nRegex.IsMatch(EnglishName, \u0026#34;@^(?=.*[A-Z].*[A-Z].*[A-Z])[A-Z//.\\\\\\s]{3,50}$\u0026#34;); 每次要寫RE都要查一下怎麼寫XD，希望我下次不要再忘記啦。\n參考 https://www.runoob.com/regexp/regexp-syntax.html https://blog.csdn.net/NAPO687/article/details/110198206\n","date":"2021-12-14T13:08:10+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211214_%E6%AD%A3%E5%89%87%E8%A1%A8%E9%81%94%E5%BC%8F.md/","title":"正則表達式筆記"},{"content":" 介紹 自小時候我就是Halo(最後一戰)系列的鐵桿粉絲了，在最初代XBOX上面不知道重破了好幾遍，這款遊戲也是我唯一想要購買XBOX的理由了，過了超久到了現在，Halo也不再是XBOX獨佔了(除了Halo 5)，其他版本皆已經能在PC上遊玩，如今Halo Infinite也正式推出，這次鐵了心買了XGPU的會員，一次就給他包3年。這三年微軟自家的遊戲都可以直接玩爆，還有EA PLAY可以玩，絕對玩不完的。 趕回來結束戰鬥\r省錢 網路上有很多教你怎麼儲XGPU最劃算，但是算一算都還是要幾千元，因為台灣的XGPU價格太高了，國外其他地區的價格可能比台灣便宜上不少，所以自行跨區購買或是請人代儲可能是最划算的方案，但是這些風險都比較高，但是我打開淘寶看到代儲3年只要118人民幣，真的是太香了，直接秒速下訂，但發現淘寶的虛擬物品只能透過中國的銀行卡來進行付款，不支持海外刷卡，或是玉山ATM轉帳，只能去蝦皮找代付，看了幾家都差不多錢，公道價應該是1:5.4台幣，換算下來淘寶代儲只需要台幣637，一年只要200出頭，太划算了。\n代儲 代儲最好使用小號且要先把密碼隨便改掉，再給淘寶的店家比較安全，店家登入時會再跟你要登入安全碼，我不確定店家是如何把成本壓那麼低的，不過代儲時會看到自己的信箱收到來自微軟的日文信件的付款訊息，應該官方的沒錯，最後記得把密碼改掉。 代儲時收到的日文信件\r貪小便宜的下場 沒想到過了半年後，突然發現被偵測到違反Xbox條款及條件，被取消訂閱啦QQ，只好聯繫賣家退款，淘寶店鋪直接倒店找不到商店了，但好在賣家客服還在，也願意按照比例退款(願意退98.5RMB)。 需要聯繫官方客服申請開通退款，經過官方客服漫長的處理(隔天早上)，再次聯繫客服才開通成功，一開始詢問是不是退到我的支付寶，客服說是，結過退完發現是退到代付的人那邊＝＝ 去蝦皮看也發現他倒店了，聊聊五天前上線，希望渺茫Ｒ\n","date":"2021-12-13T17:25:11+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211211_xboxgamepass.md/","title":"XBOX Game Pass Ultimate"},{"content":" 心得(小雷) 沒想到刀劍神域又出劇場版了，我好興奮啊!!上一次看序列爭戰我還在高雄念書，特別跑去市區超遠的高雄大遠百看4dx，那次也是我第一次體驗4dx的威力，那個動態座椅讓我完全融入在畫面裡面，刀刀砍在背上的感覺，刀削的氣流在耳邊噴發，我現在還在激動啊！總之就是回不去了，當時學生票好像是450還500有點忘記了，這個價錢對於學生的我也是不小的金額，但我還是覺得超值得。\n這次去看的電影院是信義威秀，看了一下票價原價要550，這個票價也不是鬧著玩的，身為半個客家人的我，發現蝦皮上面有在賣威秀的招待票一張300元，而且可以看4dx，立馬下定，相見恨晚，太划算了。\n用招待票通常是不能拿特典的，但是店員還是發給我，小確幸XD。\r刀劍神域Progressive是以亞絲娜作為故事主角出發，講述了進入SAO的原因及第一層的故事，本傳後面出了一堆遊戲但還是沒有比SAO更刺激好看，這個冷飯，真香。劇情還是有做一些修改與本傳不同，多了米特這個角色，她與亞絲娜從最好的朋友，遇到死結時選擇退出隊伍自己離開，到最後互相體諒和好，並走上各自的道路，完美呼應主題曲『前行』的歌詞。\n中間一定要加上桐老爺出來裝逼，帥氣收割一波，整體畫面跟音樂我都很滿意，再加上動態座椅的加持，滿分10分我給9.5分，要是能有60FPS那就完美了，2022年也要出另一部劇場版，沒意外也要看4dx!\n","date":"2021-12-09T13:29:52+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211207_%E5%88%80%E5%8A%8D%E7%A5%9E%E5%9F%9Fprogressive.md/","title":"刀劍神域Progressive 無星夜的詠嘆調 劇場版"},{"content":" 前情提要 在過去學生時期的時候就接觸了股票，總覺得要錢滾錢才能財富自由，把打工的錢都拿去玩看看，當時的選股策略是\n1.股價夠低(因為本金太小買不起太貴的股票，每一次買股票都是All in)\n2.看起來現在在低檔，低到不能再低的感覺\n當時All in買了陽明4塊多還5塊，沒過幾天不知怎麼就噴到漲停，抓到一個低買高賣的節奏，沒多久就把它出清了，獲利4000$多，後來又聽朋友建議去買光學鏡頭股玉晶光，也賺了好幾千，我該不會其實很適合玩股票吧XD，直到我膝蓋中了一箭，南亞科賠20000元，沒想到那麼慘，之後就退出股海了。\n直到現在全球股市一直突破新高，並且出社會領薪水的時候，我，再次回歸！等等這不會是高點的訊號吧QQ\n對了，這邊不做任何投資建議喔，單純心得分享。\n啟蒙 領了薪水後，只能說錢真的賺，現在年輕人基本上沒什麼希望，光活著就已經費盡全力，每週40小時的生命賣給公司，扣掉基本開銷、房租、伙食，可以花的錢也就一萬多吧，還沒有任何娛樂，活著，卻像是個死人，但想到父母為了我也把自己的生命販賣給公司，只為了能讓我有好的生活，我又有什麼好藉口不去努力呢？\n看了一本關於理財的書籍『我用死薪水輕鬆理財賺千萬』，讓我了解的資產配置、再平衡與指數投資的基本概念，書中的內容都淺顯易懂，沒有什麼難以離解的東西。之後也看了網路上許多的文章與影片，清流君、魯爸、yp筆記、多拉王與伯格頭投資指南，都讓我堅信指數投資是個GOOD SHIT~\n伯格頭的投資指南\nevelop a workable plan Invest early and ofter Never bear too much or too little risk Diversify Never try to time the market Use index funds when possible Keep costs low Minimize taxes Invest with simplicity Stay the course 開戶準備 伯格頭的投資指南第7條，Keep costs low，盡可能地減少投資成本。\n成本最低的應該是台股定期定額(新光證券20000內，手續費1元)\n海外複委託美股(富邦證券，0.12%，低消12美金)\n海外複委託英股(富邦證券，0.15%，低消15美金)\n海外券商(電匯費用一次800吧(不確定沒用過)，交易手續費趨近於0)\n金額大的話海外券商比複委託還要省很多，不過我自己錢還沒有那麼多，現在階段用復委託會比較便宜一點。\n投資標的 伯格頭的投資指南第4條，Diversify，多樣性。\nETF一籃子的股票，含有各個領域與不同公司的股票\n伯格頭的投資指南第6條，Use index funds when possible，如果可能的話使用指數基金。\n006208 可以把它想成內扣費用較低的0050\n伯格頭的投資指南第8條，Minimize taxes，上班族繳太多稅了，少繳一點。\nVWRD 可以把它想成英國版的VT，但少了小型股部位，稅也比較少了。\n投資組合 伯格頭的投資指南第9條，Invest with simplicity，簡單才好管理。\n由於使用復委託，標的太多交易成本會太高，所以我是沒有配債的部位，先用高利率活存來代替，未來在考慮要不要加入債券部位。\n股票部位：VWRD 80%、006208 20%\n投入時間 伯格頭的投資指南第5條，Never try to time the market，錢夠就丟，我就看他能不能長出一朵花。\n持有越久的現金機會成本越大，應該儘早投入。\nVWRD每3~4個月手動操作買入\n006208定期定額買入\n未來 薪水高，累積財富的速度也才會快，專注於本業，提升自己的能力與價值。\n伯格頭的投資指南第10條，Stay the course，持之以恆。\n一直堅持下去就對了，如果心中有所疑惑，那可能是投資組合不適合自己，要再做調整。\n","date":"2021-12-06T10:55:10+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211206_%E6%8C%87%E6%95%B8%E6%8A%95%E8%B3%87.md/","title":"指數投資"},{"content":" 介紹 接下來的筆記是根據線上課程Microservices Architecture and Implementation on .NET 5所記錄下來的，講者的口音有點重，聽得有點吃力，他這個專案基本上重做微軟提供的範例專案，電商系統，完美呈現微服務的使用與他的優點，一共把服務切成四個主要的服務，Catalog(商品目錄系統)、Basket(購物車系統)、Discount(折扣系統)、Ordering(訂單系統)，並分別使用不同的資料庫(mongodb、redis、PostgreSQL、MSSQL)、不同的傳輸協定(Rest API、Grpc)、不同的架構(多層式架構、簡潔架構)，最後使用Docker容器化，把他們都整合在一起運作。\n整個系統的架構圖\r工作一陣子了，維護的系統基本也都上手了(龐大的Web Service架構)，但還有許多前人的智慧，一時之間是很難理解的XD，這時有一個乾淨的架構，或許上手的時間就可以更短了。\nDomain Layer 建立一個訂單系統使用Clean Architecture\n依照分層創建各個不同的Project， Ordering.API Ordering.Domain Ordering.Application Ordering.infrastructure 整個系統的架構圖\r建立相依關係Project右鍵 \u0026gt;\u0026gt; Add \u0026gt;\u0026gt; Reference 相依關係\r詳細定義與設計可以參考\nhttps://ithelp.ithome.com.tw/articles/10223150 https://ithelp.ithome.com.tw/articles/10223595\n開發Ordering.Domain Layer 我們要先建立兩個資料夾Common、Entities\nCommon 其中Common放的是我們建立Entity的基礎，含有兩個abstract class，EntityBase、ValueObject，\n//我們每一個Entity都要的屬性 public abstract class EntityBase { public int Id { get; protected set; } public string CreatedBy { get; set; } public DateTime CreatedDate { get; set; } public string LastModifiedBy { get; set; } public DateTime? LastModifiedDate { get; set; } } Entities 建立Order物件並繼承EntityBase\n//訂單必須要的屬性 public class Order : EntityBase { public string UserName { get; set; } public decimal TotalPrice { get; set; } // BillingAddress public string FirstName { get; set; } public string LastName { get; set; } public string EmailAddress { get; set; } public string AddressLine { get; set; } public string Country { get; set; } public string State { get; set; } public string ZipCode { get; set; } // Payment public string CardName { get; set; } public string CardNumber { get; set; } public string Expiration { get; set; } public string CVV { get; set; } public int PaymentMethod { get; set; } } 參考 簡潔架構 Application Layer\n簡潔架構 Infrastructure Layer\nhttps://www.udemy.com/course/microservices-architecture-and-implementation-on-dotnet/\nhttps://rwang.medium.com/%E5%86%8D%E8%AE%80%E6%95%B4%E6%BD%94%E6%9E%B6%E6%A7%8B-clean-architecture-12b562472c3b\n","date":"2021-12-02T15:52:49+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/2021202_%E7%B0%A1%E6%BD%94%E6%9E%B6%E6%A7%8Bdomain.md/","title":"簡潔架構 Domain Layer"},{"content":" 筆記 CQRS(Command Query Responsibility Segregation)命令查詢分隔，目前看起來就是不再需要IRepository了，把它拆成Command(負責寫入資料庫的部分)與Query(只負責讀取的部分)。\n可以增加資料庫的效能，Command的部分則會透過event的形式記錄起來再同步到DB上面。\n我還是偏好原本的方法啊XD\n參考 https://ithelp.ithome.com.tw/articles/10237458\n","date":"2021-12-01T11:08:44+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/2021201_cqrs.md/","title":"CQRS"},{"content":" 關於DDD 隨著科技進步，需求也是越來越複雜，更多的是需要專業領域人員與開發人員共同協作\nDDD是一種基於領域知識來解決複雜業務問題的軟體開發方法論。\nUbiquitous Language 使用通用語言就很重要了，講人話，減少溝通成本。 ex:下訂單大家就聽得懂，別講些什麼call Order API、B2C之類的\nAnemic Model Anemic Model貧血模型是指那些只有getter、setter沒有行為能力的模型\nLF2邪鬼(地獄火焰)防下功+防上跳+防前跳+防下跳+防上功 為例\nDevil Max = new Devil(); //使用地獄火焰 Max.Defence().Down().Attack(); Max.Defence().Up().Jump(); Max.Defence().Left().Jump(); Max.Defence().Down().Jump(); Max.Defence().Up().Attack(); 導入DDD與專家討論過後，未來開發的人員直接看程式碼也看得懂在幹嘛\nDevil Max = new Devil(); Max.HellFire(); 與微服務的關係 很多時候Micorservices不知道怎麼做切割，這時候DDD就提供一個很好的方向去做業務分割。\n參考 https://ithelp.ithome.com.tw/articles/10216645 https://forum.gamer.com.tw/C.php?bsn=7648\u0026snA=3299\n","date":"2021-11-30T14:30:40+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/2021130_ddd.md/","title":"Domain Driven Design 領域驅動設計"},{"content":" SOLID原則 Single responsibility principle 單一功能原則 認為一個class就應該只有一個任務要做，不做其他任務以外的事情，過去是很多不同的需求都用同一個Service，單一功能原則則是提供各種不同的Use Case給各個需求。 SRP示意圖\rOpen/ closed principle 開閉原則 一個class或Function對於他的擴展是開放的，但是對於修改是封閉的，意思就是不改變他的行為，但是可以增加新的功能。 就像是電動理髮刀，可以換上各種不同的刀頭(擴展)，但是機身本體是不能修改的(封閉)。\nLiskov substitution principle 里氏替換原則 程式中的物件應該是可以在不改變正確性的前提下被他的子類所替換的概念，我們在使用「繼承」時，重要的是重複使用 (reuse) 已經寫好的行為，而不是將所有繼承的行為全部覆蓋。\nInterface segregation principle 介面隔離原則 很多個客製化的interface比一個通用的interface還要來得更好管理，例如一個政客interface有提出政見()、拜票()、努力工作()，但事實上不是每一個政客都想實作努力工作XD，所以應該方別建兩個interface，政客介面:提出政見()、拜票()與工作介面:努力工作()。\nDependency inversion principle 依賴反轉原則 各個class之間的相依性應該越低越好，上層的class不該依賴下層的class DIP示意圖\rSoC(Separation of concerns) 關注點分離 關注點分離表示，以前端的例子來說，在過去我們是以「關注技術」的方式來分離成HTML、CSS、JavaScript，現今主流框架Vue則是採用「關注元件」的方式來分離，每一個Component都有各自的HTML、CSS、JavaScript。\n參考 https://zh.wikipedia.org/wiki/SOLID_(%E9%9D%A2%E5%90%91%E5%AF%B9%E8%B1%A1%E8%AE%BE%E8%AE%A1) https://medium.com/@f40507777/%E9%96%8B%E6%94%BE%E5%B0%81%E9%96%89%E5%8E%9F%E5%89%87-open-closed-principle-31d61f9d37a5 https://medium.com/%E6%89%8B%E5%AF%AB%E7%AD%86%E8%A8%98/%E7%AC%AC-10-%E7%AB%A0-%E9%A1%9E%E5%88%A5-clean-code-1c7898d11cd7\n","date":"2021-11-29T16:10:40+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/2021129_solid%E5%8E%9F%E5%89%87.md/","title":"SOLID、SoC"},{"content":" 筆記 可以輕鬆的轉換兩個class，讓程式碼變得更加簡短乾淨。\nmessage CouponModel { int32 id = 1; string productName = 2; string description = 3; int32 amount = 4; } 在Grpc定義的優戶券模型\npublic class Coupon { public int Id { get; set; } public string ProductName { get; set; } public string Description { get; set; } public int Amount { get; set; } } 我們自己定義的模型\n原先轉換需要像是這個樣子\nCoupon coupon; CouponModel cm = new CouponModel{ id = coupon.Id, productName = coupon.ProductName, description = coupon.Description, amount = coupon.Amount } 使用Mapper後只要\nCoupon coupon; CouponModel cm = _mapper.Map\u0026lt;CouponModel\u0026gt;(coupon); 如何使用 1.Nuget搜尋並下載AutoMapper.Extensions.Microsoft.DependencyInjection\n2.在Startup註冊AutoMapper服務\npublic void ConfigureServices(IServiceCollection services) { services.AddAutoMapper(typeof(Startup)); } 3.建立轉換的Porfile\npublic class CouponProfile :Profile //繼承Profile { public CouponProfile() { //讓Coupon與CouponModel可以方便地互相轉換 CreateMap\u0026lt;Coupon, CouponModel\u0026gt;().ReverseMap(); } } 4.依賴注入到需要使用的class裡\nprivate readonly IMapper _mapper; public DiscountService(IMapper mapper) { _mapper = mapper; } 5.享受AutoMapper帶來的便利~~\n參考 https://igouist.github.io/post/2020/07/automapper/\n","date":"2021-11-25T14:55:07+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211125_automapper.md/","title":"AutoMapper - DI Version"},{"content":" 筆記 Grpc是google開發的rpc(Remote Procedure Call)框架，用於電腦與電腦之間的溝通，就像電腦A呼叫電腦B做事情，電腦B做好事情後把結果回傳給電腦A，與一般的api不同的地方在於，電腦A、B在進行Grpc溝通前，都必須有protocal buffers檔案來把格式與方法定義清楚，並使用HTTP/2進行傳輸，快速、低延遲、支持串流。\nprotocal buffers 檔案 在VS裡面，Add \u0026raquo; New Project \u0026raquo; 選gRPC Service \u0026raquo; \u0026hellip;一些基本設定\n生成新gRPC Service後，裡面會有.proto檔案\nsyntax = \u0026#34;proto3\u0026#34;;//使用的protocal buffers版本 option csharp_namespace = \u0026#34;MyFirstGrpc.Grpc\u0026#34;;//命名空間 package greeter; // 定義交換資料的格式 message HelloRequest { string name = 1; } // 定義交換資料的格式 message HelloReply { string message = 1; } // 定義呼叫api的方法 service Greeter { // SayHello方法需要輸入參數(HelloRequest格式) 會回傳(HelloReply格式) rpc SayHello (HelloRequest) returns (HelloReply); } AppSettings 使用Http2 { \u0026#34;Logging\u0026#34;: { \u0026#34;LogLevel\u0026#34;: { \u0026#34;Default\u0026#34;: \u0026#34;Information\u0026#34;, \u0026#34;Microsoft\u0026#34;: \u0026#34;Warning\u0026#34;, \u0026#34;Microsoft.Hosting.Lifetime\u0026#34;: \u0026#34;Information\u0026#34; } }, \u0026#34;AllowedHosts\u0026#34;: \u0026#34;*\u0026#34;, \u0026#34;Kestrel\u0026#34;: { \u0026#34;EndpointDefaults\u0026#34;: { \u0026#34;Protocols\u0026#34;: \u0026#34;Http2\u0026#34; } } } 我們可以看到在AppSettings裡Protocols是採用Http2\n產生Service class檔案 如果設定都沒有錯的話，會在MyFirstGrpc.Grpc/obj/Debug/net5.0/Protos產生Greet.cs與GreetGrpc.cs\n若資料夾內沒有產生cs檔，很有可能是專案檔MyFirstGrpc.Grpc.csproj裡面設定有問題。\n確保有\u0026lt;Protobuf Include=\u0026quot;Protos\\greet.proto\u0026quot; GrpcServices=\u0026quot;Server\u0026quot; /\u0026gt;對.proto做編譯\n//參考的.csproj \u0026lt;?xml version=\u0026#34;1.0\u0026#34; encoding=\u0026#34;UTF-8\u0026#34;?\u0026gt; \u0026lt;Project Sdk=\u0026#34;Microsoft.NET.Sdk.Web\u0026#34;\u0026gt; \u0026lt;PropertyGroup\u0026gt; \u0026lt;TargetFramework\u0026gt;net5.0\u0026lt;/TargetFramework\u0026gt; \u0026lt;/PropertyGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;None Remove=\u0026#34;Protos\\greeter.proto\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;PackageReference Include=\u0026#34;Grpc.AspNetCore\u0026#34; Version=\u0026#34;2.32.0\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt; \u0026lt;ItemGroup\u0026gt; \u0026lt;Protobuf Include=\u0026#34;Protos\\greeter.proto\u0026#34; GrpcServices=\u0026#34;Server\u0026#34; /\u0026gt; \u0026lt;/ItemGroup\u0026gt; \u0026lt;/Project\u0026gt; GreeterService 實作 namespace MyFirstGrpc.Grpc { public class GreeterService : Greeter.GreeterBase { private readonly ILogger\u0026lt;GreeterService\u0026gt; _logger; public GreeterService(ILogger\u0026lt;GreeterService\u0026gt; logger) { _logger = logger; } public override Task\u0026lt;HelloReply\u0026gt; SayHello(HelloRequest request, ServerCallContext context) { return Task.FromResult(new HelloReply { Message = $\u0026#34;Hello {request.Name}\u0026#34; }); } } } 在Services/GreeterService.cs下\n繼承自動產生的Greeter下的GreeterBase並將其覆寫，最主要的邏輯也是寫在這邊。\nSayHello方法需要輸入參數(HelloRequest格式) 會回傳(HelloReply格式)\nTip:輸入override按下空白，VS會自動把可以override的class顯示出來。\n註冊Grpc服務 public class Startup { public void ConfigureServices(IServiceCollection services) { services.AddGrpc(); } public void Configure(IApplicationBuilder app, IWebHostEnvironment env) { if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } app.UseRouting(); app.UseEndpoints(endpoints =\u0026gt; { endpoints.MapGrpcService\u0026lt;GreeterService\u0026gt;(); endpoints.MapGet(\u0026#34;/\u0026#34;, async context =\u0026gt; { await context.Response.WriteAsync(\u0026#34;Communication with gRPC endpoints must be made through a gRPC client. To learn how to create a client, visit: https://go.microsoft.com/fwlink/?linkid=2086909\u0026#34;); }); }); } } 在startup.cs下 透過services.AddGrpc();註冊Grpc服務，方可使用Grpc。 透過endpoints.MapGrpcService\u0026lt;GreeterService\u0026gt;();把所有Grpc服務部署到Routing Pipeline裡\n新增Grpc服務的reference 購物車的功能需要導入折價券.Grpc的服務\n購物車是Client端\n折價券是Server端\nVS for Mac在專案下面就可以直接看到Connected Services Windows則是右鍵 \u0026raquo; Add \u0026raquo; connected services\n選取購物車專案的connected services \u0026raquo; Add new Grpc service reference \u0026raquo; Add \u0026raquo; 參照折價券.Grpc裡面的.proto \u0026raquo; 選擇Client模式\n執行完後，可以看到.csproj多了Grpc服務、專案下也多了protos\n\u0026lt;Protobuf Include=\u0026#34;..\\..\\Discount\\Discount.Grpc\\Discount.Grpc\\Protos\\discount.proto\u0026#34; GrpcServices=\u0026#34;Client\u0026#34;\u0026gt; \u0026lt;OutputDir\u0026gt;obj\\Debug\\net5.0\\\u0026lt;/OutputDir\u0026gt; \u0026lt;Link\u0026gt;Protos\\discount.proto\u0026lt;/Link\u0026gt; \u0026lt;/Protobuf\u0026gt; 建置專案後，也會產生ProtoServiceClient等cs檔\n參考 https://pjchender.dev/golang/grpc-getting-started/\nhttps://docs.microsoft.com/en-us/aspnet/core/grpc/aspnetcore?view=aspnetcore-6.0\u0026tabs=visual-studio\n","date":"2021-11-24T10:12:35+08:00","permalink":"https://robertbasement.github.io/my-blog/posts/post/2021/20211124_grpcmemo.md/","title":"Grpc 筆記"},{"content":"","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""},{"content":"from cmoney.client import CMoneyDownloader host_addr = \u0026#39;192.168.1.56\u0026#39; dl = CMoneyDownloader(host_addr) event_df = await dl.query(\u0026#39;日個股事件\u0026#39;, start=\u0026#39;20150101\u0026#39;) import pandas as pd import numpy as np import matplotlib.pyplot as plt company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] company_event.columns Index(['日期', '股票代號', '股票名稱', '月營收公告', '財報公告', '除息日', '除權日', '法說會', '減資前', '減資後', '股東會', '申報轉讓', '庫藏股', '注意股票', '新股上市', '人事異動', '停資', '停券', '最後回補日', '今日事件數', 'RTIME'], dtype='object') company_event.loc[~company_event[\u0026#39;減資前\u0026#39;].isna(), [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]] company_event.columns 400張以上大戶持股比例數據異常\ncompany_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) , [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 import pandas as pd # Example DataFrame with datetime data = {\u0026#39;date\u0026#39;: [\u0026#39;2024-12-12\u0026#39;, \u0026#39;2024-12-18\u0026#39;, \u0026#39;2024-12-25\u0026#39;, \u0026#39;2024-12-26\u0026#39;]} df = pd.DataFrame(data) df[\u0026#39;date\u0026#39;] = pd.to_datetime(df[\u0026#39;date\u0026#39;]) # Transform to the Friday of that week df[\u0026#39;friday_of_week\u0026#39;] = df[\u0026#39;date\u0026#39;] + pd.offsets.Week(weekday=4) print(df) date friday_of_week 0 2024-12-12 2024-12-13 1 2024-12-18 2024-12-20 2 2024-12-25 2024-12-27 3 2024-12-26 2024-12-27 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) TJP = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/threeJuridicalPerson.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;,\u0026#39;外資持股比率(%)\u0026#39;,\u0026#39;投信持股比率(%)\u0026#39;, \u0026#39;自營商持股比率(%)\u0026#39;]) TJP = TJP[TJP[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] TJP.sort_values(\u0026#39;日期\u0026#39;, inplace=True) TJP.reset_index(drop=True, inplace=True) TJP.columns Index(['日期', '股票代號', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)'], dtype='object') margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) margin_df = margin_df[margin_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] margin_df.sort_values(\u0026#39;日期\u0026#39;, inplace=True) margin_df.reset_index(drop=True, inplace=True) margin_df.columns Index(['日期', '股票代號', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)'], dtype='object') SUB_TICKERS ['2059', '3529', '2383', '2330', '8069', '5274', '3008', '2454', '3533'] sub = weekly_depostie[(weekly_depostie[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;]))] agg = sub.groupby(\u0026#39;日期\u0026#39;)[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() 400張以上比率sum agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() # 100張以上 agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0100001-0200000\u0026#39;, \u0026#39;0200001-0400000\u0026#39;,\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 5張以下 sum agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0000001-0000999\u0026#39;, \u0026#39;0001000-0005000\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) agg weekly_depostie[\u0026#39;持股分級\u0026#39;].unique() price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].str.contains(r\u0026#39;^\\d{4}$\u0026#39;)] # price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].str.contains(r\u0026#39;^\\d{4}$\u0026#39;)] price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) 支撐突破 from scipy.signal import argrelextrema def groupby_extrema(df): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, \u0026#39;收盤價\u0026#39;].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, \u0026#39;收盤價\u0026#39;].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(groupby_extrema) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:30: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3364936880.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3881079495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(groupby_extrema) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 price_df.reset_index(drop=True, inplace=True) ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_min(df): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[\u0026#39;收盤價\u0026#39;].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, \u0026#39;收盤價\u0026#39;].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, \u0026#39;收盤價\u0026#39;].values, index=local_min_indices) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(groupby_extrema_min) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:31: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/380407828.py:35: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3402733562.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(groupby_extrema_min) price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]!=\u0026#39;3008\u0026#39;)\u0026amp; (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 price_df.reset_index(drop=True, inplace=True) price_df[price_df[\u0026#39;signal\u0026#39;]==1] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg = agg.merge(price_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg = agg.merge(TJP, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg = agg.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) company_event.columns Index(['日期', '股票代號', '股票名稱', '月營收公告', '財報公告', '除息日', '除權日', '法說會', '減資前', '減資後', '股東會', '申報轉讓', '庫藏股', '注意股票', '新股上市', '人事異動', '停資', '停券', '最後回補日', '今日事件數', 'RTIME', '日期_dt', 'friday_of_week', 'adjust_week'], dtype='object') agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) agg.columns Index(['日期', '股票代號', '佔集保庫存數比例(%)', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'hold_120Days_winrate', 'max_comparisons_larger', 'local_maxima', 'signal', 'min_comparisons_smaller', 'local_minima', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)', 'friday_of_week', '減資前', '新股上市', 'adjust_week'], dtype='object') agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg.columns Index(['日期', '股票代號', '佔集保庫存數比例(%)', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'hold_120Days_winrate', 'max_comparisons_larger', 'local_maxima', 'signal', 'min_comparisons_smaller', 'local_minima', '外資持股比率(%)', '投信持股比率(%)', '自營商持股比率(%)', '資餘', '券餘', '券資比', '當沖比率', '融資成本(推估)', '融券成本(推估)', '融資維持率(%)', '融券維持率(%)', '整體維持率(%)', 'friday_of_week', '減資前', '新股上市', 'adjust_week'], dtype='object') 過去一段時間週集保變化 vs 後續一段時間return 絕對變化的% 期間的震盪程度 時間分成5份 每一個時間點的平均return / precision import pandas as pd from sklearn.model_selection import TimeSeriesSplit def split_by_timeframe(data, date_col, n_splits): \u0026#34;\u0026#34;\u0026#34; Splits time series data into equal time-based chunks. Args: data (pd.DataFrame): Time series data. date_col (str): Column name containing datetime values. n_splits (int): Number of splits. Returns: list: A list of dataframes, each corresponding to a split. \u0026#34;\u0026#34;\u0026#34; # Ensure datetime format data[date_col] = pd.to_datetime(data[date_col]) # Sort by date data = data.sort_values(by=date_col) # Compute timeframe boundaries start_date = data[date_col].min() end_date = data[date_col].max() timeframe = (end_date - start_date) / n_splits timeframes = [start_date + i * timeframe for i in range(n_splits + 1)] # Split data by timeframes splits = [ data[(data[date_col] \u0026gt;= timeframes[i]) \u0026amp; (data[date_col] \u0026lt; timeframes[i + 1])] for i in range(n_splits) ] return splits # Example usage data = pd.DataFrame({ \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2023-01-01\u0026#39;, periods=100, freq=\u0026#39;D\u0026#39;), # Random irregular time series \u0026#39;value\u0026#39;: range(100) }) splits = split_by_timeframe(data, date_col=\u0026#39;date\u0026#39;, n_splits=5) # Print the results for i, split in enumerate(splits): print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;date\u0026#39;].min()} to {split[\u0026#39;date\u0026#39;].max()}\u0026#34;) Split 1: 20 rows, from 2023-01-01 00:00:00 to 2023-01-20 00:00:00 Split 2: 20 rows, from 2023-01-21 00:00:00 to 2023-02-09 00:00:00 Split 3: 20 rows, from 2023-02-10 00:00:00 to 2023-03-01 00:00:00 Split 4: 20 rows, from 2023-03-02 00:00:00 to 2023-03-21 00:00:00 Split 5: 19 rows, from 2023-03-22 00:00:00 to 2023-04-09 00:00:00 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=5) # Print the results for i, split in enumerate(splits): print(split[\u0026#39;hold_20Days_ret\u0026#39;].mean()) print(split[\u0026#39;hold_20Days_winrate\u0026#39;].mean()) print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) 0.020042361220259826 0.5847362514029181 Split 1: 891 rows, from 2015-05-08 00:00:00 to 2017-03-31 00:00:00 0.011071535202021886 0.5230078563411896 Split 2: 891 rows, from 2017-04-07 00:00:00 to 2019-02-27 00:00:00 0.03613439907321296 0.6285072951739619 Split 3: 891 rows, from 2019-03-08 00:00:00 to 2021-01-22 00:00:00 0.017309024770151112 0.5108820160366552 Split 4: 882 rows, from 2021-01-29 00:00:00 to 2022-12-16 00:00:00 0.044214360887047124 0.5861678004535147 Split 5: 882 rows, from 2022-12-23 00:00:00 to 2024-11-08 00:00:00 週集保 高or 低於 月線, 半年線 後續return (不用要求每一黨都可以work 找出能用的ticker就好) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) 因為新股發行/減資等 把有調整的week 其週集保的變化 set 0 agg[agg[\u0026#39;adjust_week\u0026#39;]==1].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[agg[\u0026#39;adjust_week\u0026#39;]==1].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) agg.loc[agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;佔集保庫存數比例(%)\u0026#39;, \u0026#39;週集保月線\u0026#39;, \u0026#39;週集保半年線\u0026#39;]] agg[\u0026#39;週集保diff\u0026#39;].describe() agg.columns return_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] qcut 依據數量做group 但有幾個點要注意, 每個分類的出現時間點不明 我要怎麼讓特定group set signal = 1來判斷個時間點的signal 數 \u0026amp; return? def groupcut(df, col): comcode = df[\u0026#39;股票代號\u0026#39;].iloc[-1] df[f\u0026#39;qcut_{comcode}\u0026#39;] = pd.qcut(df[col], 10) benchmark_df = df[return_cols].mean() # res = df.groupby(f\u0026#39;qcut_{comcode}\u0026#39;)[return_cols].mean() - benchmark_df res = df.groupby(f\u0026#39;qcut_{comcode}\u0026#39;)[return_cols].mean() return res import pandas as pd import numpy as np # Create a sample DataFrame with random data np.random.seed(42) data = pd.DataFrame({\u0026#39;value\u0026#39;: np.random.uniform(-0.2, 0.2, 100)}) # Define the range and bins bins = np.arange(-0.1, 0.1 + 0.05, 0.05) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {i}\u0026#39; for i in range(1, len(bins))] # Group labels # Categorize the data into groups data[\u0026#39;group\u0026#39;] = pd.cut(data[\u0026#39;value\u0026#39;], bins=bins, labels=labels, include_lowest=True) print(data.head()) import pandas as pd import numpy as np # Create a sample DataFrame with random data np.random.seed(42) data = pd.DataFrame({\u0026#39;value\u0026#39;: np.random.uniform(-0.2, 0.3, 100)}) # Extended range for example # Define the range and bins bins = np.arange(-0.1, 0.1 + 0.05, 0.05) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {i}\u0026#39; for i in range(1, len(bins))] # Group labels # Categorize the data into groups, including out-of-range values data[\u0026#39;group\u0026#39;] = pd.cut( data[\u0026#39;value\u0026#39;], bins=bins, labels=labels, include_lowest=True, right=False # Left-inclusive bins ) # Handle values outside the bins data[\u0026#39;group\u0026#39;] = data[\u0026#39;group\u0026#39;].cat.add_categories([\u0026#39;Outliers\u0026#39;]) # Add \u0026#39;Outliers\u0026#39; as a category data[\u0026#39;group\u0026#39;].fillna(\u0026#39;Outliers\u0026#39;, inplace=True) # Assign out-of-range values to \u0026#39;Outliers\u0026#39; print(data.head()) # Define the range and bins bins = np.arange(-10, 10, 1) # Range from -0.1 to 0.1 with 0.05 increments labels = [f\u0026#39;Group {bins[i - 1]:.2f}\u0026#39; for i in range(1, len(bins))] # Group labels labels ['Group -10.00', 'Group -9.00', 'Group -8.00', 'Group -7.00', 'Group -6.00', 'Group -5.00', 'Group -4.00', 'Group -3.00', 'Group -2.00', 'Group -1.00', 'Group 0.00', 'Group 1.00', 'Group 2.00', 'Group 3.00', 'Group 4.00', 'Group 5.00', 'Group 6.00', 'Group 7.00', 'Group 8.00'] agg[\u0026#39;週集保diff4week\u0026#39;].describe() count 4.410000e+03 mean 9.682553e-04 std 1.172644e+00 min -7.130000e+00 25% -5.199995e-01 50% -9.834766e-07 75% 5.599985e-01 max 5.129999e+00 Name: 週集保diff4week, dtype: float64 agg[\u0026#39;group\u0026#39;] = pd.cut( agg[\u0026#39;週集保diff4week\u0026#39;], bins=bins, labels=labels, include_lowest=True, right=False # Left-inclusive bins ) agg[\u0026#39;group\u0026#39;] = agg[\u0026#39;group\u0026#39;].cat.add_categories([\u0026#39;Outliers\u0026#39;]) # Add \u0026#39;Outliers\u0026#39; as a category agg[\u0026#39;group\u0026#39;].fillna(\u0026#39;Outliers\u0026#39;, inplace=True) # Assign out-of-range values to \u0026#39;Outliers\u0026#39; /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3887867593.py:2: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. agg['group'].fillna('Outliers', inplace=True) # Assign out-of-range values to 'Outliers' agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;3, return_cols].mean() hold_5Days_ret 0.009619 hold_10Days_ret 0.023788 hold_20Days_ret 0.022823 hold_60Days_ret 0.132806 hold_120Days_ret 0.216323 dtype: float64 winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg[return_cols].mean() hold_5Days_ret 0.006679 hold_10Days_ret 0.013289 hold_20Days_ret 0.025638 hold_60Days_ret 0.077952 hold_120Days_ret 0.160038 dtype: float64 for i in range(0, 6): print(f\u0026#39;週集保diff4week\u0026gt;={i}\u0026#39;, \u0026#39;-\u0026#39;*50) print(agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=i, return_cols].mean()) print(agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=i, winrate_cols].mean()) 週集保diff4week\u0026gt;=0 -------------------------------------------------- hold_5Days_ret 0.006911 hold_10Days_ret 0.014504 hold_20Days_ret 0.027247 hold_60Days_ret 0.077227 hold_120Days_ret 0.162232 dtype: float64 hold_5Days_winrate 0.525740 hold_10Days_winrate 0.555353 hold_20Days_winrate 0.569476 hold_60Days_winrate 0.610023 hold_120Days_winrate 0.658770 dtype: float64 週集保diff4week\u0026gt;=1 -------------------------------------------------- hold_5Days_ret 0.006452 hold_10Days_ret 0.014195 hold_20Days_ret 0.028679 hold_60Days_ret 0.084416 hold_120Days_ret 0.181973 dtype: float64 hold_5Days_winrate 0.520000 hold_10Days_winrate 0.533333 hold_20Days_winrate 0.576296 hold_60Days_winrate 0.616296 hold_120Days_winrate 0.699259 dtype: float64 週集保diff4week\u0026gt;=2 -------------------------------------------------- hold_5Days_ret 0.007483 hold_10Days_ret 0.019430 hold_20Days_ret 0.029827 hold_60Days_ret 0.089183 hold_120Days_ret 0.189969 dtype: float64 hold_5Days_winrate 0.513228 hold_10Days_winrate 0.529101 hold_20Days_winrate 0.603175 hold_60Days_winrate 0.603175 hold_120Days_winrate 0.777778 dtype: float64 週集保diff4week\u0026gt;=3 -------------------------------------------------- hold_5Days_ret 0.009619 hold_10Days_ret 0.023788 hold_20Days_ret 0.022823 hold_60Days_ret 0.132806 hold_120Days_ret 0.216323 dtype: float64 hold_5Days_winrate 0.531915 hold_10Days_winrate 0.553191 hold_20Days_winrate 0.659574 hold_60Days_winrate 0.702128 hold_120Days_winrate 0.808511 dtype: float64 週集保diff4week\u0026gt;=4 -------------------------------------------------- hold_5Days_ret -0.012338 hold_10Days_ret -0.000531 hold_20Days_ret -0.027299 hold_60Days_ret 0.185005 hold_120Days_ret 0.252875 dtype: float64 hold_5Days_winrate 0.294118 hold_10Days_winrate 0.294118 hold_20Days_winrate 0.470588 hold_60Days_winrate 0.764706 hold_120Days_winrate 0.882353 dtype: float64 週集保diff4week\u0026gt;=5 -------------------------------------------------- hold_5Days_ret -0.050694 hold_10Days_ret -0.098042 hold_20Days_ret -0.118287 hold_60Days_ret 0.251046 hold_120Days_ret 0.330517 dtype: float64 hold_5Days_winrate 0.0 hold_10Days_winrate 0.0 hold_20Days_winrate 0.0 hold_60Days_winrate 1.0 hold_120Days_winrate 1.0 dtype: float64 for i in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): mask = (agg[\u0026#39;股票代號\u0026#39;]==i) print(i, \u0026#39;-\u0026#39;*50) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), return_cols].mean()) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), winrate_cols].mean()) print(agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2) \u0026amp; (mask), winrate_cols].count()) 2059 -------------------------------------------------- hold_5Days_ret 0.027832 hold_10Days_ret 0.052327 hold_20Days_ret 0.060835 hold_60Days_ret 0.086638 hold_120Days_ret 0.114998 dtype: float64 hold_5Days_winrate 0.444444 hold_10Days_winrate 0.555556 hold_20Days_winrate 0.444444 hold_60Days_winrate 0.555556 hold_120Days_winrate 0.444444 dtype: float64 hold_5Days_winrate 9 hold_10Days_winrate 9 hold_20Days_winrate 9 hold_60Days_winrate 9 hold_120Days_winrate 9 dtype: int64 2330 -------------------------------------------------- hold_5Days_ret NaN hold_10Days_ret NaN hold_20Days_ret NaN hold_60Days_ret NaN hold_120Days_ret NaN dtype: float64 hold_5Days_winrate NaN hold_10Days_winrate NaN hold_20Days_winrate NaN hold_60Days_winrate NaN hold_120Days_winrate NaN dtype: float64 hold_5Days_winrate 0 hold_10Days_winrate 0 hold_20Days_winrate 0 hold_60Days_winrate 0 hold_120Days_winrate 0 dtype: int64 2383 -------------------------------------------------- hold_5Days_ret 0.005892 hold_10Days_ret 0.031547 hold_20Days_ret 0.059150 hold_60Days_ret 0.060357 hold_120Days_ret 0.161821 dtype: float64 hold_5Days_winrate 0.514286 hold_10Days_winrate 0.600000 hold_20Days_winrate 0.742857 hold_60Days_winrate 0.571429 hold_120Days_winrate 0.685714 dtype: float64 hold_5Days_winrate 35 hold_10Days_winrate 35 hold_20Days_winrate 35 hold_60Days_winrate 35 hold_120Days_winrate 35 dtype: int64 2454 -------------------------------------------------- hold_5Days_ret -0.002074 hold_10Days_ret 0.012793 hold_20Days_ret 0.113898 hold_60Days_ret 0.236901 hold_120Days_ret 0.328099 dtype: float64 hold_5Days_winrate 0.5 hold_10Days_winrate 0.5 hold_20Days_winrate 0.5 hold_60Days_winrate 1.0 hold_120Days_winrate 1.0 dtype: float64 hold_5Days_winrate 2 hold_10Days_winrate 2 hold_20Days_winrate 2 hold_60Days_winrate 2 hold_120Days_winrate 2 dtype: int64 3008 -------------------------------------------------- hold_5Days_ret 0.047004 hold_10Days_ret 0.079946 hold_20Days_ret 0.001695 hold_60Days_ret -0.054823 hold_120Days_ret -0.057345 dtype: float64 hold_5Days_winrate 0.666667 hold_10Days_winrate 1.000000 hold_20Days_winrate 0.333333 hold_60Days_winrate 0.333333 hold_120Days_winrate 0.666667 dtype: float64 hold_5Days_winrate 3 hold_10Days_winrate 3 hold_20Days_winrate 3 hold_60Days_winrate 3 hold_120Days_winrate 3 dtype: int64 3529 -------------------------------------------------- hold_5Days_ret 0.020865 hold_10Days_ret 0.033990 hold_20Days_ret 0.028309 hold_60Days_ret 0.061575 hold_120Days_ret 0.118578 dtype: float64 hold_5Days_winrate 0.631579 hold_10Days_winrate 0.631579 hold_20Days_winrate 0.578947 hold_60Days_winrate 0.736842 hold_120Days_winrate 0.736842 dtype: float64 hold_5Days_winrate 19 hold_10Days_winrate 19 hold_20Days_winrate 19 hold_60Days_winrate 19 hold_120Days_winrate 19 dtype: int64 3533 -------------------------------------------------- hold_5Days_ret 0.001765 hold_10Days_ret 0.003480 hold_20Days_ret -0.001786 hold_60Days_ret 0.061982 hold_120Days_ret 0.120031 dtype: float64 hold_5Days_winrate 0.489796 hold_10Days_winrate 0.469388 hold_20Days_winrate 0.571429 hold_60Days_winrate 0.530612 hold_120Days_winrate 0.795918 dtype: float64 hold_5Days_winrate 49 hold_10Days_winrate 49 hold_20Days_winrate 49 hold_60Days_winrate 49 hold_120Days_winrate 49 dtype: int64 5274 -------------------------------------------------- hold_5Days_ret -0.003093 hold_10Days_ret -0.001091 hold_20Days_ret -0.005808 hold_60Days_ret 0.174683 hold_120Days_ret 0.356038 dtype: float64 hold_5Days_winrate 0.500000 hold_10Days_winrate 0.441176 hold_20Days_winrate 0.558824 hold_60Days_winrate 0.823529 hold_120Days_winrate 0.941176 dtype: float64 hold_5Days_winrate 34 hold_10Days_winrate 34 hold_20Days_winrate 34 hold_60Days_winrate 34 hold_120Days_winrate 34 dtype: int64 8069 -------------------------------------------------- hold_5Days_ret 0.011655 hold_10Days_ret 0.028562 hold_20Days_ret 0.068309 hold_60Days_ret 0.091415 hold_120Days_ret 0.217771 dtype: float64 hold_5Days_winrate 0.500000 hold_10Days_winrate 0.526316 hold_20Days_winrate 0.631579 hold_60Days_winrate 0.473684 hold_120Days_winrate 0.789474 dtype: float64 hold_5Days_winrate 38 hold_10Days_winrate 38 hold_20Days_winrate 38 hold_60Days_winrate 38 hold_120Days_winrate 38 dtype: int64 8069, 2383 agg.loc[agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=0, winrate_cols].mean() hold_5Days_winrate 0.525740 hold_10Days_winrate 0.555353 hold_20Days_winrate 0.569476 hold_60Days_winrate 0.610023 hold_120Days_winrate 0.658770 dtype: float64 agg.groupby(\u0026#39;group\u0026#39;)[return_cols].mean() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/3754709820.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[return_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } Model 上線標準 - 同期大盤年化報酬的2倍(扣除手續費) \u0026amp; mdd \u0026lt; -40% \u0026amp; PnL 沒有創新高的期間\u0026lt;3y 今年 : 2個可以上線的model\n一個project 2個月\n產業surey 前10大產業market cap, 做基本面/籌碼面指標加總 -\u0026gt; 找出領先指標 建立投組\n美股產業也可以做\nagg.groupby(\u0026#39;group\u0026#39;)[return_cols].count() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/635314126.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[return_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg.groupby(\u0026#39;group\u0026#39;)[winrate_cols].mean() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_18256/432786995.py:1: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. agg.groupby('group')[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } qcut_res = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupcut(df, \u0026#39;週集保diff4week\u0026#39;)) qcut_res.loc[\u0026#39;2383\u0026#39;] mask1 = (agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;1.958) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;2.986) agg.loc[mask1 \u0026amp; mask2, return_cols].mean() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): splits = split_by_timeframe(agg[agg[\u0026#39;股票代號\u0026#39;]==ticker], date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() print(ticker, \u0026#39;-\u0026#39;*50) print(split_res) # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) 5274, 2383 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;5274\u0026#39;, \u0026#39;2383\u0026#39;]), return_cols].mean() hold_5Days_ret 0.008201 hold_10Days_ret 0.016249 hold_20Days_ret 0.031963 hold_60Days_ret 0.101030 hold_120Days_ret 0.199245 dtype: float64 agg.loc[(agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=3), return_cols].mean() hold_5Days_ret 0.010208 hold_10Days_ret 0.021064 hold_20Days_ret 0.039608 hold_60Days_ret 0.115359 hold_120Days_ret 0.198587 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), return_cols].mean() hold_5Days_ret 0.008892 hold_10Days_ret 0.029993 hold_20Days_ret 0.063918 hold_60Days_ret 0.076749 hold_120Days_ret 0.191766 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), winrate_cols].mean() hold_5Days_winrate 0.506849 hold_10Days_winrate 0.561644 hold_20Days_winrate 0.684932 hold_60Days_winrate 0.520548 hold_120Days_winrate 0.739726 dtype: float64 agg.loc[agg[\u0026#39;股票代號\u0026#39;].isin([\u0026#39;8069\u0026#39;, \u0026#39;2383\u0026#39;]) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;=2), \u0026#39;signal\u0026#39;] = 1 qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.left \u0026gt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.right \u0026lt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10] top10_index = qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10].index top10_index = qcut_res[qcut_res.index.get_level_values(1).map(lambda x: x.left \u0026gt; 0)].sort_values(\u0026#39;hold_20Days_ret\u0026#39;,ascending=False).iloc[0:10].index top10_index for i in top10_index: print(i[1].left) # agg[\u0026#39;signal\u0026#39;] = 0 for i in top10_index: mask1 = (agg[\u0026#39;股票代號\u0026#39;]==i[0]) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;i[1].left) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;i[1].right) agg.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) splits[0][\u0026#39;日期\u0026#39;].dt.strftime(\u0026#39;%Y%m%d\u0026#39;) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res 若是更簡單的 大戶持股比例在 月/半年線上 下 agg.columns agg[\u0026#39;signal\u0026#39;] = 0 mask = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保月線\u0026#39;]) agg.loc[mask, \u0026#39;signal\u0026#39;] = 1 splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res 融資維持率 agg.columns qcut_res = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupcut(df, \u0026#39;融資維持率(%)\u0026#39;)) 融資成本(推估) = [昨日融資成本 * (昨日資餘 - 今日資限償 - 資賣)] + [今日資買 * 今日收盤 / 今日資餘] 假設今天沒有任何買入 則今日融資成本一樣\n若是今日有買入 且今日股價較高 -\u0026gt; 會拉高融資成本\n反過來 今日有買入 但今日股價較低 -\u0026gt; 會拉低融資成本\n又或是我們該這樣想 有四種狀況\n今日資餘 \u0026gt; 昨日資餘 (=今日資買 \u0026gt; (今日資線嘗 + 資賣)), 今日收盤 \u0026gt; 昨日融資成本 = 融資成本上升,\n但這還要對比收盤價上升的幅度 以我的感覺來說 收盤價變動的幅度較大 融資成本跟不太上 然而當股價上漲的時候 融資維持率會增加 反過來股價下跌的時候融資維持率會降\n既然如此 那融資維持率低 是否可以解讀成\n股價大幅下殺 但是對應的資餘 減少沒那麼快 所以才有低的融資維持率\n要是股價大幅下殺 假設昨日以前的資餘全部出清 只剩今天資買的 那融資維持率就會是標準的166%對吧\nfor ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot() ax1.set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;close price\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成本(推估)\u0026#39;], label=\u0026#39;margin cost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資維持率(%)\u0026#39;], label=\u0026#39;margin maintence\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.legend() ax2.legend() 融資維持率 = 持有股票市值 / 融資金額 × 100%\n先處理不同時期融資成數 -\u0026gt; 其實我搞錯了 -\u0026gt; 我懂問題了 其實法規早在2015年前融資成數就是6成了 只是Cmoney 在計算融資維持率的時候用的是 \u0026lsquo;收盤價(未還原)\u0026rsquo; 但我們是用還原收盤\n才會出現成數是階梯狀 那其實是發放股利後 股價做調整的樣貌(這也是為什麼台積電近期成數階梯這麼密的原因 他們改成每季發放股利)\n所以拿維持率與還原股價去對 會對不上的原因\n融資維持率 = 收盤價 / (融資成本 * 融資成數) * 100%\n融資成數 = (收盤價 / 融資維持率/100) / 融資成本\nagg[\u0026#39;融資成數\u0026#39;] = agg[\u0026#39;收盤價\u0026#39;] / agg[\u0026#39;融資維持率(%)\u0026#39;] / agg[\u0026#39;融資成本(推估)\u0026#39;] / 100 for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot() ax1.set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;close price\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成本(推估)\u0026#39;], label=\u0026#39;margin cost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資成數\u0026#39;], label=\u0026#39;margin maintence\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.legend() ax2.legend() 現在確定 融資成數是相同的 那問題就回到原本的 如果融資成本與收盤價差越大 越可能出現極端的融資維持率 但這樣 融資成本不能和還原後的股價做直接比較\nagg[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((agg[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 winrate = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg[[\u0026#39;維持率反推融資平均損益\u0026#39;]+return_cols].corr() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[[\u0026#39;維持率反推融資平均損益\u0026#39;]+winrate].corr() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } agg[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;維持率反推融資平均損益\u0026#39;] + return_cols].sort_values(\u0026#39;維持率反推融資平均損益\u0026#39;, ascending=False).iloc[0:10] # agg[\u0026#39;signal\u0026#39;] = 0 mask = (agg[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) agg.loc[mask, \u0026#39;signal\u0026#39;] = 1 agg.to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/intermid/combine_signal.ftr\u0026#39;) agg[agg[\u0026#39;signal\u0026#39;]==1].sort_values(\u0026#39;融資維持率(%)\u0026#39;) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } splits = split_by_timeframe(agg, date_col=\u0026#39;日期\u0026#39;, n_splits=10) # Print the results split_res = pd.DataFrame(columns=[\u0026#39;benchmark_datapoints\u0026#39;, \u0026#39;benchmark_ret\u0026#39;, \u0026#39;benchmark_winrate\u0026#39;, \u0026#39;signal_datapoints\u0026#39;, \u0026#39;signal_ret\u0026#39;, \u0026#39;signal_winrate\u0026#39;]) for i, split in enumerate(splits): date_period = \u0026#34;{}~{}\u0026#34;.format(split[\u0026#39;日期\u0026#39;].min().strftime(\u0026#39;%Y%m%d\u0026#39;), split[\u0026#39;日期\u0026#39;].max().strftime(\u0026#39;%Y%m%d\u0026#39;)) split_res.loc[date_period, \u0026#39;benchmark_datapoints\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;benchmark_ret\u0026#39;] = split[\u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;benchmark_winrate\u0026#39;] = split[\u0026#39;hold_20Days_winrate\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_datapoints\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].count() split_res.loc[date_period, \u0026#39;signal_ret\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_ret\u0026#39;].mean() split_res.loc[date_period, \u0026#39;signal_winrate\u0026#39;] = split.loc[split[\u0026#39;signal\u0026#39;]==1, \u0026#39;hold_20Days_winrate\u0026#39;].mean() # print(f\u0026#34;Split {i+1}: {len(split)} rows, from {split[\u0026#39;日期\u0026#39;].min()} to {split[\u0026#39;日期\u0026#39;].max()}\u0026#34;) split_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 日個股事件表 週集保要處理增減資 SUB_TICKERS 籌碼 Done mask1 = (agg[\u0026#39;融資成本(推估)\u0026#39;]\u0026gt;agg[\u0026#39;收盤價\u0026#39;]) mask2 = (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026gt; 167) agg[mask2].sort_values(\u0026#39;維持率反推融資平均損益\u0026#39;, ascending=False) qcut_res.sort_values(\u0026#39;hold_20Days_ret\u0026#39;, ascending=False).iloc[0:10] agg.loc[agg[\u0026#39;signal\u0026#39;]==1, return_cols].mean() mask1 = (agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) mask2 = (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;4.644) \u0026amp; (agg[\u0026#39;週集保diff4week\u0026#39;]\u0026lt;2.986) agg.loc[mask1 \u0026amp; mask2, return_cols].mean() agg.reset_index(drop=True, inplace=True) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): print(ticker, \u0026#39;-\u0026#39;*50) print(agg.groupby(f\u0026#39;qcut_{ticker}\u0026#39;)[return_cols].mean()) benchmark_df = import pandas as pd # Example DataFrame (df1) df1 = pd.DataFrame({ \u0026#39;A\u0026#39;: [1, 2, 3], \u0026#39;B\u0026#39;: [4, 5, 6], \u0026#39;C\u0026#39;: [7, 8, 9] }) # Single-row DataFrame (df2) df2 = pd.DataFrame({\u0026#39;A\u0026#39;: [1], \u0026#39;B\u0026#39;: [2], \u0026#39;C\u0026#39;: [3]}) # Subtracting df2 from df1 result = df1 - df2.iloc[0] print(result) agg.groupby(\u0026#39;qcut\u0026#39;)[return_cols].mean() agg[\u0026#39;週集保signal\u0026#39;] = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保月線\u0026#39;]).apply(lambda x : 1 if x else 0) agg[\u0026#39;週集保signal\u0026#39;] = (agg[\u0026#39;佔集保庫存數比例(%)\u0026#39;]\u0026gt;agg[\u0026#39;週集保半年線\u0026#39;]).apply(lambda x : 1 if x else 0) return_cols = [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;] return_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] agg.groupby([\u0026#39;股票代號\u0026#39;])[return_cols].mean() agg.groupby([\u0026#39;股票代號\u0026#39;])[winrate_cols].mean() agg[agg[\u0026#39;週集保signal\u0026#39;]==1].groupby([\u0026#39;year\u0026#39;, \u0026#39;股票代號\u0026#39;])[return_cols].count().plot() margin_cols = [\u0026#39;資買\u0026#39;, \u0026#39;資賣\u0026#39;, \u0026#39;資現償\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;資增減\u0026#39;, \u0026#39;資限\u0026#39;, \u0026#39;券買\u0026#39;, \u0026#39;券賣\u0026#39;, \u0026#39;券賣金額(千)\u0026#39;, \u0026#39;券現償\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券增減\u0026#39;, \u0026#39;資券相抵\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;資使用率\u0026#39;, \u0026#39;券使用率\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;借券賣出\u0026#39;, \u0026#39;借券賣出金額(千)\u0026#39;, \u0026#39;借券賣出還券\u0026#39;, \u0026#39;借券賣出調整\u0026#39;, \u0026#39;借券賣出庫存異動\u0026#39;, \u0026#39;借券賣出餘額\u0026#39;, \u0026#39;借券可使用額度\u0026#39;, \u0026#39;借券系統當日借券\u0026#39;, \u0026#39;借券系統當日還券\u0026#39;, \u0026#39;借券系統借券餘額異動\u0026#39;, \u0026#39;借券系統借券餘額\u0026#39;, \u0026#39;借券系統借券餘額市值\u0026#39;, \u0026#39;證商營業處所當日借券\u0026#39;, \u0026#39;證商營業處所當日還券\u0026#39;, \u0026#39;證商營業處所借券餘額異動\u0026#39;, \u0026#39;證商營業處所借券餘額\u0026#39;, \u0026#39;證商營業處所借券餘額市值\u0026#39;, \u0026#39;借貸專戶當日借券\u0026#39;, \u0026#39;借貸專戶當日還券\u0026#39;, \u0026#39;借貸專戶借券餘額異動\u0026#39;, \u0026#39;借貸專戶借券餘額\u0026#39;, \u0026#39;借貸專戶借券餘額市值\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;, \u0026#39;整體維持率(%)\u0026#39;] agg[return_cols + margin_cols] agg[return_cols + margin_cols].corr().sort_values(\u0026#39;hold_20Days_ret\u0026#39;, ascending=False) import pandas as pd import numpy as np def calculate_rolling_correlation(df, col1, col2): \u0026#34;\u0026#34;\u0026#34; Calculate rolling correlation between two columns using a fixed window (weekly). Parameters: - df (pd.DataFrame): DataFrame containing the data - col1 (str): Name of the first column - col2 (str): Name of the second column - window (int): Rolling window size (e.g., 4 for four weeks) Returns: - pd.Series: Rolling correlation series \u0026#34;\u0026#34;\u0026#34; if col1 not in df.columns or col2 not in df.columns: raise ValueError(\u0026#34;Specified columns are not in the DataFrame.\u0026#34;) # Ensure data is aligned to avoid misalignment # df = df[[col1, col2]].dropna() # Use rolling window with custom function rolling_corr = df[col1].expanding(min_periods=52).corr(df[col2]) return rolling_corr sub = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] def expanding_corr(df): # 因為是未來的return 做corr 要小心data leakage # 故在signal的部分 要shift df[\u0026#39;margin_corr_5\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_5Days_ret\u0026#39;]).shift(1) df[\u0026#39;margin_short_corr_5\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_5Days_ret\u0026#39;]).shift(1) df[\u0026#39;margin_corr_20\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_20Days_ret\u0026#39;]).shift(4) df[\u0026#39;margin_short_corr_20\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=52).corr(df[\u0026#39;hold_20Days_ret\u0026#39;]).shift(4) return df agg = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(expanding_corr) agg.reset_index(drop=True, inplace=True) mask1 = (agg[\u0026#39;margin_corr_20\u0026#39;] \u0026lt; -0.15) \u0026amp; (agg[\u0026#39;margin_short_corr_20\u0026#39;] \u0026gt; -0.15) agg[\u0026#39;20_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;20_ticker_pool\u0026#39;] = 1 agg.columns agg[agg[\u0026#39;20_ticker_pool\u0026#39;]==1].groupby(\u0026#39;日期\u0026#39;)[\u0026#39;股票代號\u0026#39;].count().plot() sub[\u0026#39;test_Corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, 100) sub[\u0026#39;test_Corr\u0026#39;].plot() ssub = sub[[\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;test_Corr\u0026#39;]].iloc[-30:-4].iloc[-20::] ssub[[\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;]].corr() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): print(\u0026#39;\u0026#39;*5,ticker) print(agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker), [\u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;] ].corr()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(SUB_TICKERS): sub = agg[agg[\u0026#39;股票代號\u0026#39;]==ticker] sub[\u0026#39;margin_corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;) sub[\u0026#39;short_corr\u0026#39;] = calculate_rolling_correlation(sub, \u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;) fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker} vs 5d ret corr changed\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;margin_corr\u0026#39;], label=\u0026#39;margin corr\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;short_corr\u0026#39;], label=\u0026#39;margin short corr\u0026#39;) axes[i].legend() # ax2 = axes[i].twinx() # ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) # ax2.legend() for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20200101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} Maintenance short selling\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融券維持率(%)\u0026#39;], label=\u0026#39;Maintenance short selling\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;orange\u0026#39;) ax3 = ax1.twinx() ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券餘\u0026#39;], label=\u0026#39;short selling\u0026#39;, color=\u0026#39;black\u0026#39;) # ax3 = ax1.twinx() # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) 週集保固定禮拜五收盤後(禮拜六凌晨)會更新資料 故訊號為禮拜一開盤前初 操作應該是禮拜一收盤時買賣\nagg sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;)] sub[\u0026#39;bins\u0026#39;] = pd.qcut(sub[\u0026#39;融券維持率(%)\u0026#39;], 5) sub.groupby(\u0026#39;bins\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].describe() sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;)] sub[\u0026#39;short_bin\u0026#39;] = pd.qcut(sub[\u0026#39;融券維持率(%)\u0026#39;], 5) sub[\u0026#39;long_bin\u0026#39;] = pd.qcut(sub[\u0026#39;融資維持率(%)\u0026#39;], 5) sub.groupby([\u0026#39;short_bin\u0026#39;, \u0026#39;long_bin\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].describe() res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192.888) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161.379), \u0026#39;hold_20Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,\u0026#39;hold_20Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192.888) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161.379), \u0026#39;hold_20Days_winrate\u0026#39;].mean() res res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194.643) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159.762), \u0026#39;hold_20Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,\u0026#39;hold_20Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194.643) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159.762), \u0026#39;hold_20Days_winrate\u0026#39;].mean() res agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;192) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 161), \u0026#39;signal\u0026#39;] = 1 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;194) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; 159), \u0026#39;signal\u0026#39;] = 1 這種方式去切threshold 雖然可以得到很好的result 但總是有overfitting的感覺 我依據全部可得的資料切出來的 是不是可以更genral一些\n像是 融券維持率(%)在expanding window下的80分位數上, 融資維持率(%)在expanding window下的20分位數下\nsub = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] sub[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=16).quantile(q=0.8) sub.loc[sub[\u0026#39;日期\u0026#39;]\u0026gt;=\u0026#39;20230901\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;]] sub.loc[sub[\u0026#39;融券維持率(%)\u0026#39;].isna(), [\u0026#39;日期\u0026#39;,\u0026#39;融券維持率(%)\u0026#39;]] sub[\u0026#39;融券維持率(%)\u0026#39;].plot() sub[[\u0026#39;日期\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;]] def quantile_cut(df): df[\u0026#39;融券維持率(%)_h\u0026#39;] = df[\u0026#39;融券維持率(%)\u0026#39;].expanding(min_periods=16).quantile(0.8) df[\u0026#39;融資維持率(%)_l\u0026#39;] = df[\u0026#39;融資維持率(%)\u0026#39;].expanding(min_periods=16).quantile(0.2) return df agg.reset_index(drop=True, inplace=True) agg = agg.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_cut) agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 mask1 = (agg[\u0026#39;margin_corr_20\u0026#39;] \u0026lt; -0.15) \u0026amp; (agg[\u0026#39;margin_short_corr_20\u0026#39;] \u0026gt; -0.15) agg[\u0026#39;20_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;20_ticker_pool\u0026#39;] = 1 mask1 = (agg[\u0026#39;margin_corr_5\u0026#39;] \u0026lt; -0.1) \u0026amp; (agg[\u0026#39;margin_short_corr_5\u0026#39;] \u0026gt; -0.1) agg[\u0026#39;5_ticker_pool\u0026#39;] = 0 agg.loc[mask1, \u0026#39;5_ticker_pool\u0026#39;] = 1 agg[\u0026#39;signal\u0026#39;] = 0 agg.loc[(agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;5_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;5_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp d = 20 tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;, f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)) \u0026amp; (agg[\u0026#39;20_ticker_pool\u0026#39;]==1) \u0026amp; (agg[\u0026#39;signal\u0026#39;]==1), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp agg.reset_index(drop=True, inplace=True) agg.columns sub_cols = [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;佔集保庫存數比例(%)\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;總市值(億)\u0026#39;, \u0026#39;漲跌停\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;, \u0026#39;整體維持率(%)\u0026#39;, \u0026#39;margin_corr_5\u0026#39;, \u0026#39;margin_short_corr_5\u0026#39;, \u0026#39;margin_corr_20\u0026#39;, \u0026#39;margin_short_corr_20\u0026#39;, \u0026#39;20_ticker_pool\u0026#39;, \u0026#39;融券維持率(%)_h\u0026#39;, \u0026#39;融資維持率(%)_l\u0026#39;, \u0026#39;signal\u0026#39;, \u0026#39;5_ticker_pool\u0026#39;] agg[sub_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/intermid/9tickers_margin.ftr\u0026#39;) ticker = \u0026#39;5274\u0026#39; tmp = pd.DataFrame() for d in [5, 10, 20, 60, 120]: res = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), f\u0026#39;hold_{d}Days_ret\u0026#39;].describe().to_frame() res.loc[\u0026#39;precision\u0026#39;,f\u0026#39;hold_{d}Days_ret\u0026#39;] = agg.loc[(agg[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (agg[\u0026#39;融券維持率(%)\u0026#39;]\u0026gt;agg[\u0026#39;融券維持率(%)_h\u0026#39;]) \u0026amp; (agg[\u0026#39;融資維持率(%)\u0026#39;] \u0026lt; agg[\u0026#39;融資維持率(%)_l\u0026#39;]), f\u0026#39;hold_{d}Days_winrate\u0026#39;].mean() tmp = pd.concat([tmp, res], axis=1) tmp agg.columns[-60:-30] for ticker in [\u0026#39;3533\u0026#39;, \u0026#39;5274\u0026#39;]: sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} short \u0026gt; q0.8, long \u0026lt; q0.2\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券餘\u0026#39;], label=\u0026#39;Maintenance short selling quantity\u0026#39;, color=\u0026#39;black\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;資餘\u0026#39;], label=\u0026#39;Maintenance margin quantity\u0026#39;, color=\u0026#39;green\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;券資比\u0026#39;], label=\u0026#39;Maintenance margin quantity\u0026#39;, color=\u0026#39;blue\u0026#39;) # ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融券維持率(%)\u0026#39;], label=\u0026#39;Maintenance short selling\u0026#39;) # ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;融資維持率(%)\u0026#39;], label=\u0026#39;Maintenance margin\u0026#39;) indices = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) ] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} weekly depostie less 5\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;佔集保庫存數比例(%)\u0026#39;], label=\u0026#39;weekly depost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;black\u0026#39;) # ax3 = ax1.twinx() # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) for ticker in agg[\u0026#39;股票代號\u0026#39;].unique().tolist(): sub = agg[(agg[\u0026#39;股票代號\u0026#39;]==ticker) ] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;{} weekly depostie over 400\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1])) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;佔集保庫存數比例(%)\u0026#39;], label=\u0026#39;weekly depost\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;, color=\u0026#39;black\u0026#39;) ax3 = ax1.twinx() ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;外資持股比率(%)\u0026#39;], label=\u0026#39;FI\u0026#39;, color=\u0026#39;orange\u0026#39;) # ax3.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;投信持股比率(%)\u0026#39;], label=\u0026#39;IT\u0026#39;, color=\u0026#39;red\u0026#39;) # ax1.set_xticklabels(sub[\u0026#39;日期_dt\u0026#39;], rotation=45) ax1.legend(loc=2) ax2.legend(loc=1) ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""},{"content":"from IPython.display import HTML import pandas as pd def display_df_as_html(df): \u0026#34;\u0026#34;\u0026#34;Automatically display DataFrame as an HTML table.\u0026#34;\u0026#34;\u0026#34; display(HTML(df.to_html())) # Apply function to all DataFrame outputs pd.DataFrame._repr_html_ = display_df_as_html company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event.tail() 日期 股票代號 股票名稱 月營收公告 財報公告 除息日 除權日 法說會 減資前 減資後 ... \\ 9891130 20241225 9951 皇田 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891131 20241225 9955 佳龍 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891132 20241225 9958 世紀鋼 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891133 20241225 9960 邁達康 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 9891134 20241225 9962 有益 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; ... 申報轉讓 庫藏股 注意股票 新股上市 人事異動 停資 停券 最後回補日 今日事件數 RTIME 9891130 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 1 510725547 9891131 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891132 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891133 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 9891134 \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; \u0026lt;NA\u0026gt; 0 510725547 [5 rows x 21 columns] ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""},{"content":"import pandas as pd import numpy as np import matplotlib.pyplot as plt pd.options.display.float_format = \u0026#39;{:.4f}\u0026#39;.format SUB_TICKERS = [\u0026#39;2059\u0026#39;, \u0026#39;3529\u0026#39;, \u0026#39;2383\u0026#39;, \u0026#39;2330\u0026#39;, \u0026#39;8069\u0026#39;, \u0026#39;5274\u0026#39;, \u0026#39;3008\u0026#39;, \u0026#39;2454\u0026#39;, \u0026#39;3533\u0026#39;] 月營收 mon_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/monthly/monthly_revenue.ftr\u0026#39;) mon_df = mon_df[mon_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] mon_df = mon_df[~mon_df[\u0026#39;公告日\u0026#39;].isna()] mon_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(mon_df[\u0026#39;公告日\u0026#39;]) mon_df.sort_values(\u0026#39;公告日_dt\u0026#39;, inplace=True, ascending=True) mon_df.reset_index(drop=True, inplace=True) 收盤價 price_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/org_price.ftr\u0026#39;) price0050 = price_df[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;0050\u0026#39;] price0050[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price0050[\u0026#39;日期\u0026#39;]) price0050.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price0050.reset_index(drop=True, inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:1: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050['日期_dt'] = pd.to_datetime(price0050['日期']) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1320320034.py:2: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy price0050.sort_values('日期_dt', inplace=True, ascending=True) price_df = price_df[price_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;]) price_df.sort_values(\u0026#39;日期_dt\u0026#39;, inplace=True, ascending=True) price_df.reset_index(drop=True, inplace=True) def holding_nDays(df): for n in [5, 10, 20, 60, 120]: df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = (df[\u0026#39;收盤價\u0026#39;].shift(-n) / df[\u0026#39;收盤價\u0026#39;]) - 1 df[f\u0026#39;hold_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(-1) # 實際上隔日才能操作 df[f\u0026#39;last_{n}Days_ret\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].shift(n + 2) # 實際上隔日才能操作 df[f\u0026#39;hold_{n}Days_winrate\u0026#39;] = df[f\u0026#39;hold_{n}Days_ret\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/392270890.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price0050 = price0050.groupby(\u0026#39;股票代號\u0026#39;).apply(holding_nDays).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2395123834.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price0050 = price0050.groupby('股票代號').apply(holding_nDays).reset_index(drop=True) price_df = price_df.merge(price0050, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_0050\u0026#39;)) 融資 margin_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/dayMarginTrading.ftr\u0026#39;, columns=[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;資餘\u0026#39;, \u0026#39;券餘\u0026#39;, \u0026#39;券資比\u0026#39;, \u0026#39;當沖比率\u0026#39;, \u0026#39;融資成本(推估)\u0026#39;, \u0026#39;融券成本(推估)\u0026#39;, \u0026#39;融資維持率(%)\u0026#39;, \u0026#39;融券維持率(%)\u0026#39;,\u0026#39;整體維持率(%)\u0026#39;]) price_df = price_df.merge(margin_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;維持率反推融資平均損益\u0026#39;] = ((price_df[\u0026#39;融資維持率(%)\u0026#39;] * 0.6) - 100) /100 週集保 weekly_depostie = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/weeklyDepository.ftr\u0026#39;) weekly_depostie = weekly_depostie[weekly_depostie[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] weekly_depostie.sort_values(\u0026#39;日期\u0026#39;, inplace=True) weekly_depostie.reset_index(drop=True, inplace=True) agg = weekly_depostie[weekly_depostie[\u0026#39;持股分級\u0026#39;].isin([\u0026#39;0400001-0600000\u0026#39;, \u0026#39;0600001-0800000\u0026#39;, \u0026#39;0800001-1000000\u0026#39;, \u0026#39;1000001以上\u0026#39;])].groupby([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].sum().to_frame() agg.reset_index(drop=False, inplace=True) company_event = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/daily/company_event.ftr\u0026#39;) company_event = company_event[company_event[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] date_pattern = r\u0026#39;^\\d{8}$\u0026#39; company_event = company_event[company_event[\u0026#39;日期\u0026#39;].str.contains(date_pattern)] company_event[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(company_event[\u0026#39;日期\u0026#39;]) company_event[\u0026#39;friday_of_week\u0026#39;] = company_event[\u0026#39;日期_dt\u0026#39;] + pd.offsets.Week(weekday=4) company_event[\u0026#39;adjust_week\u0026#39;] = 0 company_event.loc[(company_event[\u0026#39;新股上市\u0026#39;]==0) | (company_event[\u0026#39;減資前\u0026#39;]==0), \u0026#39;adjust_week\u0026#39;] = 1 agg[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(agg[\u0026#39;日期\u0026#39;]) agg[\u0026#39;year\u0026#39;] = agg[\u0026#39;日期_dt\u0026#39;].dt.year agg[\u0026#39;週集保月線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(4).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保半年線\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].rolling(24).mean().reset_index(level=0, drop=True) agg[\u0026#39;週集保diff\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;佔集保庫存數比例(%)\u0026#39;].diff().reset_index(level=0, drop=True) agg = agg.merge(company_event.loc[company_event[\u0026#39;adjust_week\u0026#39;]==1, [\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;減資前\u0026#39;, \u0026#39;新股上市\u0026#39;, \u0026#39;adjust_week\u0026#39;]], how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;friday_of_week\u0026#39;, \u0026#39;股票代號\u0026#39;])) # 有股數異動 當周週集保diff -\u0026gt; 0 agg.loc[agg[\u0026#39;adjust_week\u0026#39;]==1, \u0026#39;週集保diff\u0026#39;] = 0 agg[\u0026#39;週集保diff4week\u0026#39;] = agg.groupby([\u0026#39;股票代號\u0026#39;])[\u0026#39;週集保diff\u0026#39;].rolling(4).sum().reset_index(level=0, drop=True) price_df = price_df.merge(agg, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;])) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/3876432843.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res = res.merge(price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False), how=\u0026#39;left\u0026#39;, left_on=(\u0026#39;股票代號\u0026#39;), right_on=(\u0026#39;股票代號\u0026#39;), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_baseline\u0026#39;)) res[\u0026#39;diff_ret\u0026#39;] = res[\u0026#39;hold_20Days_ret\u0026#39;] - res[\u0026#39;hold_20Days_ret_baseline\u0026#39;] for ticker in SUB_TICKERS: print(res.loc[res[\u0026#39;股票代號\u0026#39;]==ticker, [\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;diff_ret\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;signal_count\u0026#39;]]) cut 股票代號 diff_ret hold_20Days_winrate signal_count 0 (-7.381, -0.0403] 2059 0.0074 0.5253 297 9 (-0.0403, -0.0209] 2059 -0.0003 0.5539 612 18 (-0.0209, -0.0112] 2059 -0.0105 0.5278 612 27 (-0.0112, -0.00457] 2059 0.0055 0.6105 493 36 (-0.00457, 0.000588] 2059 -0.0055 0.5302 464 45 (0.000588, 0.0064] 2059 -0.0165 0.5211 474 54 (0.0064, 0.0132] 2059 -0.0066 0.5511 470 63 (0.0132, 0.0236] 2059 0.0048 0.5630 579 72 (0.0236, 0.0459] 2059 0.0154 0.4592 368 81 (0.0459, 6.477] 2059 -0.0042 0.4848 330 cut 股票代號 diff_ret hold_20Days_winrate signal_count 5 (-7.381, -0.0403] 3529 0.0076 0.5681 639 14 (-0.0403, -0.0209] 3529 0.0057 0.5977 430 23 (-0.0209, -0.0112] 3529 0.0197 0.6016 251 32 (-0.0112, -0.00457] 3529 -0.0115 0.4541 185 41 (-0.00457, 0.000588] 3529 -0.0182 0.4237 118 50 (0.000588, 0.0064] 3529 0.0286 0.5524 105 59 (0.0064, 0.0132] 3529 0.0080 0.5088 114 68 (0.0132, 0.0236] 3529 0.0233 0.6364 132 77 (0.0236, 0.0459] 3529 -0.0101 0.5516 368 86 (0.0459, 6.477] 3529 -0.0001 0.5152 924 cut 股票代號 diff_ret hold_20Days_winrate signal_count 2 (-7.381, -0.0403] 2383 -0.0163 0.5163 337 11 (-0.0403, -0.0209] 2383 -0.0155 0.6022 450 20 (-0.0209, -0.0112] 2383 0.0208 0.5992 509 29 (-0.0112, -0.00457] 2383 0.0109 0.6031 456 38 (-0.00457, 0.000588] 2383 -0.0056 0.5408 845 47 (0.000588, 0.0064] 2383 0.0085 0.5935 866 56 (0.0064, 0.0132] 2383 0.0112 0.5605 860 65 (0.0132, 0.0236] 2383 -0.0099 0.4559 601 74 (0.0236, 0.0459] 2383 0.0042 0.4363 314 83 (0.0459, 6.477] 2383 0.0311 0.5296 287 cut 股票代號 diff_ret hold_20Days_winrate signal_count 1 (-7.381, -0.0403] 2330 -0.0388 0.4315 788 10 (-0.0403, -0.0209] 2330 0.0045 0.5472 424 19 (-0.0209, -0.0112] 2330 -0.0026 0.5797 364 28 (-0.0112, -0.00457] 2330 0.0076 0.6842 741 37 (-0.00457, 0.000588] 2330 -0.0034 0.6103 839 46 (0.000588, 0.0064] 2330 -0.0058 0.5833 768 55 (0.0064, 0.0132] 2330 -0.0045 0.6129 824 64 (0.0132, 0.0236] 2330 0.0027 0.6062 617 73 (0.0236, 0.0459] 2330 0.0221 0.6621 441 82 (0.0459, 6.477] 2330 -0.0033 0.5289 484 cut 股票代號 diff_ret hold_20Days_winrate signal_count 8 (-7.381, -0.0403] 8069 -0.0083 0.4898 786 17 (-0.0403, -0.0209] 8069 0.0377 0.6390 313 26 (-0.0209, -0.0112] 8069 0.0130 0.5763 321 35 (-0.0112, -0.00457] 8069 -0.0059 0.5538 316 44 (-0.00457, 0.000588] 8069 0.0035 0.5430 256 53 (0.000588, 0.0064] 8069 -0.0044 0.5430 291 62 (0.0064, 0.0132] 8069 0.0173 0.6335 352 71 (0.0132, 0.0236] 8069 0.0035 0.5276 381 80 (0.0236, 0.0459] 8069 -0.0176 0.4596 594 89 (0.0459, 6.477] 8069 -0.0020 0.5591 744 cut 股票代號 diff_ret hold_20Days_winrate signal_count 7 (-7.381, -0.0403] 5274 0.0202 0.6256 438 16 (-0.0403, -0.0209] 5274 -0.0428 0.5028 179 25 (-0.0209, -0.0112] 5274 -0.0071 0.6331 169 34 (-0.0112, -0.00457] 5274 0.0072 0.6823 192 43 (-0.00457, 0.000588] 5274 0.0079 0.6508 126 52 (0.000588, 0.0064] 5274 0.0453 0.7287 129 61 (0.0064, 0.0132] 5274 0.0348 0.7063 160 70 (0.0132, 0.0236] 5274 0.0197 0.6702 188 79 (0.0236, 0.0459] 5274 0.0036 0.6394 416 88 (0.0459, 6.477] 5274 -0.0205 0.5478 712 cut 股票代號 diff_ret hold_20Days_winrate signal_count 4 (-7.381, -0.0403] 3008 0.0105 0.4967 449 13 (-0.0403, -0.0209] 3008 0.0191 0.6574 788 22 (-0.0209, -0.0112] 3008 0.0128 0.6181 720 31 (-0.0112, -0.00457] 3008 0.0030 0.5690 652 40 (-0.00457, 0.000588] 3008 -0.0275 0.4177 565 49 (0.000588, 0.0064] 3008 -0.0320 0.3731 453 58 (0.0064, 0.0132] 3008 -0.0063 0.4907 377 67 (0.0132, 0.0236] 3008 0.0032 0.5278 485 76 (0.0236, 0.0459] 3008 -0.0048 0.5455 627 85 (0.0459, 6.477] 3008 0.0236 0.5260 365 cut 股票代號 diff_ret hold_20Days_winrate signal_count 3 (-7.381, -0.0403] 2454 -0.0014 0.5589 433 12 (-0.0403, -0.0209] 2454 -0.0161 0.4977 663 21 (-0.0209, -0.0112] 2454 0.0020 0.6016 728 30 (-0.0112, -0.00457] 2454 -0.0285 0.4292 643 39 (-0.00457, 0.000588] 2454 0.0040 0.5687 466 48 (0.000588, 0.0064] 2454 0.0165 0.6183 503 57 (0.0064, 0.0132] 2454 -0.0053 0.5879 512 66 (0.0132, 0.0236] 2454 0.0106 0.6314 681 75 (0.0236, 0.0459] 2454 -0.0067 0.5551 726 84 (0.0459, 6.477] 2454 -0.0048 0.5616 276 cut 股票代號 diff_ret hold_20Days_winrate signal_count 6 (-7.381, -0.0403] 3533 -0.0589 0.2222 36 15 (-0.0403, -0.0209] 3533 0.0147 0.6366 344 24 (-0.0209, -0.0112] 3533 0.0306 0.6929 521 33 (-0.0112, -0.00457] 3533 -0.0040 0.5455 528 42 (-0.00457, 0.000588] 3533 -0.0483 0.3852 527 51 (0.000588, 0.0064] 3533 -0.0313 0.4356 606 60 (0.0064, 0.0132] 3533 0.0060 0.5898 529 69 (0.0132, 0.0236] 3533 0.0259 0.6311 534 78 (0.0236, 0.0459] 3533 0.0143 0.4725 345 87 (0.0459, 6.477] 3533 0.1118 0.8333 78 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window): date_numeric = window[:, 0] # Extract the first column (date_numeric) value = window[:, 1] # Extract the second column (value) x_diff = date_numeric[-1] - date_numeric[0] # Time difference y_diff = value[-1] - value[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size][[\u0026#39;date_numeric\u0026#39;, \u0026#39;value\u0026#39;]].to_numpy() slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 import pandas as pd # Sample data data = { \u0026#39;date\u0026#39;: pd.date_range(start=\u0026#39;2025-01-01\u0026#39;, periods=20, freq=\u0026#39;D\u0026#39;), # 20 consecutive dates \u0026#39;value\u0026#39;: [i ** 2 for i in range(20)] # Example values (can be any time series data) } # Convert to a DataFrame df = pd.DataFrame(data) # Convert date to numeric (e.g., number of days since the first date) df[\u0026#39;date_numeric\u0026#39;] = (df[\u0026#39;date\u0026#39;] - df[\u0026#39;date\u0026#39;].min()).dt.days # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] # Time difference y_diff = window_df[\u0026#39;value\u0026#39;].iloc[-1] - window_df[\u0026#39;value\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) return [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment # Add slope to the DataFrame df[\u0026#39;slope\u0026#39;] = rolling_slope(df, window_size=5) # Output the result print(df) date value date_numeric slope 0 2025-01-01 0 0 NaN 1 2025-01-02 1 1 NaN 2 2025-01-03 4 2 NaN 3 2025-01-04 9 3 NaN 4 2025-01-05 16 4 4.0000 5 2025-01-06 25 5 6.0000 6 2025-01-07 36 6 8.0000 7 2025-01-08 49 7 10.0000 8 2025-01-09 64 8 12.0000 9 2025-01-10 81 9 14.0000 10 2025-01-11 100 10 16.0000 11 2025-01-12 121 11 18.0000 12 2025-01-13 144 12 20.0000 13 2025-01-14 169 13 22.0000 14 2025-01-15 196 14 24.0000 15 2025-01-16 225 15 26.0000 16 2025-01-17 256 16 28.0000 17 2025-01-18 289 17 30.0000 18 2025-01-19 324 18 32.0000 19 2025-01-20 361 19 34.0000 price_df[\u0026#39;date_numeric\u0026#39;] = (price_df[\u0026#39;日期_dt\u0026#39;] - price_df[\u0026#39;日期_dt\u0026#39;].min()).dt.days price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'date_numeric'], dtype='object') # 120日本益比的切線斜率 # Function to calculate slope for a window def calculate_slope(window_df): x_diff = window_df[\u0026#39;date_numeric\u0026#39;].iloc[-1] - window_df[\u0026#39;date_numeric\u0026#39;].iloc[0] - 1 # Time difference y_diff = (window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[-1] - window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] )/ window_df[\u0026#39;本益比(近四季)\u0026#39;].iloc[0] # Value difference return y_diff / x_diff if x_diff != 0 else None # Apply rolling window calculation def rolling_slope(df, window_size): slopes = [] for i in range(len(df) - window_size + 1): window = df.iloc[i:i + window_size] # Get the rolling window as a DataFrame slopes.append(calculate_slope(window)) df[f\u0026#39;slope_{window_size}\u0026#39;] = [None] * (window_size - 1) + slopes # Fill the start with NaNs for alignment df[f\u0026#39;slope_{window_size}\u0026#39;] = df[f\u0026#39;slope_{window_size}\u0026#39;].shift(1) # 本益比用今天的收盤價去計算 明天才知道result return df # Add slope to the DataFrame # price_df[\u0026#39;slope\u0026#39;] = rolling_slope(price_df, window_size=5) for w in [5, 10, 20, 60, 120]: price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2524162785.py:20: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : rolling_slope(df, window_size=w)).reset_index(drop=True) price_df.loc[price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;, [\u0026#39;日期\u0026#39;,\u0026#39;本益比(近四季)\u0026#39;, \u0026#39;slope_5\u0026#39;, \u0026#39;date_numeric\u0026#39;]].iloc[-20::] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } ((25.6-29.5)/29.5)/5 -0.026440677966101684 for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).mean().reset_index(drop=True) price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[f\u0026#39;slope_{w}\u0026#39;].rolling(j).sum().reset_index(drop=True) ret_cols = [f\u0026#39;hold_{i}Days_ret\u0026#39; for i in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{i}Days_winrate\u0026#39; for i in [5, 10, 20, 60, 120]] for w in [5, 10, 20, 60, 120]: for j in [5, 10, 20, 60, 120]: print(price_df.loc[price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]\u0026gt;0, ret_cols].mean()) # price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : rolling_slope(df, window_size=5)) w = 60 j = 60 for ticker in SUB_TICKERS: tmp = price_df[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;] = tmp[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean() ax1.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;本益比(近四季)_rolling5\u0026#39;], label=\u0026#39;PE\u0026#39;) ax2 = ax1.twinx() ax2.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;],color=\u0026#39;green\u0026#39;, label=\u0026#39;PE slope\u0026#39;) ax3 = ax1.twinx() ax3.plot(tmp[\u0026#39;日期_dt\u0026#39;], tmp[\u0026#39;收盤價\u0026#39;],color=\u0026#39;orange\u0026#39;, label=\u0026#39;price\u0026#39;) ax1.set_title(ticker) indices = tmp.loc[(tmp[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt;= 0.02), \u0026#39;日期_dt\u0026#39;].values # Plot vertical lines for x in indices: plt.axvline(x=x, color=\u0026#39;r\u0026#39;, linestyle=\u0026#39;--\u0026#39;, linewidth=1, alpha=0.4) ax1.legend() ax2.legend() def vector_backtest(df): # input: df, 需要有signa columns, output : [[trade_data1], [trade_data2], ...] (list中包含多個list) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4] # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; com_code = group[\u0026#39;股票代號\u0026#39;].iloc[-1] start_date = group[\u0026#39;日期\u0026#39;].iloc[0] end_date = group[\u0026#39;日期\u0026#39;].iloc[-1] buy_price = group[\u0026#39;次日收盤價\u0026#39;].iloc[0] sell_price = group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1] ret = (sell_price/buy_price) - 1 holding_days = len(group) event_list = [com_code, start_date, end_date, buy_price, sell_price, ret, holding_days] event_list_all.append(event_list) return event_list_all print(f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;) slope_60_rolling_60_SUM price_df[\u0026#39;本益比_rolling5\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(5).mean().reset_index(drop=True) price_df[\u0026#39;本益比_rolling20\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;本益比(近四季)\u0026#39;].rolling(20).mean().reset_index(drop=True) 看起來本益比切線斜率 累積增加\u0026gt;0 對捕捉上升趨勢還不錯 price_df.reset_index(drop=True, inplace=True) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) # | (price_df[f\u0026#39;slope_{w}\u0026#39;] \u0026lt; price_df[f\u0026#39;slope_{w}_rolling_{j}\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) \u0026amp; (price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt;= 0) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/312944587.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), ret_cols].mean() hold_5Days_ret 0.0080 hold_10Days_ret 0.0148 hold_20Days_ret 0.0310 hold_60Days_ret 0.0807 hold_120Days_ret 0.1454 dtype: float64 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;] \u0026gt; price_df[\u0026#39;last_60Days_ret_0050\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3156983121.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) w, j = 60, 60 price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;本益比_rolling5\u0026#39;]\u0026gt;=price_df[\u0026#39;本益比_rolling20\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) | (price_df[\u0026#39;last_60Days_ret_0050\u0026#39;] \u0026lt;= -0.1) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/95528996.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df.columns[-140:-120] Index(['收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME'], dtype='object') price_df[\u0026#39;20MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(20).mean().reset_index(drop=True) price_df[\u0026#39;60MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(60).mean().reset_index(drop=True) price_df[\u0026#39;200MA\u0026#39;] = price_df.groupby(\u0026#39;股票代號\u0026#39;)[\u0026#39;收盤價\u0026#39;].rolling(200).mean().reset_index(drop=True) Local Minima, maxima from scipy.signal import argrelextrema def groupby_extrema(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # Step 2: Compare successive maxima max_comparisons_larger_idx = [] max_comparisons_smaller_idx = [] if len(local_maxima) \u0026gt; 1: for i in range(len(local_maxima) - 1): current_max = local_maxima.iloc[i] next_max = local_maxima.iloc[i + 1] if next_max \u0026gt; current_max: max_comparisons_larger_idx.append(local_maxima.index[i+1]) else: max_comparisons_smaller_idx.append(local_maxima.index[i+1]) df[\u0026#39;max_comparisons_larger\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 1 df.loc[max_comparisons_smaller_idx, \u0026#39;max_comparisons_larger\u0026#39;] = 0 df[\u0026#39;max_comparisons_larger\u0026#39;].ffill(inplace=True) df[\u0026#39;max_comparisons_larger\u0026#39;] = df[\u0026#39;max_comparisons_larger\u0026#39;].shift(window) df[\u0026#39;local_maxima\u0026#39;] = None df.loc[max_comparisons_larger_idx, \u0026#39;local_maxima\u0026#39;] = local_maxima.loc[max_comparisons_larger_idx].values.tolist() df[\u0026#39;local_maxima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_maxima\u0026#39;] = df[\u0026#39;local_maxima\u0026#39;].shift(window) return df ## 反向 股價跌破 local minima 又這個local minima \u0026lt; 上一個 在谷底的感覺 def groupby_extrema_sup(df, col): df.reset_index(drop=True, inplace=True) # 1. Identify Local Minima and Maxima window = 10 # Window size for extrema detection local_max_indices = argrelextrema(df[col].values, np.greater, order=window)[0] local_min_indices = argrelextrema(df[col].values, np.less, order=window)[0] # Extract local maxima and minima, ensuring proper alignment (avoid leakage) local_maxima = pd.Series(df.loc[local_max_indices, col].values, index=local_max_indices) local_minima = pd.Series(df.loc[local_min_indices, col].values, index=local_min_indices) # print(local_minima) # Step 2: Compare successive maxima min_comparisons_larger_idx = [] min_comparisons_smaller_idx = [] if len(local_minima) \u0026gt; 1: for i in range(len(local_minima) - 1): current_min = local_minima.iloc[i] next_min = local_minima.iloc[i + 1] if next_min \u0026lt; current_min: min_comparisons_smaller_idx.append(local_minima.index[i+1]) else: min_comparisons_larger_idx.append(local_minima.index[i+1]) print(min_comparisons_smaller_idx) df[\u0026#39;min_comparisons_smaller\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 1 df.loc[min_comparisons_larger_idx, \u0026#39;min_comparisons_smaller\u0026#39;] = 0 df[\u0026#39;min_comparisons_smaller\u0026#39;].ffill(inplace=True) df[\u0026#39;min_comparisons_smaller\u0026#39;] = df[\u0026#39;min_comparisons_smaller\u0026#39;].shift(window) df[\u0026#39;local_minima\u0026#39;] = None df.loc[min_comparisons_smaller_idx, \u0026#39;local_minima\u0026#39;] = local_minima.loc[min_comparisons_smaller_idx].values.tolist() df[\u0026#39;local_minima\u0026#39;].ffill(inplace=True) df[\u0026#39;local_minima\u0026#39;] = df[\u0026#39;local_minima\u0026#39;].shift(window) return df w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;)) [np.int64(647), np.int64(727), np.int64(916), np.int64(1198), np.int64(1314), np.int64(1388), np.int64(1801), np.int64(2151), np.int64(2358), np.int64(2549), np.int64(2999), np.int64(3101), np.int64(3290), np.int64(4081), np.int64(4249), np.int64(4392), np.int64(4752)] [np.int64(388), np.int64(960), np.int64(1098), np.int64(1504), np.int64(1633), np.int64(1760), np.int64(2227), np.int64(2331), np.int64(2519), np.int64(2642), np.int64(2956), np.int64(3136), np.int64(3325), np.int64(3444), np.int64(3646), np.int64(3675), np.int64(3740), np.int64(4131), np.int64(4369), np.int64(4417), np.int64(4677), np.int64(4757), np.int64(4858), np.int64(4902), np.int64(5019), np.int64(5178), np.int64(5262), np.int64(5381), np.int64(5749), np.int64(6100), np.int64(6562), np.int64(6835), np.int64(6941), np.int64(7077), np.int64(7161)] [np.int64(799), np.int64(1099), np.int64(2475), np.int64(2879), np.int64(2999), np.int64(3090), np.int64(3347), np.int64(3469), np.int64(3750), np.int64(4090), np.int64(4196), np.int64(4293), np.int64(4472), np.int64(4599), np.int64(4716), np.int64(4844), np.int64(5076), np.int64(5188), np.int64(5317), np.int64(5535), np.int64(5556), np.int64(5818), np.int64(5899), np.int64(6264), np.int64(6430), np.int64(6451), np.int64(6795), np.int64(6893)] [np.int64(380), np.int64(624), np.int64(749), np.int64(1254), np.int64(1441), np.int64(1629), np.int64(1859), np.int64(2107), np.int64(2236), np.int64(2638), np.int64(2710), np.int64(2894), np.int64(2993), np.int64(3240), np.int64(3541), np.int64(3848), np.int64(4122), np.int64(4240), np.int64(4639), np.int64(4952), np.int64(5171), np.int64(5380), np.int64(5662), np.int64(5684), np.int64(5735)] [np.int64(345), np.int64(628), np.int64(1091), np.int64(1513), np.int64(1715), np.int64(1910), np.int64(1946), np.int64(2023), np.int64(2086), np.int64(2190), np.int64(2438), np.int64(2813), np.int64(3199), np.int64(3389), np.int64(3426), np.int64(3459), np.int64(3681), np.int64(3819), np.int64(3965), np.int64(4515), np.int64(4766), np.int64(4890), np.int64(5135), np.int64(5230), np.int64(5349), np.int64(5502)] [np.int64(374), np.int64(465), np.int64(598), np.int64(624), np.int64(1017), np.int64(1173), np.int64(1588), np.int64(1710), np.int64(1939), np.int64(2157), np.int64(2286), np.int64(2761), np.int64(2816), np.int64(3084), np.int64(3111), np.int64(3293)] [np.int64(653), np.int64(953), np.int64(1046), np.int64(1150), np.int64(1469), np.int64(1596), np.int64(1628), np.int64(1706), np.int64(1826), np.int64(1922), np.int64(2362), np.int64(2518), np.int64(2731), np.int64(3190), np.int64(3637), np.int64(3741), np.int64(3757), np.int64(3873), np.int64(4145)] [np.int64(318), np.int64(534), np.int64(796), np.int64(1031), np.int64(1068), np.int64(1110), np.int64(1153), np.int64(1328), np.int64(1394), np.int64(1716), np.int64(1835), np.int64(2269)] [np.int64(765), np.int64(952), np.int64(1659), np.int64(1962), np.int64(2577), np.int64(3066), np.int64(3310), np.int64(3626), np.int64(3773), np.int64(3796), np.int64(3961), np.int64(4354), np.int64(4559), np.int64(4661), np.int64(4841)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3911248321.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, f'slope_{w}_rolling_{j}_SUM')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema(df, \u0026#39;收盤價\u0026#39;)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/326216370.py:34: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2624941152.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, '收盤價')) w, j = 60, 60 price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : groupby_extrema_sup(df, \u0026#39;收盤價\u0026#39;)) [np.int64(204), np.int64(287), np.int64(387), np.int64(690), np.int64(886), np.int64(1026), np.int64(1259), np.int64(1299), np.int64(1369), np.int64(1471), np.int64(1508), np.int64(1530), np.int64(1583), np.int64(1742), np.int64(2029), np.int64(2081), np.int64(2308), np.int64(2343), np.int64(2501), np.int64(2543), np.int64(2626), np.int64(2713), np.int64(2737), np.int64(2794), np.int64(3012), np.int64(3029), np.int64(3053), np.int64(3107), np.int64(3157), np.int64(3169), np.int64(3267), np.int64(3314), np.int64(3345), np.int64(3420), np.int64(3452), np.int64(3475), np.int64(3494), np.int64(3681), np.int64(3819), np.int64(4028), np.int64(4159), np.int64(4193), np.int64(4316), np.int64(4338), np.int64(4367), np.int64(4410), np.int64(4563), np.int64(4706), np.int64(4746), np.int64(4790)] [np.int64(40), np.int64(133), np.int64(185), np.int64(258), np.int64(317), np.int64(343), np.int64(386), np.int64(431), np.int64(615), np.int64(904), np.int64(943), np.int64(1029), np.int64(1069), np.int64(1159), np.int64(1224), np.int64(1537), np.int64(1562), np.int64(1646), np.int64(1704), np.int64(1757), np.int64(1797), np.int64(1823), np.int64(1875), np.int64(1896), np.int64(1942), np.int64(2037), np.int64(2083), np.int64(2110), np.int64(2125), np.int64(2149), np.int64(2193), np.int64(2253), np.int64(2277), np.int64(2491), np.int64(2553), np.int64(2592), np.int64(2616), np.int64(2641), np.int64(2704), np.int64(2912), np.int64(2930), np.int64(2948), np.int64(3039), np.int64(3102), np.int64(3284), np.int64(3333), np.int64(3400), np.int64(3470), np.int64(3508), np.int64(3668), np.int64(3695), np.int64(3713), np.int64(3951), np.int64(4018), np.int64(4088), np.int64(4291), np.int64(4359), np.int64(4375), np.int64(4390), np.int64(4593), np.int64(4802), np.int64(4895), np.int64(4960), np.int64(5006), np.int64(5243), np.int64(5336), np.int64(5389), np.int64(5488), np.int64(5564), np.int64(5962), np.int64(6047), np.int64(6086), np.int64(6169), np.int64(6187), np.int64(6219), np.int64(6310), np.int64(6506), np.int64(6636), np.int64(6754), np.int64(6786), np.int64(6856), np.int64(6991), np.int64(7030), np.int64(7068), np.int64(7145), np.int64(7262), np.int64(7367), np.int64(7573)] [np.int64(96), np.int64(147), np.int64(203), np.int64(240), np.int64(401), np.int64(468), np.int64(587), np.int64(715), np.int64(789), np.int64(1042), np.int64(1190), np.int64(1235), np.int64(1283), np.int64(1432), np.int64(1463), np.int64(1489), np.int64(1530), np.int64(1632), np.int64(1646), np.int64(1669), np.int64(1894), np.int64(1986), np.int64(2041), np.int64(2101), np.int64(2167), np.int64(2263), np.int64(2449), np.int64(2622), np.int64(2822), np.int64(2847), np.int64(2976), np.int64(3006), np.int64(3078), np.int64(3287), np.int64(3307), np.int64(3349), np.int64(3437), np.int64(3543), np.int64(3629), np.int64(3673), np.int64(3693), np.int64(3710), np.int64(3737), np.int64(3820), np.int64(3890), np.int64(4051), np.int64(4140), np.int64(4164), np.int64(4193), np.int64(4274), np.int64(4496), np.int64(4577), np.int64(4681), np.int64(4806), np.int64(4827), np.int64(5003), np.int64(5026), np.int64(5273), np.int64(5294), np.int64(5333), np.int64(5387), np.int64(5430), np.int64(5477), np.int64(5508), np.int64(5742), np.int64(5760), np.int64(5812), np.int64(5844), np.int64(5999), np.int64(6123), np.int64(6411), np.int64(6484), np.int64(6574), np.int64(6600), np.int64(6702), np.int64(6727), np.int64(6777), np.int64(6840), np.int64(6911)] [np.int64(215), np.int64(229), np.int64(247), np.int64(390), np.int64(584), np.int64(692), np.int64(789), np.int64(833), np.int64(875), np.int64(1018), np.int64(1058), np.int64(1121), np.int64(1136), np.int64(1196), np.int64(1216), np.int64(1234), np.int64(1317), np.int64(1588), np.int64(1622), np.int64(1729), np.int64(1818), np.int64(1829), np.int64(2054), np.int64(2120), np.int64(2193), np.int64(2220), np.int64(2295), np.int64(2394), np.int64(2421), np.int64(2459), np.int64(2476), np.int64(2493), np.int64(2673), np.int64(2817), np.int64(2850), np.int64(2959), np.int64(3232), np.int64(3282), np.int64(3419), np.int64(3494), np.int64(3594), np.int64(3608), np.int64(3664), np.int64(3754), np.int64(3793), np.int64(3845), np.int64(4071), np.int64(4196), np.int64(4214), np.int64(4229), np.int64(4275), np.int64(4324), np.int64(4611), np.int64(4961), np.int64(4997), np.int64(5096), np.int64(5125), np.int64(5173), np.int64(5233), np.int64(5367), np.int64(5429), np.int64(5549), np.int64(5607)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) [np.int64(86), np.int64(106), np.int64(213), np.int64(429), np.int64(450), np.int64(573), np.int64(592), np.int64(639), np.int64(718), np.int64(1006), np.int64(1066), np.int64(1146), np.int64(1188), np.int64(1217), np.int64(1241), np.int64(1277), np.int64(1472), np.int64(1580), np.int64(1650), np.int64(1679), np.int64(1775), np.int64(1854), np.int64(1965), np.int64(2041), np.int64(2244), np.int64(2354), np.int64(2387), np.int64(2428), np.int64(2507), np.int64(2524), np.int64(2648), np.int64(2708), np.int64(2769), np.int64(2828), np.int64(2868), np.int64(3122), np.int64(3142), np.int64(3332), np.int64(3355), np.int64(3370), np.int64(3423), np.int64(3438), np.int64(3644), np.int64(3742), np.int64(3858), np.int64(3932), np.int64(3950), np.int64(3985), np.int64(4114), np.int64(4136), np.int64(4154), np.int64(4174), np.int64(4271), np.int64(4461), np.int64(4573), np.int64(4602), np.int64(4671), np.int64(4805), np.int64(4847), np.int64(4963), np.int64(4982), np.int64(5085), np.int64(5457), np.int64(5559), np.int64(5594)] [np.int64(63), np.int64(113), np.int64(163), np.int64(232), np.int64(292), np.int64(338), np.int64(349), np.int64(424), np.int64(436), np.int64(451), np.int64(520), np.int64(531), np.int64(640), np.int64(671), np.int64(1002), np.int64(1117), np.int64(1129), np.int64(1300), np.int64(1344), np.int64(1529), np.int64(1554), np.int64(1632), np.int64(1645), np.int64(1661), np.int64(1738), np.int64(1798), np.int64(1881), np.int64(1923), np.int64(2102), np.int64(2175), np.int64(2214), np.int64(2246), np.int64(2363), np.int64(2593), np.int64(2704), np.int64(2759), np.int64(2812), np.int64(3083), np.int64(3175), np.int64(3245), np.int64(3313)] [np.int64(123), np.int64(149), np.int64(219), np.int64(260), np.int64(280), np.int64(608), np.int64(637), np.int64(727), np.int64(813), np.int64(894), np.int64(921), np.int64(997), np.int64(1090), np.int64(1115), np.int64(1235), np.int64(1275), np.int64(1370), np.int64(1384), np.int64(1482), np.int64(1502), np.int64(1654), np.int64(1826), np.int64(1838), np.int64(1865), np.int64(1896), np.int64(2014), np.int64(2086), np.int64(2190), np.int64(2208), np.int64(2302), np.int64(2471), np.int64(2513), np.int64(2569), np.int64(2583), np.int64(2681), np.int64(2821), np.int64(2838), np.int64(3028), np.int64(3096), np.int64(3264), np.int64(3308), np.int64(3377), np.int64(3513), np.int64(3590), np.int64(3668), np.int64(3728), np.int64(3814), np.int64(3853), np.int64(3908), np.int64(4095)] [np.int64(38), np.int64(114), np.int64(255), np.int64(302), np.int64(314), np.int64(335), np.int64(674), np.int64(778), np.int64(922), np.int64(1079), np.int64(1276), np.int64(1310), np.int64(1342), np.int64(1486), np.int64(1781), np.int64(1968), np.int64(2036), np.int64(2161), np.int64(2174), np.int64(2223), np.int64(2255), np.int64(2276), np.int64(2310), np.int64(2328), np.int64(2444), np.int64(2476), np.int64(2498), np.int64(2520), np.int64(2659), np.int64(2826)] [np.int64(59), np.int64(146), np.int64(176), np.int64(272), np.int64(395), np.int64(475), np.int64(553), np.int64(571), np.int64(659), np.int64(901), np.int64(960), np.int64(1056), np.int64(1080), np.int64(1112), np.int64(1139), np.int64(1491), np.int64(1530), np.int64(1555), np.int64(1733), np.int64(1809), np.int64(1925), np.int64(1940), np.int64(2024), np.int64(2035), np.int64(2156), np.int64(2201), np.int64(2304), np.int64(2334), np.int64(2395), np.int64(2528), np.int64(2578), np.int64(2629), np.int64(2651), np.int64(2763), np.int64(2811), np.int64(2831), np.int64(2908), np.int64(2930), np.int64(3133), np.int64(3285), np.int64(3345), np.int64(3451), np.int64(3500), np.int64(3582), np.int64(3611), np.int64(3837), np.int64(3914), np.int64(3948), np.int64(4087), np.int64(4230), np.int64(4327), np.int64(4414), np.int64(4433), np.int64(4510), np.int64(4587), np.int64(4607), np.int64(4700), np.int64(4783), np.int64(4799), np.int64(4828), np.int64(4944), np.int64(5083)] /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:32: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['min_comparisons_smaller'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1558634327.py:37: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['local_minima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/785596803.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema_sup(df, '收盤價')) price_df[\u0026#39;日期_dt\u0026#39;] = pd.to_datetime(price_df[\u0026#39;日期\u0026#39;] ) strategy Logic price_df.reset_index(drop=True, inplace=True) # 近一個月 400張大戶 增加2%以上 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4079245513.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 mask = (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[mask, \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/857034293.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1700805250.py:4: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[((price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;])) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/168196673.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;20MA\u0026#39;] \u0026gt;= price_df[\u0026#39;200MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3380416550.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/939178834.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/357474516.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 組合上下行 price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/950731482.py:5: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/4128040719.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3623880085.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;min_comparisons_smaller\u0026#39;]==1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1110539843.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt; 0.02), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3456730543.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026gt;= price_df[\u0026#39;60MA\u0026#39;]) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;] \u0026gt; 0.02) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/1528418423.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;收盤價\u0026#39;] \u0026lt; price_df[\u0026#39;60MA\u0026#39;]) , \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/538384737.py:3: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) # price_df[price_df[\u0026#39;signal\u0026#39;]==1] NOW price_df[\u0026#39;signal\u0026#39;] = 0 # (price_df[\u0026#39;max_comparisons_larger\u0026#39;]==1) # \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;]) # (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5)| (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1) price_df.loc[((price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;0.02) \u0026amp; (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026gt;price_df[\u0026#39;local_maxima\u0026#39;])) | (price_df[\u0026#39;週集保diff4week\u0026#39;]\u0026gt;0.5) | (price_df[f\u0026#39;slope_{w}_rolling_{j}_SUM\u0026#39;]\u0026lt;price_df[\u0026#39;local_minima\u0026#39;]) | (price_df[\u0026#39;維持率反推融資平均損益\u0026#39;]\u0026lt;-0.1), \u0026#39;signal\u0026#39;] = 1 res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3722245375.py:6: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) 簡易PnL模擬 res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2059', '3008'], dtype='object') from collections import Counter def vector_backtest_ratio(df, buyholddays): \u0026#39;\u0026#39;\u0026#39; for backtest PnL ratio index_count 算目前在該ticker 上累積bet的數量 \u0026#39;\u0026#39;\u0026#39; df.reset_index(drop=True, inplace=True) df[\u0026#39;ratio\u0026#39;] = 0 signal_idx = df[df[\u0026#39;signal\u0026#39;]==1].index all_holding_idx = [] for idx in signal_idx: adding_idx = [i for i in range(idx, idx+buyholddays) if i \u0026lt; len(df)] all_holding_idx += adding_idx df.loc[all_holding_idx, \u0026#39;signal\u0026#39;] = 1 return df price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 10)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/517245478.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 10)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 20)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2754594864.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 20)) price_df = price_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_ratio(df, 60)) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/3282921495.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : vector_backtest_ratio(df, 60)) price_df.reset_index(drop=True, inplace=True) res_list = price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;).apply(vector_backtest) res_df = pd.DataFrame() for data in res_list: tmp = pd.DataFrame(data, columns=[\u0026#39;股票代號\u0026#39;, \u0026#39;訊號開始日\u0026#39;, \u0026#39;訊號結束日\u0026#39;, \u0026#39;買入價格\u0026#39;, \u0026#39;賣出價格\u0026#39;, \u0026#39;return\u0026#39;, \u0026#39;訊號持續天數\u0026#39;]) res_df = pd.concat([res_df, tmp], ignore_index=True) res_df[\u0026#39;return_fee\u0026#39;] = (res_df[\u0026#39;return\u0026#39;] - 0.00585) + 1 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/317971430.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res_list = price_df[(price_df['日期_dt']\u0026gt;='20150101')].groupby('股票代號').apply(vector_backtest) show_df = pd.DataFrame(columns=[\u0026#39;ticker_benchmark_pnl\u0026#39;, \u0026#39;strategy_pnl\u0026#39;, \u0026#39;time_in_markets\u0026#39;]) for ticker in SUB_TICKERS: GOAL = (price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[-1]/price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;), \u0026#39;收盤價\u0026#39;].iloc[0])-1 show_df.loc[ticker, \u0026#39;ticker_benchmark_pnl\u0026#39;] = GOAL if res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().empty: continue strategy_pnl = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;return_fee\u0026#39;].cumprod().dropna().values[-1] show_df.loc[ticker, \u0026#39;strategy_pnl\u0026#39;] = strategy_pnl show_df.loc[ticker, \u0026#39;time_in_markets\u0026#39;] = res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==ticker), \u0026#39;訊號持續天數\u0026#39;].sum()/len(price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==ticker) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df[\u0026#39;perfect_res\u0026#39;] = show_df[\u0026#39;strategy_pnl\u0026#39;]/show_df[\u0026#39;time_in_markets\u0026#39;] show_df[\u0026#39;0.8_benchmark\u0026#39;] = show_df[\u0026#39;ticker_benchmark_pnl\u0026#39;]*0.8 show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } print(show_df[show_df[\u0026#39;perfect_res\u0026#39;]\u0026gt;show_df[\u0026#39;0.8_benchmark\u0026#39;]].index) Index(['2330', '8069', '3008'], dtype='object') 如果是想要抄底的策略 holding 天數可能要拉長到可以等他漲回去 # price_df.loc[(price_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (price_df[\u0026#39;signal\u0026#39;]==1)].iloc[-20::] res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;5274\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } 1410/2410 0.5850622406639004 2454, 2383, 2059, 3008 done res_df.loc[(res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;)] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:29: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)` df['max_comparisons_larger'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2871522017.py:33: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method. The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy. For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object. df['local_maxima'].ffill(inplace=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_4023/2373799201.py:2: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. price_df = price_df.groupby('股票代號').apply(lambda df : groupby_extrema(df, f'slope_{w}_rolling_{j}_SUM')) price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;slope\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1444240800.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;last_20Days_ret_0050\u0026#39;]\u0026lt;=-0.05), \u0026#39;signal\u0026#39;] = 1 price_df[\u0026#39;signal\u0026#39;] = 0 price_df.loc[(price_df[\u0026#39;slope\u0026#39;]\u0026gt;=0.1), \u0026#39;signal\u0026#39;] = 1 ret_cols = [f\u0026#39;hold_{n}Days_ret\u0026#39; for n in [5, 10, 20, 60, 120]] winrate_cols = [f\u0026#39;hold_{n}Days_winrate\u0026#39; for n in [5, 10, 20, 60, 120]] price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() - price_df[(price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[ret_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].mean() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } PE price_df[\u0026#39;cut\u0026#39;] = pd.qcut(price_df[\u0026#39;本益比(近四季)\u0026#39;], 10) res = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_ret\u0026#39;].mean().reset_index(drop=False) res[\u0026#39;hold_20Days_winrate\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].mean().reset_index(drop=True) res[\u0026#39;signal_count\u0026#39;] = price_df.groupby([\u0026#39;cut\u0026#39;, \u0026#39;股票代號\u0026#39;])[\u0026#39;hold_20Days_winrate\u0026#39;].count().reset_index(drop=True) res /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:2: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res = price_df.groupby(['cut', '股票代號'])['hold_20Days_ret'].mean().reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:3: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['hold_20Days_winrate'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].mean().reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_17654/1178586764.py:4: FutureWarning: The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning. res['signal_count'] = price_df.groupby(['cut', '股票代號'])['hold_20Days_winrate'].count().reset_index(drop=True) .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df.columns Index(['日期', '股票代號', '股票名稱', '開盤價', '最高價', '最低價', '收盤價', '漲跌', '漲幅(%)', '振幅(%)', '成交量', '成交筆數', '成交金額(千)', '均張', '成交量變動(%)', '均張變動(%)', '股本(百萬)', '總市值(億)', '市值比重(%)', '本益比', '股價淨值比', '本益比(近四季)', '週轉率(%)', '成交值比重(%)', '漲跌停', 'RTIME', '日期_dt', 'hold_5Days_ret', 'last_5Days_ret', 'hold_5Days_winrate', 'hold_10Days_ret', 'last_10Days_ret', 'hold_10Days_winrate', 'hold_20Days_ret', 'last_20Days_ret', 'hold_20Days_winrate', 'hold_60Days_ret', 'last_60Days_ret', 'hold_60Days_winrate', 'hold_120Days_ret', 'last_120Days_ret', 'hold_120Days_winrate', '日期_0050', '股票代號_0050', '股票名稱_0050', '開盤價_0050', '最高價_0050', '最低價_0050', '收盤價_0050', '漲跌_0050', '漲幅(%)_0050', '振幅(%)_0050', '成交量_0050', '成交筆數_0050', '成交金額(千)_0050', '均張_0050', '成交量變動(%)_0050', '均張變動(%)_0050', '股本(百萬)_0050', '總市值(億)_0050', '市值比重(%)_0050', '本益比_0050', '股價淨值比_0050', '本益比(近四季)_0050', '週轉率(%)_0050', '成交值比重(%)_0050', '漲跌停_0050', 'RTIME_0050', 'hold_5Days_ret_0050', 'last_5Days_ret_0050', 'hold_5Days_winrate_0050', 'hold_10Days_ret_0050', 'last_10Days_ret_0050', 'hold_10Days_winrate_0050', 'hold_20Days_ret_0050', 'last_20Days_ret_0050', 'hold_20Days_winrate_0050', 'hold_60Days_ret_0050', 'last_60Days_ret_0050', 'hold_60Days_winrate_0050', 'hold_120Days_ret_0050', 'last_120Days_ret_0050', 'hold_120Days_winrate_0050', 'cut', 'signal'], dtype='object') price_df[(price_df[\u0026#39;signal\u0026#39;]==1) \u0026amp; (price_df[\u0026#39;日期_dt\u0026#39;]\u0026gt;=\u0026#39;20150101\u0026#39;)].groupby(\u0026#39;股票代號\u0026#39;)[winrate_cols].count() .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } price_df[[\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;signal\u0026#39;]+ret_cols+winrate_cols].to_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/TW_forwardPE/data/test_get_strategy_result/test.ftr\u0026#39;) income_stat_df = pd.read_feather(\u0026#39;/Users/roberthsu/Documents/TrendForce_project/cmoney_warehouse/quarterly/quarterlyIncomeStatementSingal.ftr\u0026#39;) income_stat_df = income_stat_df[income_stat_df[\u0026#39;股票代號\u0026#39;].isin(SUB_TICKERS)] income_stat_df[\u0026#39;公告日_dt\u0026#39;] = pd.to_datetime(income_stat_df[\u0026#39;公告日期\u0026#39;]) income_stat_df.sort_values(\u0026#39;年季\u0026#39;, inplace=True, ascending=True) income_stat_df.reset_index(drop=True, inplace=True) income_stat_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import re income_stat_df.columns = [re.sub(r\u0026#39;\\s+\u0026#39;, \u0026#39;\u0026#39;, i) for i in income_stat_df.columns] income_stat_df.columns[0:30] Index(['年季', '股票代號', '股票名稱', '市場別', '財報類別', '銷貨收入淨額(千)', '銷貨收入(千)', '銷貨退回(千)', '銷貨折讓(千)', '營業收入淨額(千)', '營業成本(千)', '營業毛利(千)', '聯屬公司間未實現利益(千)', '聯屬公司間已實現利益(千)', '營業毛利淨額(千)', '營業費用(千)', '推銷費用(千)', '管理費用(千)', '研發費用(千)', '預期信用減損損益(千)', '其他營業費用(千)', '其他收益及費損(千)', '其他收益(千)', '其他費損(千)', '營業利益(千)', '營業外收入及支出(千)', '利息收入(千)', '銀行存款利息(千)', '按攤銷後成本衡量之金融資產利息收入(千)', '透過其他綜合損益按公允價值衡量之金融資產利息收入(千)'], dtype='object') income_stat_df.columns[-30::] Index(['國外營運機構淨投資避險中屬有效避險部分之避險工具損益(千)', '與待出售非流動資產直接相關之權益–可能重分類至損益(千)', '透過其他綜合損益按公允價值衡量之債務工具投資未實現評價損益(千)', '避險工具之損益–可能重分類至損益(千)', '採權益法認列關聯企業及合資其他綜合損益之份額–可能重分類至損益(千)', '可能重分類至損益之其他項目(千)', '與可能重分類至損益之項目相關之所得稅(千)', '綜合損益(千)', '稅後純益歸屬(千)', '母公司業主–稅後純益(千)', '非控制權益–稅後純益(千)', '共同控制下前手權益–稅後純益(千)', '綜合損益歸屬(千)', '母公司業主–綜合損益(千)', '非控制權益–綜合損益(千)', '共同控制下前手權益–綜合損益(千)', 'EBITDA(千)', '公告基本每股盈餘(元)', '公告稀釋每股盈餘(元)', '原始每股稅前盈餘(元)', '原始每股稅後盈餘(元)', '原始每股綜合盈餘(元)', '每股稅前盈餘(元)', '每股稅後盈餘(元)', '每股綜合盈餘(元)', '更新日期', '公告日期', '建立日期', 'RTIME', '公告日_dt'], dtype='object') income_stat_df[\u0026#39;母公司業主–稅後純益(千)\u0026#39;] 0 \u0026lt;NA\u0026gt; 1 \u0026lt;NA\u0026gt; 2 \u0026lt;NA\u0026gt; 3 \u0026lt;NA\u0026gt; 4 1602873 ... 818 4498178 819 25715520 820 2435866 821 247845528 822 1456409 Name: 母公司業主–稅後純益(千), Length: 823, dtype: Int64 不同時間段 適合看得指標也不盡相同 我能不能這個概念 -\u0026gt; 用基本面的變化來作為時間段的區分 像是基本面改善期間 -\u0026gt; 適合的策略\n基本面維持不變時的策略\n股價過度反應/過高過低PE對應的策略\n像是 基本面漲, 股價沒漲 -\u0026gt; 可能已經反應過了, 也可能是還沒反應\n順勢 基本面漲 \u0026amp; 股價也漲\n大盤逆風 基本面漲 但股價大跌 -\u0026gt; 先不要進場 等大盤回穩 or PE到一定程度才進場\n貝氏定理 先把營收, EPS, 對比股價的圖Plot出來 判斷大盤行情 上行, 糾結, 下行 在對比各個features在這些期間之下的表現 ex: 大盤下行的時候 全部訊號都沒用 除了PE跌倒歷史quantile多少時可以買入\u0026hellip;, 上行的時候跟著持有也不用管基本面etc reample + merge EPS forward knowing , cal + resample + merge 1. 先把每一季的EPS做加總(4季 agg) 再藉由shift去假設 能夠完美預測未來N季 再resample 至daily def resample_q_forward(df): # print(df[\u0026#39;股票代號\u0026#39;].iloc[-1]) df = df[~df[\u0026#39;公告日期\u0026#39;].isna()] df = df[~df.duplicated(subset=[\u0026#39;公告日期\u0026#39;])] df[\u0026#39;knowNext0Q\u0026#39;] = df[\u0026#39;每股稅後盈餘(元)\u0026#39;].rolling(4).sum() df.set_index(\u0026#39;公告日_dt\u0026#39;, inplace=True) df = df.resample(\u0026#39;D\u0026#39;).ffill() return df 2. 與股價合併 resample_q_df = combine_df = price_df.merge(resample_q_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) combine_df[\u0026#39;Y_M\u0026#39;] = combine_df[\u0026#39;日期_dt\u0026#39;].dt.year.astype(str) + \u0026#39;_\u0026#39; + combine_df[\u0026#39;日期_dt\u0026#39;].dt.month.astype(str).str.zfill(2) sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub[\u0026#39;PEG_0Q\u0026#39;].describe() count 5167.0000 mean 1.5405 std 2.4577 min -1.0632 25% 0.3917 50% 0.7254 75% 1.6816 max 20.2743 Name: PEG_0Q, dtype: float64 3. 有股價 有完美預測一段時間的EPS -\u0026gt; 就有完美預估的PE 找出該期間的MAX, MIN值 主要是用來繪制河流圖 並shift def find_PE_range(df): \u0026#39;\u0026#39;\u0026#39; groupby 年季, ticker 假設知道未來N季的EPS 對應期間股價的P/E 區間的max, min 應該要用於未來畫本益比河流圖所用 \u0026#39;\u0026#39;\u0026#39; tmp = pd.DataFrame() YM = df[\u0026#39;Y_M\u0026#39;].iloc[-1] Q = df[\u0026#39;年季\u0026#39;].iloc[-1] for i in range(1, 5): tmp.loc[Q, f\u0026#39;{i}_max_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].max() tmp.loc[Q, f\u0026#39;{i}_mean_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].mean() tmp.loc[Q, f\u0026#39;{i}_min_PE\u0026#39;] = df[f\u0026#39;PE_{i}Q\u0026#39;].min() # tmp.loc[Q, f\u0026#39;{i}_max_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].max() # tmp.loc[Q, f\u0026#39;{i}_mean_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].mean() # tmp.loc[Q, f\u0026#39;{i}_min_PEG\u0026#39;] = df[f\u0026#39;PEG_{i}Q\u0026#39;].min() tmp[\u0026#39;Q\u0026#39;] = Q return tmp pe_res = combine_df.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]).apply(find_PE_range).reset_index(drop=False) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/3018702681.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. pe_res = combine_df.groupby(['股票代號', '年季']).apply(find_PE_range).reset_index(drop=False) 用前一季之前的All data 來計算 分位數 # Convert the \u0026#39;quarter\u0026#39; column to a Period with quarterly frequency combine_df[\u0026#39;year\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[:4] # Extract the year (first 4 digits) combine_df[\u0026#39;qtr\u0026#39;] = combine_df[\u0026#39;年季\u0026#39;].str[-2:] # Extract the quarter (last 2 digits) # Create a new column with period as \u0026#39;YYYYQ#\u0026#39; format (like 2000Q4, 2001Q1, etc.) combine_df[\u0026#39;period\u0026#39;] = combine_df[\u0026#39;year\u0026#39;] + \u0026#39;Q\u0026#39; + combine_df[\u0026#39;qtr\u0026#39;].replace({\u0026#39;01\u0026#39;: \u0026#39;1\u0026#39;, \u0026#39;02\u0026#39;: \u0026#39;2\u0026#39;, \u0026#39;03\u0026#39;: \u0026#39;3\u0026#39;, \u0026#39;04\u0026#39;: \u0026#39;4\u0026#39;}) # Convert to Pandas Period with quarterly frequency combine_df[\u0026#39;period\u0026#39;] = pd.PeriodIndex(combine_df[\u0026#39;period\u0026#39;], freq=\u0026#39;Q\u0026#39;) def quantile_q(df): i = 0 q_list = df[\u0026#39;period\u0026#39;].unique().tolist() sub_df_list = [] for q in q_list: thisQ = df[df[\u0026#39;period\u0026#39;]==q] lastQ = df[(df[\u0026#39;period\u0026#39;]\u0026gt;(q - 40)) \u0026amp; (df[\u0026#39;period\u0026#39;]\u0026lt;q)] # 20 -\u0026gt; 5y, 12 -\u0026gt; 3y for i in range(0, 5): thisQ[f\u0026#39;q20_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.2) thisQ[f\u0026#39;q40_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.4) thisQ[f\u0026#39;q60_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.6) thisQ[f\u0026#39;q80_{i}Q\u0026#39;] = lastQ[f\u0026#39;PE_{i}Q\u0026#39;].quantile(0.8) # thisQ[f\u0026#39;q20_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.2) # thisQ[f\u0026#39;q40_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.4) # thisQ[f\u0026#39;q60_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.6) # thisQ[f\u0026#39;q80_{i}Q_G\u0026#39;] = lastQ[f\u0026#39;PEG_{i}Q\u0026#39;].quantile(0.8) sub_df_list.append(thisQ) new_df = pd.concat(sub_df_list) return new_df res = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(quantile_q).reset_index(drop=True) /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/348048885.py:1: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning. res = combine_df.groupby('股票代號').apply(quantile_q).reset_index(drop=True) res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;3533\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2008Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x1283cb400\u0026gt; png\r\u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[(res[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (res[\u0026#39;period\u0026#39;]\u0026gt;=\u0026#39;2018Q1\u0026#39;)] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 4 ax1.set_title(\u0026#39;{}_PE_knowNext{}Q\u0026#39;.format(sub[\u0026#39;股票代號\u0026#39;].iloc[-1], i)) # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q20_{i}Q_G\u0026#39;], label=\u0026#39;q20\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q40_{i}Q_G\u0026#39;], label=\u0026#39;q40\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q60_{i}Q_G\u0026#39;], label=\u0026#39;q60\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;q80_{i}Q_G\u0026#39;], label=\u0026#39;q80\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PEG_{i}Q\u0026#39;]) ax1.legend() \u0026lt;matplotlib.legend.Legend at 0x124c216d0\u0026gt; png\rfor i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;0~20_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;20~40_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;40~60_{i}Q_G\u0026#39; if (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q_G\u0026#39;]) \u0026amp; (row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q_G\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;60~80_{i}Q_G\u0026#39; if row[f\u0026#39;PEG_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q_G\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q_G\u0026#39;] = f\u0026#39;80~100_{i}Q_G\u0026#39; for i in range(0, 5): for idx, row in res.iterrows(): if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q20_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;0~20_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q20_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q40_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;20~40_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q40_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q60_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;40~60_{i}Q\u0026#39; if (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q60_{i}Q\u0026#39;]) \u0026amp; (row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;q80_{i}Q\u0026#39;]): res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;60~80_{i}Q\u0026#39; if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;q80_{i}Q\u0026#39;]: res.loc[idx, f\u0026#39;cata_{i}Q\u0026#39;] = f\u0026#39;80~100_{i}Q\u0026#39; res[res[\u0026#39;cata_0Q\u0026#39;]==\u0026#39;0~20_0Q\u0026#39;] .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[[\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() preview_res = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_0Q\u0026#39;])[[\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() preview_res[\u0026#39;day_ratio\u0026#39;] = res.groupby([\u0026#39;股票代號\u0026#39;, \u0026#39;cata_4Q\u0026#39;])[\u0026#39;收盤價\u0026#39;].count()/6275 preview_res .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;20~40_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) # for i in range(0, 5): for i in [0, 4]: # ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;PE_1Q\u0026#39;], label=\u0026#39;PE_1Q\u0026#39;) hist_obj = ax1.hist(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, bins=100, alpha=0.5 ) color = hist_obj[2][0].get_facecolor() ax1.axvline(sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].mean(), ymin=0, ymax=500, label=f\u0026#39;q{quantile}_{i}Q\u0026#39;, color=color) ax1.legend() png\rpng\rpng\rpng\rpng\rfrom scipy import stats import numpy as np # Generate some sample data with different lengths data1 = np.random.normal(50, 10, 100) # Dataset 1 data2 = np.random.normal(52, 15, 150) # Dataset 2 # Perform a two-sample t-test assuming equal variances (Student\u0026#39;s t-test) t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}\u0026#34;) # Perform Welch\u0026#39;s t-test (does not assume equal variances) t_stat_welch, p_value_welch = stats.ttest_ind(data1, data2, equal_var=False) print(f\u0026#34;Welch\u0026#39;s t-test: t-statistic = {t_stat_welch:.4f}, p-value = {p_value_welch:.4f}\u0026#34;) \u0026#39;\u0026#39;\u0026#39; 分位數的計算區間 - depends on func. quantile_q look back 20Q = 5y 區間 \u0026#39;\u0026#39;\u0026#39; sub = res tmp = pd.DataFrame() for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: i = 0 t = 1 for days in [5, 10, 20, 60, 120]: data1 = sub.loc[sub[f\u0026#39;cata_{i}Q\u0026#39;] == f\u0026#39;{quantile}_{i}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values data2 = sub.loc[sub[f\u0026#39;cata_{t}Q\u0026#39;] == f\u0026#39;{quantile}_{t}Q\u0026#39;, f\u0026#39;hold_{days}Days_ret\u0026#39;].values t_stat, p_value = stats.ttest_ind(data1, data2, equal_var=True) print(f\u0026#34;Student\u0026#39;s t-test: t-statistic = {t_stat:.4f}, p-value = {p_value:.4f}, {quantile}_{t}Q, \u0026#39;hold_{days}Days_ret\u0026#39;\u0026#34;) tmp.loc[f\u0026#39;{quantile}_{i}Q vs {t}Q\u0026#39;, f\u0026#39;hold {days} mean return p-value\u0026#39;] = p_value tmp 有多少 forward 0 在低本益比 但其實用forward 4Q是高本益比\n反之亦然\n這類股價其實是由未來營收所帶動的 也許就是我們想要抓的?\nforward 的優勢就在於 用歷史推估 跟由研調預測得出來的結論有明顯差異 材值得做\nsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;60~80_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1 \u0026amp; mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;80~100_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res # mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;40~60_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } sub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) # mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() show_df.loc[\u0026#39;precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } import numpy as np sub = res mask1 = (sub[\u0026#39;cata_0Q_G\u0026#39;] == \u0026#39;80~100_0Q_G\u0026#39;) mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt; 0) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt; 1) show_df = pd.DataFrame() for i in np.arange(0.1, 1, 0.1): mask2 = (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026gt;= i) \u0026amp; (sub[\u0026#39;PEG_0Q\u0026#39;] \u0026lt; (i + 0.1)) show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_precision\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask2, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df.loc[f\u0026#39;{i:.1f}~{i+0.1:.1f}_mean return\u0026#39;, \u0026#39;count\u0026#39;] = len(sub.loc[mask2]) show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } show_df = pd.DataFrame() sub = res for quantile in [\u0026#39;0~20\u0026#39;, \u0026#39;20~40\u0026#39;, \u0026#39;40~60\u0026#39;, \u0026#39;60~80\u0026#39;, \u0026#39;80~100\u0026#39;]: mask1 = (sub[\u0026#39;cata_4Q\u0026#39;] == f\u0026#39;{quantile}_4Q\u0026#39;) show_df.loc[f\u0026#39;mean_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() show_df.loc[f\u0026#39;precision_{quantile}\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean().tolist() show_df .dataframe tbody tr th { vertical-align: top; } .dataframe thead th { text-align: right; } res.columns import pandas as pd import matplotlib.pyplot as plt # Example data with 8 categories data = {\u0026#39;Date\u0026#39;: pd.date_range(start=\u0026#39;2024-01-01\u0026#39;, periods=10, freq=\u0026#39;D\u0026#39;), \u0026#39;Signal\u0026#39;: [0, 1, 0, 1, 0, 0, 1, 0, 1, 0], \u0026#39;Category\u0026#39;: [\u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;, \u0026#39;C\u0026#39;, \u0026#39;D\u0026#39;, \u0026#39;E\u0026#39;, \u0026#39;F\u0026#39;, \u0026#39;G\u0026#39;, \u0026#39;H\u0026#39;, \u0026#39;A\u0026#39;, \u0026#39;B\u0026#39;]} df = pd.DataFrame(data) # Get unique categories (suppose you have exactly 8 categories) categories = df[\u0026#39;Category\u0026#39;].unique() # Define the number of rows and columns for the subplots n_rows, n_cols = 2, 4 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() # Loop through each category and plot for i, category in enumerate(categories): # Filter DataFrame by category category_df = df[df[\u0026#39;Category\u0026#39;] == category] # Get dates where Signal == 1 for that category signal_dates = category_df.loc[category_df[\u0026#39;Signal\u0026#39;] == 1, \u0026#39;Date\u0026#39;] # Plot vertical lines on the respective subplot axes[i].vlines(x=signal_dates, ymin=0, ymax=1, color=\u0026#39;b\u0026#39;, linestyle=\u0026#39;--\u0026#39;, label=f\u0026#39;Signal {category}\u0026#39;) axes[i].set_title(f\u0026#39;Category {category}\u0026#39;) axes[i].set_ylabel(\u0026#39;Signal\u0026#39;) # Format the x-axis for dates (shared x-axis) axes[i].xaxis.set_major_formatter(plt.matplotlib.dates.DateFormatter(\u0026#39;%Y-%m-%d\u0026#39;)) axes[i].tick_params(axis=\u0026#39;x\u0026#39;, rotation=45) # Hide empty subplots if any (for cases when the grid is larger than needed) for j in range(i + 1, n_rows * n_cols): fig.delaxes(axes[j]) # Set the xlabel for the subplots in the last row for ax in axes[-n_cols:]: ax.set_xlabel(\u0026#39;Date\u0026#39;) # Adjust layout plt.tight_layout() plt.show() len(res[\u0026#39;股票代號\u0026#39;].unique()) \u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q 0~20\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2901875589.py:18: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\r\u0026#39;\u0026#39;\u0026#39; Plot 不同組合的signal PEG ver. \u0026#39;\u0026#39;\u0026#39; n_rows, n_cols = 3, 3 # Create subplots for each category in a 2x4 grid fig, axes = plt.subplots(n_rows, n_cols, figsize=(15, 8), sharex=True) # Flatten the axes array for easier indexing axes = axes.flatten() for i, ticker in enumerate(res[\u0026#39;股票代號\u0026#39;].unique()): sub = res[res[\u0026#39;股票代號\u0026#39;]==ticker] mask2 = (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026gt;= 0.7) \u0026amp; (sub[\u0026#39;PEG_4Q\u0026#39;] \u0026lt;= 0.9) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 # sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 sub.loc[mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(331) # axes[i].set_title(f\u0026#39;{ticker}_0Q 80~100, 4Q 0~20\u0026#39;) axes[i].set_title(f\u0026#39;{ticker}_4Q, PEG 0.7~0.9\u0026#39;) axes[i].plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = axes[i].twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax2.legend() /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 /var/folders/l8/m7cjxss57kbc_bplh66qpmy40000gn/T/ipykernel_1441/2280781.py:19: SettingWithCopyWarning: A value is trying to be set on a copy of a slice from a DataFrame. Try using .loc[row_indexer,col_indexer] = value instead See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy sub['signal'] = 0 png\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rpng\rsub = res[res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] mask1 = (sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;80~100_0Q\u0026#39;) mask2 = (sub[\u0026#39;cata_4Q\u0026#39;] == \u0026#39;0~20_4Q\u0026#39;) # sub.loc[mask1 \u0026amp; mask2, [\u0026#39;股票代號\u0026#39;, \u0026#39;日期_dt\u0026#39;,\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].describe() sub[\u0026#39;signal\u0026#39;] = 0 sub.loc[mask1 \u0026amp; mask2, \u0026#39;signal\u0026#39;] = 1 fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) i = 0 ax1.set_title(f\u0026#39;{quantile}_{i}Q holding 120 ret\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.vlines(sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;], ymin=0, ymax=1, label=\u0026#39;signal\u0026#39;, colors=\u0026#39;orange\u0026#39;) ax1.legend() signal_dates = sub.loc[sub[\u0026#39;signal\u0026#39;] == 1, \u0026#39;日期_dt\u0026#39;].values ax1.vlines(x=signal_dates, label=\u0026#39;signal\u0026#39;) sub.loc[mask1, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() sub.loc[sub[\u0026#39;cata_0Q\u0026#39;] == \u0026#39;0~20_0Q\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;].values preview_res.loc[\u0026#39;2330\u0026#39;] res_indexPE = res.merge(IndexPE_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;]), right_on=([\u0026#39;日期_dt\u0026#39;])) IndexPE_res.columns res_indexPE[\u0026#39;股票代號\u0026#39;].unique() sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20030701\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20101231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] sub = IndexPE_res.loc[(IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20101231\u0026#39;) \u0026amp; (IndexPE_res[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20191231\u0026#39;), [\u0026#39;日期_dt\u0026#39;,\u0026#39;agg_PE_0Q\u0026#39;, \u0026#39;agg_PE_1Q\u0026#39;, \u0026#39;agg_PE_2Q\u0026#39;, \u0026#39;agg_PE_3Q\u0026#39;, \u0026#39;agg_PE_4Q\u0026#39;]] i = 1 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20121231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20240509\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] i = 4 sub = res_indexPE.loc[(res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026gt;\u0026#39;20161231\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;日期_dt\u0026#39;]\u0026lt;\u0026#39;20231109\u0026#39;) \u0026amp; (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;), [\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;,f\u0026#39;agg_PE_{i}Q\u0026#39;, f\u0026#39;PE_{i}Q\u0026#39;]] fig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ticker = sub[\u0026#39;股票代號\u0026#39;].iloc[-1] ax1.set_title(f\u0026#39;Index PE vs {ticker}_forward{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;PE_{i}Q\u0026#39;], label=f\u0026#39;{ticker}_PE_{i}Q\u0026#39;) ax1.plot(sub[\u0026#39;日期_dt\u0026#39;], sub[f\u0026#39;agg_PE_{i}Q\u0026#39;], label=f\u0026#39;index_PE_{i}Q\u0026#39;) ax1.legend() ticker = (res_indexPE[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) q = 4 tmp = pd.DataFrame() for i in [2, 4, 6, 8]: signal = (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026gt;res_indexPE[f\u0026#39;agg_PE_{q}Q\u0026#39;]) \u0026amp; (res_indexPE[f\u0026#39;PE_{q}Q\u0026#39;]\u0026lt;res_indexPE[f\u0026#39;q{i}0\u0026#39;]) # tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_ret\u0026#39;, \u0026#39;hold_10Days_ret\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]].mean() tmp.loc[f\u0026#39;\u0026lt;q{i}0\u0026#39;, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]] = res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].mean() # res_indexPE.loc[signal, [\u0026#39;hold_5Days_winrate\u0026#39;, \u0026#39;hold_10Days_winrate\u0026#39;, \u0026#39;hold_20Days_winrate\u0026#39;, \u0026#39;hold_60Days_winrate\u0026#39;, \u0026#39;hold_120Days_winrate\u0026#39;]].describe() tmp cumsum or rolling min/max + shift 就可以了\ndef rolling_max(df): \u0026#39;\u0026#39;\u0026#39; groupby ticker \u0026#39;\u0026#39;\u0026#39; for i in range(1, 5): df[f\u0026#39;{i}_cummax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].cummax().shift(1) df[f\u0026#39;{i}_cummin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].cummin().shift(1) df[f\u0026#39;{i}_cummean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].expanding().mean().shift(1) df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(20).max().shift(1) df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).min().shift(1) df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(20).mean().shift(1) df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(12).max().shift(1) df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).min().shift(1) df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(12).mean().shift(1) df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] = pe_res[f\u0026#39;{i}_max_PE\u0026#39;].rolling(40).max().shift(1) df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).min().shift(1) df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] = pe_res[f\u0026#39;{i}_min_PE\u0026#39;].rolling(40).mean().shift(1) return df pe_res = pe_res.groupby(\u0026#39;股票代號\u0026#39;).apply(rolling_max).reset_index(drop=True) # cumsum 至上一季 PE最高值, cumsum 至上一季 PE最低值, rolling 5y 至上一季 PE最高值, rolling 5y 至上一季 PE最低值 pe_res.loc[(pe_res[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) , [\u0026#39;年季\u0026#39;, \u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] 把 截至上一季 PE的高低點 算出來後 與股價merge combine_df = combine_df.merge(pe_res, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), right_on=([\u0026#39;股票代號\u0026#39;, \u0026#39;年季\u0026#39;]), suffixes=(\u0026#39;\u0026#39;, \u0026#39;_MINMAX\u0026#39;)) combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;) , [\u0026#39;日期\u0026#39;,\u0026#39;PE_1Q\u0026#39; ,\u0026#39;1_cummax_PE\u0026#39;, \u0026#39;1_cummin_PE\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;]] combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2454\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;knowNext1Q\u0026#39;, \u0026#39;1_rolling5ymax_PE\u0026#39;, \u0026#39;1_rolling5ymin_PE\u0026#39;, \u0026#39;1_rolling5ymean_PE\u0026#39;]].dropna() for i in range(1, 5): combine_df[f\u0026#39;knowNext{i}Q_5y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_5y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_3y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling3ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_10y平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_rolling10ymean_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最高價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummax_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum最低價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummin_PE\u0026#39;] combine_df[f\u0026#39;knowNext{i}Q_cumsum平均價\u0026#39;] = combine_df[f\u0026#39;knowNext{i}Q\u0026#39;] * combine_df[f\u0026#39;{i}_cummean_PE\u0026#39;] # 在知曉下一季EPS後 利用過往3季 + 未來1季 去算年度EPS # 在用該EPS 與當下股價計算 預知PE # 期間預知PE的min, max 將獨立出來 combine_df.loc[(combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;) \u0026amp; (combine_df[\u0026#39;年季\u0026#39;]==\u0026#39;202301\u0026#39;), [\u0026#39;日期\u0026#39;, \u0026#39;PE_1Q\u0026#39;, \u0026#39;1_max_PE\u0026#39;, \u0026#39;1_min_PE\u0026#39;, \u0026#39;1_mean_PE\u0026#39;, \u0026#39;hold_20Days_ret\u0026#39;, \u0026#39;hold_60Days_ret\u0026#39;, \u0026#39;hold_120Days_ret\u0026#39;]] 繪製本益比河流圖時 河流應為過去一段時間的min, max ex : under 知曉下一Q EPS的情況下\n過去10年 所有在知曉下一Q對應的EPS\nmin, max 作為河流 對照如今的 預知PE\n可以try 的財務指標\n存貨(千) 研發費用(千) PPE (不動產相關的變化) 先做圖 在想要怎麼辦\ncombine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] combine_df.columns[180:210] combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub.reset_index(drop=True, inplace=True) def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data def set_signal(data): # Initialize the signal and state i = 4 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= data[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt; row[f\u0026#39;{i}_rolling5ymin_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.7): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;]: data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 return data # 反向 def set_signal_reverse(data): # Initialize the signal and state i = 1 data[\u0026#39;signal\u0026#39;] = 0 data.loc[(data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (data[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2)) * (data[f\u0026#39;PE_{i}Q\u0026#39;] \u0026lt;= (data[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9)), \u0026#39;signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for idx, row in data.iterrows(): if state == 0: # Normal period if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymax_PE\u0026#39;] * 0.9): data.at[idx, \u0026#39;signal\u0026#39;] = 0 state = 2 elif state == 2: # Rebounding, waiting for upper bound if row[f\u0026#39;PE_{i}Q\u0026#39;] \u0026gt;= (row[f\u0026#39;{i}_rolling5ymean_PE\u0026#39;] * 1.2): data.at[idx, \u0026#39;signal\u0026#39;] = 0 else: data.at[idx, \u0026#39;signal\u0026#39;] = 1 state = 0 return data signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal).reset_index(drop=True) signal_df = combine_df.groupby(\u0026#39;股票代號\u0026#39;).apply(set_signal_reverse).reset_index(drop=True) def vector_backtest_delay_entering(df, delay_days): # prodction ver. # input: df, 需要有signal columns, output : [{trade_data1}, {trade_data2}, ...] (list中包含多個dict) # df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1) 會return boolean, 對此用cumsum # 在false的時候 就不會+1 就可以讓連續的組出現一樣的數字 # [0 , 1, 1, 0, 0, 1, 1, 1] (df[\u0026#39;signal\u0026#39;]) # [nan, 0, 1, 1, 0, 0, 1, 1] (df[\u0026#39;signal\u0026#39;].shift(1)) # [T, T, F, T, F, T, F, F] -\u0026gt; [1, 2, 2, 3, 3, 4, 4, 4](cumsum) # 然而連續組 同時包含signal==1 \u0026amp; signal==0 部分 # 利用df[signal]==1 來取得signal==1的index ## 想要include 最新持有的狀態 -\u0026gt; 若是最後一個row 的連續持有日期 \u0026gt;=4 (3個訊號 隔日才會買進 目前沒有持有) ## return的計算 要改 if not all(col in df.columns for col in [\u0026#39;日期\u0026#39;, \u0026#39;股票代號\u0026#39;, \u0026#39;收盤價\u0026#39;, \u0026#39;signal\u0026#39;]): raise KeyError(\u0026#34;df.columns should have 日期, 股票代號, 收盤價, signal\u0026#34;) df[\u0026#39;次日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-1) df[\u0026#39;次二日收盤價\u0026#39;] = df[\u0026#39;收盤價\u0026#39;].shift(-2) # 用來確認退場reaso # 將所有連續的事件相同數字表示, 而事件轉換時, 數字不相同 change_indices = (df[\u0026#39;signal\u0026#39;] != df[\u0026#39;signal\u0026#39;].shift(1)).cumsum() # 只想要group signal==1的事件 groups = df[df[\u0026#39;signal\u0026#39;] == 1].groupby(change_indices[df[\u0026#39;signal\u0026#39;] == 1]) event_list_all = [] for _, group in groups: \u0026#39;\u0026#39;\u0026#39; 盤後才知道訊號, 故操作都會在後續日期... 訊號開始日期(start_date): 該日收盤後有符合訊號, 故買入價會是隔一日的收盤價 訊號最後日期(end_date): 代表隔日收盤後就無訊號, 故賣出價是訊號最後日的隔二日收盤價 ex: date=[10/1, 10/2, 10/3, 10/4], signal = [1, 1, 0, 0] 則10/1為訊號開始日期 -\u0026gt; 10/2收盤價買入 10/2為訊號最後日期 -\u0026gt; 10/3收盤才知道訊號結束 -\u0026gt; 10/4收盤賣出 \u0026#39;\u0026#39;\u0026#39; if len(group) \u0026lt;= delay_days: # 訊號數不足 不會進場 continue else: group.reset_index(drop=True, inplace=True) group = group.iloc[delay_days::] # extract info from group trading_dict = { \u0026#39;股票代號\u0026#39;: group[\u0026#39;股票代號\u0026#39;].iloc[-1], \u0026#39;買入日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[0], \u0026#39;賣出日期\u0026#39;: group[\u0026#39;日期\u0026#39;].iloc[-1], \u0026#39;買入價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].iloc[0], \u0026#39;賣出價\u0026#39; : group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1], \u0026#39;期間最高價\u0026#39; : group[\u0026#39;次日收盤價\u0026#39;].max(), \u0026#39;持有天數\u0026#39; : len(group), \u0026#39;持有狀態\u0026#39; : \u0026#39;history\u0026#39;, \u0026#39;return\u0026#39; : (group[\u0026#39;次二日收盤價\u0026#39;].iloc[-1]/group[\u0026#39;次日收盤價\u0026#39;].iloc[0]) - 1, } event_list_all.append(trading_dict) # production情況下 每日最新一個group的狀況不一定 \u0026#39;\u0026#39;\u0026#39; 原本是收盤後跑 下午3點跑 改為開盤前 早上8點跑 這樣昨天的data一定更新好了 故 持有狀態的用詞修改 從buy_tomorrow -\u0026gt; buy_today \u0026#39;\u0026#39;\u0026#39; return event_list_all vector_backtest_delay_entering(sub, 0) res = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) res import pandas as pd import numpy as np # Simulated data with multiple cycles dates = pd.to_datetime([ \u0026#39;2024-01-01\u0026#39;, \u0026#39;2024-01-02\u0026#39;, \u0026#39;2024-01-03\u0026#39;, \u0026#39;2024-01-04\u0026#39;, \u0026#39;2024-01-05\u0026#39;, \u0026#39;2024-01-06\u0026#39;, \u0026#39;2024-01-07\u0026#39;, \u0026#39;2024-01-08\u0026#39;, \u0026#39;2024-01-09\u0026#39;, \u0026#39;2024-01-10\u0026#39;, \u0026#39;2024-01-11\u0026#39;, \u0026#39;2024-01-12\u0026#39;, \u0026#39;2024-01-13\u0026#39;, \u0026#39;2024-01-14\u0026#39;, \u0026#39;2024-01-15\u0026#39;, \u0026#39;2024-01-16\u0026#39;, \u0026#39;2024-01-17\u0026#39;, \u0026#39;2024-01-18\u0026#39;, \u0026#39;2024-01-19\u0026#39;, \u0026#39;2024-01-20\u0026#39; ]) # Simulated P/E ratios data = pd.DataFrame({ \u0026#39;PE_ratio\u0026#39;: [20, 21, 19, 22, 23, 10, 9, 11, 14, 16, 18, 20, 35, 36, 10, 9, 12, 15, 18, 20], \u0026#39;Adj Close\u0026#39;: np.random.randn(len(dates)) * 10 + 100 }, index=dates) # Parameters lower_bound = 10 upper_bound = 35 # Initialize the signal and state data[\u0026#39;Signal\u0026#39;] = 0 data.loc[(data[\u0026#39;PE_ratio\u0026#39;] \u0026lt;= lower_bound), \u0026#39;Signal\u0026#39;] = 1 state = 0 # 0: Normal, 1: Lower bound hit, 2: Rebounding for i in range(len(data)): pe_ratio = data.iloc[i][\u0026#39;PE_ratio\u0026#39;] if state == 0: # Normal period if pe_ratio \u0026lt;= lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 1 elif state == 1: # After hitting the lower bound, waiting for rebound if pe_ratio \u0026gt; lower_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 state = 2 elif state == 2: # Rebounding, waiting for upper bound if pe_ratio \u0026gt;= upper_bound: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 0 state = 0 else: data.at[data.index[i], \u0026#39;Signal\u0026#39;] = 1 print(\u0026#34;Filtered Data with Signals:\u0026#34;) print(data) trading_dict = signal_df.groupby(\u0026#39;股票代號\u0026#39;).apply(lambda df : vector_backtest_delay_entering(df, 0)) # 整理backtest result code = signal_df[\u0026#39;股票代號\u0026#39;].unique().tolist() res_df = pd.DataFrame() for c in code: tmp = trading_dict[c] tmp_df = pd.DataFrame(tmp) if not tmp_df.empty: res_df = pd.concat([res_df, tmp_df], ignore_index=True) code res_df[\u0026#39;precision\u0026#39;] = res_df[\u0026#39;return\u0026#39;].apply(lambda x : 1 if x \u0026gt; 0 else 0) res_df[[\u0026#39;return\u0026#39;, \u0026#39;precision\u0026#39;,\u0026#39;持有天數\u0026#39;]].describe() res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2383\u0026#39;, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe() for i in code: print(i) print(res_df.loc[res_df[\u0026#39;股票代號\u0026#39;]==i, [\u0026#39;return\u0026#39;, \u0026#39;持有天數\u0026#39;]].describe()) trading_dict[\u0026#39;2059\u0026#39;] sub[\u0026#39;forwardPE\u0026#39;].expanding().std() # combine_df = price_df.merge(resample_mon_df, how=\u0026#39;left\u0026#39;, left_on=([\u0026#39;日期_dt\u0026#39;, \u0026#39;股票代號\u0026#39;]), right_on=([\u0026#39;公告日_dt\u0026#39;, \u0026#39;股票代號\u0026#39;])) columns 展示 combine_df.columns[0:30] combine_df.columns[30:60] combine_df.columns[60:90] combine_df.columns[90:120] combine_df.columns[120:150] combine_df.columns[150:180] # Create subplots without shared axes fig, axes = plt.subplots(3, 3, figsize=(12, 8)) # Flatten the axes array for easy iteration axes = axes.flatten() # Group by \u0026#39;Stock\u0026#39; and plot each group in a separate subplot for ax, (name, group) in zip(axes, combine_df.groupby(\u0026#39;股票代號\u0026#39;)): ax.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;收盤價\u0026#39;], label=\u0026#39;Price\u0026#39;) ax.set_title(name) ax.set_xlabel(\u0026#39;Date\u0026#39;) # ax.set_ylabel(\u0026#39;Price\u0026#39;, color=\u0026#39;blue\u0026#39;) ax.legend(loc=2) # Create a secondary y-axis and plot \u0026#39;Volume\u0026#39; ax2 = ax.twinx() ax2.plot(group[\u0026#39;日期_dt\u0026#39;], group[\u0026#39;稅後純益率(%)\u0026#39;], label=\u0026#39;net profit ratio\u0026#39;, color=\u0026#39;orange\u0026#39;, alpha=0.6) # ax2.set_ylabel(\u0026#39;monthly rev\u0026#39;, color=\u0026#39;green\u0026#39;) ax2.legend(loc=3) # Set axis colors to match the data they represent ax.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;blue\u0026#39;) ax2.tick_params(axis=\u0026#39;y\u0026#39;, labelcolor=\u0026#39;green\u0026#39;) # Adjust layout to prevent overlap plt.tight_layout() # Show the plot plt.show() combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;8069\u0026#39;, \u0026#39;近三月合併營收(千)\u0026#39;].plot() combine_df[\u0026#39;股票代號\u0026#39;].unique() sub = combine_df.loc[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;3529\u0026#39;] image_2024-08-15_11-38-01.png\rfig = plt.figure(figsize=(16, 8)) ax1 = fig.add_subplot(111) ax1.set_title(\u0026#39;2317\u0026#39;) ax1.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;收盤價\u0026#39;], label=\u0026#39;price\u0026#39;) ax2 = ax1.twinx() ax2.plot(sub[\u0026#39;公告日_dt\u0026#39;], sub[\u0026#39;近12月累計合併營收(千)\u0026#39;], label=\u0026#39;12m_rev_agg\u0026#39;, color=\u0026#39;orange\u0026#39;) ax1.legend(loc=1) 指標相關聯 我覺得應該不只是財務數據 也有其他的東西但我們無法access\n籌碼相關, 分析師估值等\n但以我目前的情況 應該是做估值 並建立買賣點\n-\u0026gt; 存貨\n大概看了一下 營收的趨勢整體多為向上，股價也是 但若將週期縮小至2-3個月 營收與股價背離的情況很常發生\n判斷營收成長 or 衰退的趨勢 其time frame也要抓好\n畢竟營收整個趨勢變化較慢 但方向較穩定 但股價有更多雜訊因素\nsub = combine_df[combine_df[\u0026#39;股票代號\u0026#39;]==\u0026#39;2330\u0026#39;] sub = sub[(~sub[\u0026#39;3m_diff\u0026#39;].isna()) \u0026amp; (~sub[\u0026#39;12m_diff\u0026#39;].isna())] sub.isna().sum() combine_df.columns[-60:-30] sub[\u0026#39;optimize\u0026#39;] = (sub[\u0026#39;3m_diff\u0026#39;] \u0026gt; sub[\u0026#39;12m_diff\u0026#39;]).apply(lambda x : 1 if x else 0) sub[\u0026#39;近三月合併營收(千)\u0026#39;] sub[\u0026#39;3m_diff\u0026#39;] 694442123 - 673510177 ","date":"0001-01-01T00:00:00Z","permalink":"https://robertbasement.github.io/my-blog/posts/","title":""}]